{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCIR7rd5h9fv",
        "outputId": "2f7daf99-de20-446f-81ee-91c9b4ea83ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "#drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')\n",
        "#drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k8FHrSIiqDo",
        "outputId": "d98f2fa4-2e72-441e-e859-8ee72b9c70c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 15.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 83.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 36.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 14.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 489.6 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.37.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (4.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.0.0)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 68.8 MB/s \n",
            "\u001b[?25hCollecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 67.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.44.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (13.0.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.24.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "Successfully installed gast-0.4.0 keras-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.4.0-py3-none-any.whl (574 kB)\n",
            "\u001b[K     |████████████████████████████████| 574 kB 14.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from stanza) (4.18.0)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 88.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.11.0+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (4.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (4.11.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (0.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (0.0.49)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->stanza) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->stanza) (3.8.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->stanza) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->stanza) (7.1.2)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=96794efbc9090bbbca756a98dbbf0c5687d0071a08378df5d5069f9ed74ae6d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-1.7.0 stanza-1.4.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Collecting textacy\n",
            "  Downloading textacy-0.11.0-py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.64.0)\n",
            "Collecting pyphen>=0.10.0\n",
            "  Downloading pyphen-0.12.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 77.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.23.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.6.3)\n",
            "Collecting cytoolz>=0.10.1\n",
            "  Downloading cytoolz-0.11.2.tar.gz (481 kB)\n",
            "\u001b[K     |████████████████████████████████| 481 kB 73.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.2.4)\n",
            "Collecting jellyfish>=0.8.0\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 81.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.4.1)\n",
            "Collecting spacy>=3.0.0\n",
            "  Downloading spacy-3.2.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 53.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.1.0)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz>=0.10.1->textacy) (0.11.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.0->textacy) (3.1.0)\n",
            "Collecting typing-extensions<4.0.0.0,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (21.3)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n",
            "\u001b[K     |████████████████████████████████| 653 kB 65.2 MB/s \n",
            "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (57.4.0)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
            "\u001b[K     |████████████████████████████████| 457 kB 96.9 MB/s \n",
            "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.0.6)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 79.1 MB/s \n",
            "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.11.3)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 96.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.9.1)\n",
            "Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (7.1.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.4.1)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.0->textacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0.0->textacy) (3.0.8)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.0.0->textacy) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.0.0->textacy) (2.0.1)\n",
            "Building wheels for collected packages: cytoolz, jellyfish\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.11.2-cp37-cp37m-linux_x86_64.whl size=1230824 sha256=7b59a9d32fc65362ad33d9e0cccc46f9ca5aabf00ce7e4d699673981a6b17f80\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/70/71/ca13ea3d36ccd0b3d0ec7d7a4ca67522048d695b556bba4f59\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=73996 sha256=74817d1a674fdd2893ccf7a3d13f32b44fc627b8897cd61af1464f36eac5ed7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "Successfully built cytoolz jellyfish\n",
            "Installing collected packages: typing-extensions, catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy, pyphen, jellyfish, cytoolz, textacy\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.7 cytoolz-0.11.2 jellyfish-0.9.0 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 pyphen-0.12.0 spacy-3.2.4 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 textacy-0.11.0 thinc-8.0.15 typer-0.4.1 typing-extensions-3.10.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install tensorflow==2.7.0\n",
        "!pip install stanza\n",
        "!pip install transformers\n",
        "!pip install tensorflow-addons\n",
        "!pip install nltk\n",
        "!pip install textacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0rs0NoritMk",
        "outputId": "cf598b1b-2675-4ded-949f-c6d677d14855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wYwcFK5gixXz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from textacy.datasets.supreme_court import SupremeCourt\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "import nltk\n",
        "#from transformers import pipeline\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense,Dropout, Input, BatchNormalization\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras import regularizers\n",
        "#from transformers import *\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "import numpy as np\n",
        "import gc\n",
        "import math\n",
        "import json\n",
        "import stanza\n",
        "from tensorflow.keras import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import *\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import TFRobertaModel,RobertaTokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.initializers import RandomUniform\n",
        "\n",
        "from numpy.random import seed\n",
        "import random as python_random\n",
        "import os\n",
        "import sys\n",
        "\n",
        "np.random.seed(1)\n",
        "python_random.seed(1)\n",
        "tf.random.set_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bffI5vYTUeFW"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/labels_sc.txt\" \"./labels_sc.txt\"\n",
        "!cp \"/content/drive/My Drive/labels_sc_279.txt\" \"./labels_sc_279.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZinwFiui-A3",
        "outputId": "ee5ccda0-1696-4f7b-ef48-199ec640589d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'supreme_court', 'site_url': 'http://caselaw.findlaw.com/court/us-supreme-court', 'description': 'Collection of ~8.4k decisions issued by the U.S. Supreme Court between November 1946 and June 2016.'}\n",
            "[-1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
            "{'-1': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14}\n",
            "[8, 1, 8, 2, 8, 8, 8, 9, 7, 8, 1, 2, 1, 1, 8, 4, 8, 8, 12, 3, 3, 7, 3, 12, 1, 8, 8, 8, 8, 8, 8, 8, 1, 9, 5, 9, 9, 9, 11, 8, 8, 8, 4, 8, 8, 8, 8, 1, 3, 9, 3, 7, 1, 2, 9, 9, 7, 8, 8, 1, 10, 7, 8, 8, 9, 8, 7, 9, 9, 12, 7, 2, 8, 1, 11, 11, 1, 7, 7, 12, 1, 9, 8, 10, 12, 7, 8, 2, 8, 9, 9, 1, 8, 9, 1, 7, 12, 10, 10, 10, 8, 3, 7, 9, 8, 9, 1, 8, 8, 2, 7, 2, 9, 9, 11, 8, 8, 12, 12, 7, 8, 12, 4, 9, 3, 1, 12, 1, 1, 8, 8, 3, 8, 8, 8, 8, 9, 1, 8, 8, 10, 1, 8, 2, 8, 8, 7, 3, 8, 2, 4, 4, 9, 8, 10, 12, 12, 1, 1, 9, 1, 1, 1, 8, 2, 2, 8, 1, 1, 2, 2, 1, 2, 8, 1, 9, 9, 8, 8, 4, 2, 9, 9, 8, 3, 4, 3, 1, 8, 8, 2, 1, 9, 7, 8, 8, 1, 12, 3, 8, 2, 4, 2, 9, 12, 1, 4, 1, 8, 8, 8, 2, 2, 8, 9, 8, 8, 8, 10, 9, 8, 7, 9, 1, 1, 9, 4, 2, 4, 2, 2, 1, 7, 8, 11, 11, 3, 9, 2, 4, 8, 9, 1, 8, 1, 1, 4, 9, 1, 1, 8, 8, 2, 1, 8, 4, 2, 8, 9, 8, 8, 2, 8, 8, 8, 7, 1, 1, 1, 2, 1, 1, 8, 7, 8, 8, 12, 2, 12, 12, 8, 10, 12, 8, 3, 3, 12, 10, 1, 8, 12, 1, 8, 8, 2, 8, 4, 7, 8, 7, 10, 8, 10, 9, 8, 12, 12, 1, 8, 8, 3, 8, 8, 8, 8, 8, 1, 9, 8, 11, 1, 1, 1, 9, 8, 1, 9, 2, 3, 11, 8, 9, 9, 9, 2, 1, 8, 8, 9, 7, 1, 4, 9, 4, 8, 8, 4, 8, 12, 9, 4, 8, 2, 10, 10, 10, 8, 9, 9, 8, 8, 12, 7, 1, 8, 8, 8, 4, 1, 1, 1, 1, 1, 1, 8, 1, 9, 8, 9, 9, 4, 8, 12, 9, 8, 8, 2, 8, 8, 8, 6, 9, 8, 3, 7, 8, 8, 4, 12, 8, 8, 9, 12, 12, 9, 8, 2, 9, 2, 3, 1, 12, 8, 10, 9, 9, 9, 10, 10, 3, 8, 12, 1, 4, 2, 1, 10, 8, 2, 8, 4, 8, 9, 1, 9, 9, 10, 10, 1, 4, 9, 2, 4, 9, 1, 1, 3, 10, 3, 3, 8, 7, 3, 8, 9, 9, 12, 4, 8, 12, 2, 2, 4, 1, 9, 9, 4, 1, 4, 2, 8, 12, 2, 3, 10, 10, 9, 8, 9, 9, 1, 12, 8, 8, 8, 12, 4, 1, 8, 8, 1, 9, 8, 8, 2, 1, 8, 9, 8, 3, 3, 3, 1, 8, 8, 9, 1, 10, 9, 9, 9, 9, 5, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 11, 12, 8, 8, 1, 8, 9, 11, 2, 2, 2, 2, 3, 1, 2, 2, 8, 2, 4, 9, 1, 2, 9, 8, 2, 8, 9, 9, 3, 10, 9, 9, 2, 8, 9, 8, 12, 12, 1, 3, 8, 8, 8, 2, 7, 7, 7, 7, 3, 9, 1, 9, 8, 9, 9, 1, 1, 1, 2, 9, 9, 9, 11, 1, 8, 8, 9, 1, 9, 8, 8, 8, 1, 1, 8, 7, 1, 1, 8, 8, 9, 4, 4, 8, 2, 2, 8, 8, 8, 8, 8, 8, 11, 8, 2, 9, 4, 9, 3, 9, 9, 1, 3, 9, 3, 1, 12, 8, 9, 12, 1, 8, 4, 2, 1, 4, 8, 3, 3, 8, 2, 8, 9, 7, 8, 8, 8, 5, 8, 3, 9, 8, 8, 13, 12, 1, 1, 2, 8, 4, 1, 9, 9, 12, 8, 9, 12, 9, 1, 9, 9, 9, 9, 3, 2, 9, 9, 4, 8, 12, 2, 4, 9, 3, 1, 9, 7, 8, 9, 9, 8, 4, 8, 8, 7, 9, 10, 3, 8, 8, 8, 1, 1, 1, 1, 8, 8, 4, 1, 10, 1, 5, 7, 7, 1, 8, 9, 3, 7, 2, 7, 7, 2, 4, 8, 12, 7, 4, 2, 9, 9, 12, 6, 10, 8, 2, 4, 12, 9, 9, 3, 8, 8, 1, 2, 10, 9, 9, 8, 4, 12, 2, 1, 8, 8, 8, 12, 10, 10, 9, 3, 8, 8, 9, 2, 8, 10, 1, 1, 1, 1, 2, 1, 1, 1, 1, 9, 8, 12, 9, 4, 8, 8, 9, 1, 9, 3, 9, 8, 8, 1, 7, 7, 10, 1, 8, 8, 1, 9, 8, 10, 3, 1, 7, 1, 8, 8, 12, 8, 8, 1, 8, 7, 1, 7, 7, 8, 2, 1, 8, 8, 2, 10, 8, 8, 8, 8, 8, 10, 1, 8, 8, 12, 8, 3, 3, 2, 2, 2, 10, 8, 8, 8, 2, 9, 1, 8, 9, 3, 2, 8, 10, 8, 6, 1, 1, 8, 4, 1, 9, 10, 8, 1, 7, 1, 2, 8, 1, 1, 1, 12, 1, 9, 12, 8, 12, 12, 12, 8, 8, 12, 4, 8, 8, 8, 8, 9, 9, 1, 3, 3, 3, 3, 1, 12, 12, 9, 10, 8, 8, 1, 9, 2, 2, 13, 9, 8, 9, 2, 1, 9, 1, 8, 8, 8, 4, 8, 1, 1, 1, 12, 12, 7, 2, 2, 2, 8, 3, 8, 9, 2, 10, 7, 8, 9, 2, 1, 2, 12, 12, 8, 8, 9, 2, 2, 9, 11, 1, 8, 1, 10, 9, 2, 1, 4, 7, 7, 7, 7, 7, 12, 8, 8, 8, 1, 1, 10, 1, 12, 1, 8, 2, 1, 1, 12, 8, 7, 9, 12, 8, 9, 3, 9, 8, 8, 8, 8, 3, 11, 2, 2, 9, 8, 8, 10, 8, 2, 7, 3, 1, 4, 7, 8, 8, 1, 8, 3, 7, 12, 8, 10, 9, 9, 8, 8, 2, 8, 9, 9, 1, 2, 8, 8, 9, 8, 3, 8, 1, 8, 10, 9, 8, 9, 9, 12, 4, 4, 8, 9, 9, 8, 2, 10, 1, 2, 8, 9, 1, 9, 9, 9, 7, 12, 12, 8, 1, 1, 1, 1, 8, 3, 1, 1, 8, 1, 8, 8, 7, 8, 8, 8, 8, 3, 2, 2, 10, 10, 10, 7, 8, 1, 2, 12, 7, 9, 8, 7, 8, 12, 2, 8, 9, 2, 6, 6, 7, 9, 8, 1, 8, 9, 8, 1, 12, 1, 2, 8, 7, 7, 7, 8, 2, 2, 8, 1, 2, 2, 9, 9, 1, 8, 8, 4, 3, 3, 1, 6, 3, 3, 12, 3, 8, 9, 1, 4, 3, 1, 8, 3, 9, 2, 8, 2, 8, 8, 8, 1, 1, 1, 9, 9, 8, 1, 9, 8, 1, 1, 3, 10, 8, 1, 1, 3, 9, 1, 4, 4, 1, 8, 9, 9, 2, 0, 0, 1, 8, 3, 1, 8, 8, 9, 8, 8, 1, 1, 8, 9, 8, 8, 8, 7, 9, 8, 8, 8, 10, 9, 8, 1, 2, 6, 1, 9, 9, 8, 12, 12, 12, 8, 8, 2, 8, 1, 2, 2, 2, 1, 9, 8, 2, 12, 2, 8, 12, 8, 9, 8, 8, 9, 7, 1, 1, 1, 1, 1, 8, 8, 1, 8, 8, 1, 1, 3, 2, 8, 8, 9, 10, 10, 2, 2, 1, 9, 2, 9, 9, 4, 12, 12, 12, 10, 7, 3, 3, 4, 2, 2, 9, 2, 8, 4, 2, 4, 1, 10, 9, 7, 8, 7, 1, 1, 3, 3, 1, 1, 3, 3, 3, 1, 1, 1, 1, 8, 2, 3, 1, 1, 2, 8, 8, 12, 8, 8, 8, 8, 11, 9, 1, 8, 9, 2, 8, 8, 8, 3, 9, 1, 9, 2, 7, 2, 8, 2, 8, 10, 8, 1, 10, 1, 1, 9, 9, 8, 8, 1, 8, 8, 8, 12, 8, 8, 8, 1, 8, 8, 8, 1, 9, 1, 1, 8, 1, 8, 9, 8, 2, 12, 9, 9, 0, 1, 8, 8, 1, 8, 12, 8, 8, 10, 8, 8, 8, 7, 8, 1, 8, 7, 3, 10, 1, 8, 9, 1, 8, 8, 8, 10, 1, 10, 3, 9, 1, 8, 9, 2, 8, 3, 3, 9, 9, 7, 9, 1, 1, 9, 2, 1, 1, 1, 7, 1, 1, 8, 8, 1, 1, 8, 1, 8, 3, 12, 9, 3, 3, 8, 8, 8, 8, 3, 1, 3, 3, 1, 11, 0, 8, 8, 7, 8, 12, 1, 8, 9, 8, 9, 8, 8, 3, 8, 8, 1, 1, 1, 9, 2, 2, 2, 8, 7, 12, 8, 8, 9, 10, 10, 7, 8, 1, 9, 8, 7, 3, 1, 3, 8, 2, 2, 3, 9, 8, 4, 4, 8, 9, 2, 1, 1, 7, 8, 9, 9, 7, 8, 7, 7, 8, 2, 2, 8, 4, 9, 7, 10, 0, 9, 8, 3, 7, 8, 1, 1, 8, 9, 9, 2, 2, 10, 1, 9, 10, 10, 10, 8, 3, 2, 12, 9, 9, 10, 12, 9, 12, 12, 9, 1, 2, 4, 12, 12, 7, 8, 9, 7, 7, 7, 3, 9, 8, 9, 1, 12, 8, 9, 4, 1, 3, 12, 12, 12, 12, 8, 8, 2, 1, 1, 2, 1, 1, 1, 12, 12, 8, 12, 2, 2, 12, 3, 3, 12, 8, 2, 8, 8, 12, 2, 1, 10, 3, 2, 8, 7, 1, 8, 1, 3, 7, 8, 9, 8, 3, 1, 1, 7, 8, 8, 9, 8, 2, 9, 2, 2, 9, 8, 1, 8, 8, 1, 3, 3, 1, 1, 10, 1, 2, 8, 1, 1, 1, 1, 9, 1, 4, 1, 7, 7, 7, 7, 2, 2, 8, 8, 12, 1, 9, 1, 7, 3, 3, 1, 8, 8, 10, 8, 9, 2, 9, 1, 3, 8, 8, 3, 12, 2, 8, 12, 2, 9, 1, 3, 3, 3, 3, 2, 8, 7, 9, 8, 3, 3, 1, 7, 8, 3, 1, 1, 12, 8, 9, 1, 2, 3, 8, 1, 1, 3, 3, 9, 1, 1, 1, 12, 1, 7, 3, 3, 1, 8, 8, 8, 1, 2, 4, 8, 1, 10, 2, 5, 3, 3, 12, 10, 9, 9, 12, 9, 0, 2, 8, 8, 9, 9, 9, 8, 1, 3, 1, 1, 4, 8, 1, 10, 8, 7, 2, 8, 2, 8, 4, 7, 8, 1, 9, 1, 9, 8, 2, 8, 2, 7, 9, 2, 2, 9, 1, 8, 12, 1, 8, 1, 4, 1, 9, 9, 1, 10, 12, 4, 8, 1, 7, 3, 9, 2, 12, 7, 8, 8, 2, 1, 12, 9, 8, 1, 2, 2, 8, 10, 2, 1, 7, 7, 7, 12, 3, 3, 8, 3, 8, 8, 3, 9, 8, 9, 1, 1, 8, 7, 9, 3, 3, 8, 1, 0, 9, 9, 9, 1, 8, 9, 9, 10, 1, 8, 7, 8, 8, 8, 9, 9, 8, 9, 10, 4, 9, 3, 7, 12, 1, 9, 9, 8, 9, 1, 9, 3, 1, 8, 4, 12, 10, 9, 8, 7, 10, 8, 12, 12, 3, 10, 8, 12, 2, 1, 2, 3, 9, 8, 8, 7, 1, 1, 2, 2, 1, 2, 2, 7, 1, 3, 9, 9, 3, 8, 8, 8, 8, 8, 7, 8, 8, 10, 8, 1, 8, 2, 8, 2, 2, 2, 2, 2, 1, 7, 12, 10, 1, 2, 8, 1, 4, 7, 8, 1, 12, 8, 7, 9, 2, 2, 2, 8, 1, 8, 1, 1, 0, 2, 2, 6, 1, 8, 2, 1, 8, 1, 1, 2, 2, 3, 2, 2, 10, 10, 9, 1, 7, 7, 8, 8, 1, 12, 10, 12, 3, 8, 8, 8, 3, 8, 3, 10, 2, 2, 2, 1, 2, 2, 1, 0, 1, 8, 9, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 12, 9, 9, 1, 10, 11, 12, 9, 1, 1, 8, 8, 1, 2, 12, 8, 3, 7, 2, 10, 9, 7, 8, 1, 2, 2, 7, 9, 12, 2, 2, 1, 8, 9, 2, 3, 2, 2, 2, 9, 9, 8, 9, 2, 3, 8, 8, 9, 7, 3, 10, 8, 8, 9, 1, 1, 2, 8, 1, 10, 8, 8, 9, 7, 1, 7, 12, 8, 1, 7, 2, 1, 3, 9, 2, 8, 8, 1, 2, 3, 9, 3, 8, 9, 7, 7, 1, 10, 2, 8, 8, 8, 1, 8, 2, 8, 8, 1, 2, 8, 10, 2, 1, 0, 8, 3, 8, 10, 10, 12, 3, 8, 9, 3, 10, 8, 8, 8, 1, 8, 8, 2, 2, 2, 2, 2, 2, 1, 1, 10, 1, 10, 8, 2, 1, 2, 2, 8, 3, 3, 2, 2, 1, 8, 1, 3, 1, 9, 2, 2, 1, 3, 2, 2, 3, 2, 2, 3, 2, 1, 1, 2, 1, 2, 7, 8, 2, 1, 12, 12, 3, 1, 9, 9, 7, 8, 7, 2, 7, 9, 2, 2, 2, 8, 9, 7, 9, 2, 8, 9, 9, 2, 9, 1, 1, 9, 8, 3, 3, 8, 2, 7, 8, 11, 2, 8, 9, 1, 8, 3, 1, 2, 1, 2, 2, 2, 2, 8, 3, 9, 2, 10, 9, 9, 2, 7, 7, 7, 1, 3, 8, 8, 1, 1, 8, 7, 1, 8, 8, 9, 3, 3, 3, 2, 4, 8, 12, 8, 1, 12, 9, 2, 8, 2, 12, 2, 1, 3, 8, 12, 12, 11, 8, 10, 9, 2, 9, 4, 10, 1, 12, 12, 9, 3, 8, 9, 12, 9, 9, 2, 2, 2, 3, 5, 1, 1, 1, 7, 7, 8, 2, 2, 8, 2, 1, 7, 3, 2, 9, 8, 9, 1, 1, 9, 8, 9, 3, 3, 2, 9, 4, 9, 8, 8, 1, 8, 10, 2, 0, 3, 8, 8, 8, 9, 12, 9, 8, 2, 2, 8, 10, 9, 8, 2, 2, 4, 1, 9, 9, 8, 8, 10, 3, 1, 1, 2, 8, 7, 8, 2, 1, 1, 8, 12, 2, 9, 4, 8, 3, 3, 3, 8, 2, 12, 12, 8, 9, 12, 8, 2, 12, 7, 9, 2, 2, 1, 3, 1, 3, 11, 9, 8, 1, 10, 2, 12, 3, 8, 4, 1, 2, 8, 8, 3, 9, 3, 8, 7, 1, 1, 3, 1, 8, 2, 9, 8, 12, 1, 1, 1, 9, 9, 1, 8, 8, 8, 2, 2, 12, 3, 1, 1, 1, 9, 9, 3, 2, 1, 1, 9, 9, 1, 9, 9, 1, 9, 3, 9, 1, 8, 1, 9, 8, 3, 8, 8, 9, 9, 8, 2, 8, 1, 2, 2, 10, 1, 2, 1, 1, 9, 1, 9, 3, 7, 7, 2, 10, 3, 3, 1, 1, 9, 1, 2, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 8, 8, 7, 1, 1, 8, 8, 2, 1, 12, 1, 8, 1, 9, 8, 8, 2, 1, 9, 9, 2, 2, 8, 1, 7, 7, 9, 8, 1, 6, 8, 8, 2, 2, 8, 3, 8, 3, 2, 3, 8, 1, 2, 2, 2, 8, 9, 9, 9, 12, 1, 9, 2, 1, 9, 2, 9, 9, 10, 8, 1, 1, 9, 2, 1, 7, 1, 3, 7, 1, 1, 1, 3, 8, 8, 8, 9, 9, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 1, 1, 1, 2, 2, 3, 1, 1, 2, 3, 3, 3, 7, 3, 1, 9, 3, 9, 1, 4, 1, 1, 9, 10, 9, 8, 2, 3, 10, 9, 3, 10, 12, 8, 9, 8, 2, 1, 9, 8, 1, 7, 8, 1, 9, 1, 2, 10, 7, 7, 8, 1, 3, 3, 9, 3, 3, 1, 1, 1, 9, 1, 3, 8, 8, 8, 1, 8, 1, 9, 7, 8, 8, 2, 1, 3, 8, 2, 1, 6, 1, 8, 8, 2, 8, 2, 2, 9, 8, 1, 1, 6, 8, 6, 10, 2, 1, 1, 8, 9, 3, 3, 3, 1, 3, 9, 6, 8, 1, 8, 3, 1, 2, 2, 12, 7, 1, 1, 1, 1, 12, 1, 8, 8, 3, 2, 1, 9, 2, 3, 3, 2, 2, 7, 2, 2, 2, 3, 1, 9, 8, 7, 1, 1, 3, 1, 9, 4, 3, 9, 2, 1, 1, 9, 8, 8, 7, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 10, 1, 1, 8, 2, 8, 1, 8, 1, 3, 1, 2, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 8, 1, 9, 8, 8, 1, 10, 8, 8, 1, 3, 9, 8, 9, 8, 2, 1, 3, 4, 1, 12, 1, 9, 8, 2, 7, 2, 1, 2, 9, 2, 1, 3, 8, 1, 2, 3, 8, 2, 10, 10, 10, 9, 9, 9, 3, 8, 3, 1, 1, 1, 1, 1, 1, 2, 1, 9, 2, 7, 9, 8, 7, 9, 1, 1, 1, 1, 8, 2, 2, 3, 3, 2, 12, 8, 3, 1, 1, 12, 9, 8, 2, 2, 9, 1, 2, 2, 9, 1, 1, 2, 4, 8, 1, 8, 10, 2, 9, 9, 9, 1, 2, 1, 1, 2, 2, 2, 12, 1, 2, 8, 3, 9, 9, 3, 2, 9, 9, 7, 2, 8, 8, 9, 2, 9, 1, 1, 1, 1, 1, 2, 8, 2, 1, 2, 2, 8, 3, 1, 1, 9, 1, 3, 10, 7, 9, 8, 8, 2, 2, 9, 2, 2, 2, 2, 2, 2, 9, 1, 3, 6, 4, 2, 2, 9, 1, 9, 8, 1, 1, 1, 7, 3, 2, 9, 9, 1, 9, 7, 2, 8, 9, 9, 12, 10, 8, 10, 2, 3, 1, 2, 2, 12, 12, 3, 12, 1, 2, 1, 2, 1, 2, 8, 2, 3, 12, 12, 8, 2, 2, 9, 2, 9, 2, 3, 3, 1, 1, 1, 12, 3, 7, 1, 3, 1, 2, 9, 2, 7, 2, 1, 8, 3, 7, 8, 1, 1, 3, 8, 3, 2, 9, 3, 1, 1, 1, 1, 11, 1, 2, 6, 1, 2, 3, 8, 9, 9, 2, 9, 2, 1, 1, 3, 1, 12, 9, 1, 1, 9, 1, 9, 9, 8, 9, 8, 1, 2, 7, 1, 0, 9, 8, 2, 3, 2, 4, 1, 1, 1, 8, 1, 12, 1, 2, 3, 3, 9, 9, 9, 9, 9, 7, 9, 3, 9, 1, 7, 3, 3, 3, 3, 7, 8, 2, 2, 2, 8, 2, 3, 9, 9, 3, 1, 8, 9, 12, 8, 8, 3, 2, 1, 6, 1, 9, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 9, 2, 5, 3, 2, 2, 8, 2, 1, 8, 3, 3, 8, 3, 1, 3, 9, 2, 8, 9, 4, 4, 9, 8, 8, 7, 7, 3, 1, 8, 8, 3, 2, 2, 10, 3, 3, 2, 2, 2, 2, 12, 3, 1, 2, 7, 7, 12, 2, 1, 2, 1, 1, 2, 1, 3, 3, 3, 1, 3, 9, 4, 8, 8, 4, 2, 4, 2, 8, 9, 1, 1, 2, 2, 2, 8, 7, 2, 8, 2, 9, 1, 8, 1, 1, 2, 1, 1, 1, 2, 9, 9, 8, 1, 8, 1, 4, 8, 1, 2, 7, 9, 2, 1, 8, 9, 8, 9, 1, 1, 2, 3, 2, 12, 7, 1, 2, 4, 4, 4, 2, 2, 2, 9, 8, 8, 1, 12, 3, 3, 2, 2, 3, 12, 1, 5, 1, 1, 3, 2, 8, 8, 2, 2, 2, 3, 9, 8, 8, 9, 8, 8, 11, 8, 2, 9, 2, 3, 1, 7, 1, 8, 2, 8, 1, 1, 1, 8, 1, 1, 1, 7, 8, 8, 2, 3, 2, 1, 8, 8, 1, 8, 4, 8, 9, 8, 9, 8, 1, 2, 3, 2, 1, 2, 2, 3, 1, 9, 4, 8, 1, 1, 9, 1, 1, 8, 2, 2, 2, 1, 7, 3, 3, 1, 3, 3, 12, 3, 1, 1, 3, 1, 1, 4, 8, 4, 4, 3, 3, 3, 4, 8, 1, 9, 9, 9, 4, 1, 7, 4, 8, 4, 9, 8, 1, 1, 3, 8, 9, 1, 9, 7, 1, 1, 9, 1, 8, 8, 8, 1, 1, 8, 2, 2, 2, 9, 4, 4, 1, 2, 1, 2, 9, 1, 1, 8, 5, 5, 5, 9, 12, 4, 1, 2, 1, 8, 8, 1, 9, 9, 2, 12, 1, 1, 7, 8, 8, 4, 1, 2, 8, 11, 2, 3, 2, 2, 1, 11, 2, 2, 2, 2, 9, 9, 2, 2, 9, 3, 1, 9, 1, 1, 1, 7, 8, 1, 8, 9, 1, 2, 9, 8, 1, 2, 9, 8, 12, 2, 2, 10, 8, 2, 2, 8, 8, 1, 2, 6, 1, 1, 7, 7, 2, 3, 2, 1, 1, 8, 1, 10, 8, 12, 6, 4, 1, 4, 1, 2, 9, 8, 9, 4, 8, 8, 10, 8, 8, 8, 8, 8, 2, 2, 8, 4, 9, 3, 3, 3, 3, 3, 9, 2, 1, 1, 2, 3, 2, 1, 2, 3, 3, 3, 2, 2, 3, 3, 2, 1, 2, 3, 3, 3, 3, 12, 9, 3, 2, 2, 3, 1, 5, 1, 1, 3, 2, 2, 1, 2, 9, 3, 9, 8, 1, 8, 7, 7, 9, 1, 1, 7, 9, 10, 1, 7, 1, 4, 3, 8, 9, 4, 9, 9, 2, 9, 2, 8, 4, 2, 2, 9, 5, 2, 1, 10, 9, 3, 1, 1, 1, 2, 1, 2, 9, 1, 7, 9, 9, 8, 2, 2, 8, 9, 1, 9, 8, 2, 3, 2, 2, 1, 2, 2, 2, 1, 1, 8, 1, 9, 4, 12, 8, 2, 7, 2, 2, 1, 9, 3, 1, 8, 12, 1, 1, 2, 1, 10, 2, 6, 12, 12, 4, 9, 1, 9, 10, 1, 2, 8, 2, 1, 8, 6, 12, 9, 9, 2, 1, 7, 8, 9, 5, 8, 1, 8, 8, 3, 1, 8, 2, 8, 2, 2, 1, 2, 9, 2, 8, 1, 12, 8, 2, 7, 3, 3, 12, 2, 3, 3, 9, 9, 3, 3, 3, 3, 3, 2, 1, 4, 1, 4, 8, 8, 2, 1, 2, 9, 12, 1, 10, 12, 1, 2, 9, 4, 8, 10, 3, 2, 8, 7, 4, 8, 9, 2, 7, 1, 10, 2, 2, 2, 8, 4, 2, 2, 1, 1, 8, 7, 9, 2, 1, 9, 8, 9, 12, 4, 8, 2, 8, 7, 7, 1, 9, 2, 1, 1, 9, 1, 8, 2, 3, 9, 9, 1, 3, 2, 9, 2, 2, 8, 1, 1, 2, 1, 2, 1, 9, 8, 2, 2, 4, 8, 8, 9, 5, 5, 9, 8, 9, 6, 2, 1, 12, 2, 3, 8, 8, 9, 2, 2, 1, 3, 2, 10, 9, 10, 7, 2, 8, 4, 2, 8, 9, 8, 1, 3, 8, 8, 1, 8, 3, 8, 8, 1, 10, 3, 1, 5, 8, 8, 9, 2, 2, 9, 2, 1, 9, 1, 4, 1, 12, 8, 8, 2, 1, 1, 1, 1, 1, 9, 2, 9, 8, 9, 5, 9, 1, 8, 2, 4, 1, 1, 1, 9, 12, 4, 1, 1, 9, 8, 4, 1, 8, 9, 8, 8, 9, 9, 9, 9, 9, 9, 1, 3, 4, 2, 2, 8, 2, 9, 2, 3, 8, 3, 1, 7, 2, 1, 1, 4, 2, 9, 2, 1, 3, 2, 9, 2, 9, 3, 8, 1, 9, 1, 1, 2, 8, 8, 8, 2, 3, 9, 9, 8, 2, 4, 1, 5, 1, 1, 9, 9, 2, 1, 1, 1, 9, 9, 1, 3, 9, 2, 2, 9, 9, 8, 3, 9, 9, 8, 2, 2, 8, 9, 2, 2, 8, 9, 10, 10, 2, 8, 7, 9, 9, 4, 2, 4, 11, 2, 1, 7, 8, 8, 8, 9, 4, 9, 8, 8, 2, 1, 1, 9, 8, 3, 3, 8, 8, 7, 9, 1, 3, 4, 8, 10, 2, 4, 4, 8, 2, 8, 2, 8, 9, 2, 1, 2, 2, 3, 1, 9, 4, 5, 9, 9, 1, 1, 1, 1, 1, 1, 7, 1, 1, 1, 8, 1, 1, 1, 1, 1, 9, 1, 2, 1, 12, 9, 3, 9, 9, 4, 1, 9, 1, 1, 2, 11, 9, 3, 2, 2, 2, 4, 2, 3, 2, 7, 7, 8, 1, 10, 9, 5, 7, 1, 10, 8, 1, 2, 7, 1, 12, 5, 8, 4, 2, 9, 9, 8, 2, 9, 8, 8, 10, 2, 3, 2, 7, 2, 8, 10, 3, 2, 9, 9, 9, 1, 1, 1, 1, 8, 2, 10, 9, 8, 1, 2, 2, 2, 1, 2, 1, 3, 9, 12, 2, 2, 4, 8, 1, 3, 9, 4, 9, 1, 9, 9, 2, 1, 1, 9, 7, 10, 3, 10, 2, 9, 2, 9, 2, 8, 2, 1, 2, 3, 1, 1, 1, 8, 5, 8, 3, 1, 1, 4, 2, 2, 1, 3, 8, 2, 1, 1, 1, 2, 9, 4, 1, 8, 1, 2, 8, 2, 9, 2, 2, 5, 5, 2, 5, 2, 1, 8, 8, 1, 3, 12, 2, 4, 3, 2, 2, 2, 6, 2, 3, 3, 1, 8, 2, 2, 1, 1, 8, 8, 10, 1, 9, 2, 9, 12, 0, 2, 1, 3, 2, 2, 1, 2, 1, 9, 9, 2, 9, 8, 8, 1, 7, 8, 1, 2, 6, 9, 8, 10, 1, 12, 2, 2, 1, 8, 2, 1, 12, 7, 4, 2, 10, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 9, 8, 10, 2, 10, 9, 9, 12, 5, 3, 2, 8, 2, 8, 3, 3, 1, 4, 9, 10, 2, 4, 8, 1, 2, 10, 12, 12, 3, 1, 1, 2, 9, 6, 6, 1, 9, 1, 8, 1, 8, 8, 8, 8, 2, 2, 2, 8, 8, 2, 1, 1, 1, 1, 1, 8, 8, 5, 8, 8, 1, 8, 9, 9, 1, 7, 12, 9, 9, 7, 2, 2, 7, 8, 9, 8, 2, 9, 6, 3, 4, 8, 4, 1, 2, 9, 8, 8, 8, 2, 1, 1, 8, 8, 3, 1, 9, 9, 7, 1, 2, 2, 2, 9, 4, 1, 2, 12, 1, 8, 2, 1, 9, 1, 8, 9, 9, 2, 5, 4, 2, 1, 2, 8, 12, 8, 10, 3, 8, 8, 8, 2, 2, 8, 2, 8, 2, 4, 8, 10, 2, 7, 2, 1, 8, 8, 9, 5, 8, 1, 12, 7, 10, 2, 2, 2, 1, 4, 8, 12, 1, 8, 2, 2, 9, 1, 8, 3, 1, 1, 5, 10, 2, 1, 2, 4, 8, 9, 3, 2, 8, 7, 4, 4, 9, 9, 2, 8, 1, 1, 2, 4, 7, 1, 9, 1, 1, 1, 8, 4, 1, 3, 1, 2, 2, 9, 1, 8, 8, 2, 2, 9, 9, 1, 8, 8, 1, 9, 8, 8, 2, 2, 2, 2, 1, 1, 1, 7, 4, 1, 1, 4, 2, 3, 3, 2, 3, 9, 2, 8, 2, 1, 5, 1, 2, 2, 1, 3, 5, 2, 9, 1, 1, 9, 8, 1, 4, 8, 1, 8, 2, 4, 8, 4, 7, 9, 8, 1, 2, 2, 4, 4, 11, 3, 11, 1, 3, 8, 1, 9, 6, 8, 9, 3, 9, 8, 9, 2, 3, 3, 7, 1, 7, 2, 9, 9, 1, 8, 8, 1, 5, 5, 8, 8, 1, 2, 1, 3, 9, 9, 5, 9, 8, 1, 4, 3, 8, 1, 1, 2, 1, 8, 9, 8, 2, 2, 2, 1, 2, 4, 10, 8, 1, 9, 1, 8, 1, 1, 9, 9, 8, 11, 1, 8, 2, 1, 2, 8, 2, 8, 8, 2, 9, 6, 10, 1, 8, 6, 4, 5, 11, 2, 2, 8, 1, 8, 1, 8, 1, 4, 8, 1, 1, 1, 8, 3, 7, 3, 3, 7, 1, 1, 4, 8, 1, 6, 4, 2, 2, 1, 1, 1, 1, 6, 2, 2, 8, 1, 8, 5, 5, 2, 1, 1, 2, 3, 7, 1, 1, 6, 2, 9, 3, 9, 8, 9, 2, 1, 4, 2, 9, 13, 9, 2, 8, 12, 4, 1, 1, 9, 5, 1, 1, 1, 1, 8, 2, 1, 1, 2, 9, 0, 12, 1, 1, 8, 9, 8, 3, 2, 2, 12, 8, 2, 2, 2, 1, 10, 1, 9, 8, 9, 5, 2, 2, 9, 2, 8, 4, 8, 3, 7, 9, 2, 2, 7, 2, 2, 8, 1, 1, 9, 10, 9, 8, 2, 9, 0, 7, 1, 1, 1, 9, 8, 2, 8, 12, 8, 3, 2, 8, 8, 7, 7, 8, 12, 2, 1, 3, 9, 2, 2, 8, 2, 8, 8, 12, 8, 8, 1, 8, 9, 2, 4, 4, 7, 2, 1, 1, 9, 3, 7, 1, 3, 9, 8, 2, 2, 3, 1, 3, 10, 2, 3, 7, 1, 8, 1, 1, 10, 3, 10, 8, 4, 1, 2, 4, 3, 10, 9, 3, 9, 5, 8, 7, 2, 9, 3, 3, 2, 11, 8, 1, 1, 7, 2, 7, 2, 9, 4, 8, 1, 12, 8, 7, 9, 1, 0, 2, 6, 4, 9, 3, 2, 4, 12, 9, 8, 5, 9, 2, 8, 4, 6, 8, 9, 3, 1, 8, 7, 3, 1, 1, 1, 8, 9, 1, 8, 7, 9, 8, 2, 1, 2, 2, 3, 2, 2, 1, 1, 4, 9, 7, 3, 2, 8, 8, 9, 1, 9, 7, 4, 2, 2, 8, 5, 9, 1, 5, 7, 1, 4, 6, 9, 10, 1, 8, 2, 9, 1, 9, 2, 9, 8, 2, 9, 9, 11, 2, 12, 2, 2, 9, 4, 8, 1, 9, 9, 2, 8, 9, 1, 2, 9, 3, 8, 8, 1, 7, 8, 8, 2, 3, 2, 2, 2, 2, 9, 8, 10, 2, 2, 1, 9, 11, 1, 8, 8, 2, 4, 2, 1, 2, 8, 8, 9, 2, 8, 9, 2, 3, 1, 2, 1, 3, 10, 8, 1, 2, 4, 1, 9, 8, 9, 3, 3, 9, 8, 2, 11, 3, 7, 1, 8, 7, 1, 8, 8, 8, 1, 4, 8, 8, 1, 9, 3, 1, 1, 2, 8, 8, 8, 2, 1, 8, 10, 2, 12, 8, 8, 9, 1, 8, 1, 3, 2, 2, 10, 7, 2, 2, 1, 1, 8, 2, 9, 1, 2, 9, 3, 3, 10, 1, 4, 7, 10, 12, 2, 4, 10, 8, 6, 2, 9, 1, 8, 3, 1, 2, 8, 8, 2, 12, 10, 2, 10, 9, 1, 2, 5, 8, 12, 8, 8, 7, 8, 8, 1, 8, 2, 2, 9, 1, 8, 10, 5, 5, 5, 8, 1, 9, 1, 13, 1, 2, 2, 1, 2, 4, 9, 2, 1, 9, 13, 11, 1, 9, 9, 3, 10, 8, 7, 8, 8, 4, 2, 1, 9, 4, 3, 1, 1, 10, 9, 2, 8, 6, 2, 1, 1, 3, 2, 8, 1, 1, 1, 1, 2, 4, 1, 1, 10, 1, 8, 1, 1, 9, 1, 7, 1, 1, 9, 9, 2, 12, 9, 1, 8, 1, 12, 1, 8, 3, 8, 1, 8, 1, 2, 10, 1, 1, 2, 2, 9, 3, 9, 12, 1, 9, 1, 2, 8, 7, 2, 1, 1, 3, 2, 8, 4, 4, 5, 12, 7, 8, 9, 6, 1, 8, 9, 2, 1, 9, 1, 4, 1, 8, 2, 1, 1, 8, 7, 4, 9, 1, 8, 4, 2, 7, 5, 1, 3, 9, 2, 8, 2, 1, 2, 9, 1, 1, 2, 3, 4, 3, 1, 2, 2, 10, 2, 2, 8, 1, 1, 2, 4, 9, 2, 11, 9, 8, 9, 2, 1, 10, 4, 1, 1, 10, 7, 2, 10, 8, 1, 10, 8, 8, 8, 8, 8, 8, 2, 2, 2, 8, 3, 4, 1, 1, 1, 2, 1, 8, 8, 2, 8, 3, 8, 3, 1, 2, 3, 1, 1, 10, 1, 4, 4, 3, 3, 1, 9, 1, 1, 2, 1, 1, 6, 1, 1, 1, 9, 1, 4, 1, 1, 1, 1, 1, 1, 2, 12, 8, 8, 1, 9, 12, 10, 8, 2, 12, 1, 1, 2, 1, 7, 10, 7, 1, 2, 1, 10, 8, 2, 2, 8, 2, 2, 1, 9, 8, 8, 8, 8, 3, 1, 4, 2, 8, 3, 10, 10, 1, 9, 1, 9, 1, 9, 1, 8, 3, 1, 1, 8, 8, 8, 6, 3, 4, 1, 1, 1, 9, 9, 5, 2, 10, 2, 6, 2, 2, 7, 1, 8, 2, 11, 1, 1, 1, 2, 1, 9, 4, 4, 2, 8, 4, 6, 8, 8, 10, 10, 2, 1, 2, 9, 1, 8, 8, 3, 4, 8, 8, 2, 8, 8, 1, 2, 1, 2, 9, 4, 1, 3, 3, 3, 8, 8, 8, 2, 6, 4, 3, 3, 12, 3, 4, 9, 6, 8, 7, 7, 8, 6, 4, 1, 10, 6, 3, 3, 8, 1, 1, 8, 1, 11, 8, 1, 1, 2, 3, 11, 7, 2, 1, 1, 1, 9, 1, 2, 1, 1, 9, 8, 1, 1, 8, 0, 4, 1, 1, 2, 1, 1, 2, 2, 9, 1, 10, 1, 3, 8, 9, 3, 3, 1, 10, 1, 9, 1, 1, 7, 4, 1, 8, 10, 1, 2, 10, 1, 1, 2, 3, 3, 9, 1, 8, 10, 1, 7, 9, 1, 9, 6, 3, 9, 2, 8, 4, 12, 12, 3, 1, 1, 9, 1, 9, 2, 1, 1, 1, 1, 1, 9, 2, 1, 2, 10, 9, 8, 8, 10, 8, 2, 3, 2, 1, 12, 8, 12, 2, 9, 1, 3, 2, 5, 2, 2, 8, 2, 2, 4, 10, 9, 10, 9, 4, 2, 4, 12, 8, 2, 1, 8, 3, 9, 2, 9, 4, 1, 1, 1, 1, 1, 9, 6, 2, 9, 2, 1, 3, 2, 2, 5, 8, 9, 1, 6, 3, 1, 2, 2, 2, 6, 1, 8, 10, 8, 3, 3, 13, 2, 9, 9, 10, 6, 12, 8, 2, 9, 2, 3, 8, 8, 1, 2, 2, 3, 2, 10, 1, 8, 9, 1, 8, 9, 8, 8, 2, 10, 2, 1, 1, 1, 9, 9, 12, 1, 1, 4, 8, 3, 2, 2, 4, 4, 2, 2, 1, 1, 1, 9, 2, 2, 4, 1, 1, 8, 8, 8, 9, 2, 13, 9, 9, 4, 1, 9, 7, 10, 10, 8, 1, 9, 1, 1, 1, 8, 12, 4, 1, 2, 1, 1, 1, 7, 8, 3, 3, 1, 2, 2, 7, 2, 2, 10, 1, 8, 4, 0, 1, 9, 4, 1, 1, 2, 10, 10, 7, 9, 3, 12, 11, 2, 8, 10, 8, 9, 4, 3, 4, 10, 1, 1, 9, 3, 10, 1, 5, 3, 3, 2, 2, 1, 1, 6, 1, 7, 1, 1, 12, 1, 1, 1, 10, 1, 8, 8, 1, 3, 8, 3, 1, 2, 8, 3, 4, 2, 8, 8, 6, 1, 1, 4, 1, 2, 9, 5, 1, 7, 8, 9, 2, 4, 9, 8, 5, 9, 9, 9, 1, 2, 1, 3, 8, 9, 2, 9, 8, 9, 1, 8, 13, 9, 3, 8, 1, 4, 1, 3, 1, 6, 4, 10, 2, 2, 7, 8, 8, 12, 8, 9, 9, 9, 10, 3, 12, 12, 2, 9, 10, 9, 7, 2, 3, 4, 10, 10, 2, 7, 7, 1, 7, 3, 9, 1, 9, 8, 2, 9, 1, 8, 1, 10, 8, 8, 2, 7, 8, 1, 8, 9, 8, 1, 4, 1, 8, 8, 8, 1, 1, 10, 3, 2, 2, 6, 8, 9, 8, 2, 1, 1, 3, 8, 8, 1, 4, 4, 3, 9, 10, 4, 2, 4, 2, 9, 2, 2, 9, 1, 1, 10, 1, 1, 2, 1, 1, 1, 9, 1, 8, 8, 8, 2, 3, 8, 1, 6, 7, 3, 1, 9, 1, 2, 1, 6, 1, 2, 10, 1, 4, 2, 3, 2, 9, 9, 4, 9, 9, 1, 2, 8, 4, 7, 8, 7, 13, 9, 1, 2, 1, 9, 3, 3, 6, 8, 9, 10, 9, 2, 2, 3, 12, 1, 1, 1, 13, 2, 1, 7, 10, 8, 9, 1, 2, 9, 1, 1, 1, 2, 1, 12, 5, 6, 9, 10, 3, 1, 10, 1, 3, 2, 8, 9, 2, 10, 8, 8, 9, 2, 8, 9, 2, 2, 2, 8, 8, 2, 3, 1, 4, 8, 1, 9, 9, 2, 8, 10, 9, 1, 2, 12, 8, 8, 0, 2, 1, 1, 9, 10, 1, 6, 2, 2, 10, 2, 2, 4, 2, 2, 12, 1, 6, 7, 8, 9, 1, 3, 5, 7, 3, 1, 3, 1, 1, 3, 2, 6, 3, 2, 1, 8, 3, 5, 2, 1, 1, 8, 1, 1, 0, 2, 3, 5, 3, 1, 1, 9, 8, 8, 8, 8, 4, 7, 2, 9, 12, 5, 9, 3, 12, 3, 9, 1, 9, 1, 7, 3, 9, 3, 10, 1, 2, 1, 4, 9, 8, 2, 9, 11, 2, 8, 9, 4, 1, 1, 1, 1, 1, 1, 1, 9, 1, 9, 1, 1, 1, 12, 3, 10, 3, 6, 1, 7, 10, 8, 3, 7, 1, 1, 2, 6, 1, 3, 9, 2, 8, 1, 8, 8, 1, 8, 10, 12, 1, 10, 12, 10, 1, 8, 8, 1, 4, 7, 9, 2, 1, 9, 3, 8, 12, 10, 6, 1, 6, 8, 3, 1, 3, 1, 10, 10, 9, 8, 1, 2, 9, 8, 8, 1, 9, 8, 8, 3, 1, 3, 9, 12, 1, 8, 1, 5, 8, 11, 5, 5, 1, 2, 1, 3, 1, 1, 1, 9, 8, 8, 1, 9, 10, 8, 4, 1, 1, 8, 10, 8, 9, 1, 10, 1, 7, 2, 1, 1, 9, 6, 2, 9, 8, 1, 1, 1, 9, 8, 8, 1, 9, 9, 1, 1, 2, 7, 9, 2, 9, 9, 8, 7, 6, 8, 7, 8, 2, 9, 2, 1, 8, 8, 8, 2, 6, 3, 1, 8, 12, 12, 8, 7, 1, 2, 2, 7, 1, 9, 8, 1, 4, 1, 1, 8, 5, 8, 1, 8, 8, 8, 8, 1, 2, 11, 1, 1, 1, 2, 7, 1, 9, 2, 2, 2, 9, 8, 9, 2, 9, 1, 8, 1, 7, 11, 13, 1, 9, 8, 2, 2, 1, 2, 3, 10, 3, 10, 4, 3, 9, 1, 8, 1, 1, 13, 1, 1, 3, 8, 1, 2, 2, 2, 9, 4, 1, 8, 1, 9, 3, 6, 8, 5, 2, 8, 2, 8, 1, 9, 2, 2, 8, 1, 1, 4, 8, 9, 2, 2, 7, 1, 8, 12, 2, 12, 8, 2, 9, 9, 3, 8, 1, 1, 9, 9, 9, 2, 8, 1, 9, 1, 8, 9, 8, 2, 2, 4, 1, 9, 10, 10, 8, 8, 1, 1, 2, 1, 4, 1, 2, 1, 1, 3, 12, 8, 8, 8, 8, 10, 2, 8, 12, 1, 9, 9, 8, 9, 1, 2, 1, 8, 8, 8, 2, 8, 8, 3, 10, 8, 9, 1, 1, 1, 3, 4, 8, 10, 6, 3, 1, 3, 2, 8, 9, 3, 5, 4, 1, 5, 2, 9, 9, 9, 1, 1, 1, 9, 9, 6, 10, 9, 8, 12, 2, 9, 1, 2, 1, 1, 1, 8, 1, 12, 1, 12, 1, 9, 1, 8, 1, 2, 1, 2, 8, 8, 10, 1, 9, 1, 2, 2, 8, 8, 3, 12, 1, 11, 2, 10, 12, 11, 2, 1, 10, 1, 1, 9, 3, 10, 2, 7, 1, 8, 1, 9, 9, 2, 1, 3, 12, 5, 9, 9, 8, 1, 8, 8, 8, 1, 1, 3, 9, 8, 9, 8, 3, 10, 3, 7, 8, 9, 2, 3, 1, 9, 10, 9, 2, 8, 2, 6, 4, 1, 1, 3, 8, 2, 3, 9, 1, 2, 1, 8, 1, 2, 2, 2, 2, 9, 9, 4, 8, 9, 1, 1, 2, 9, 1, 5, 2, 9, 8, 10, 1, 2, 10, 8, 5, 6, 4, 8, 1, 1, 1, 8, 9, 2, 8, 8, 8, 12, 2, 2, 1, 8, 1, 2, 1, 9, 8, 8, 9, 1, 1, 8, 7, 1, 8, 0, 2, 3, 8, 1, 1, 8, 1, 1, 12, 3, 2, 10, 8, 10, 6, 1, 8, 8, 10, 8, 8, 1, 4, 8, 1, 2, 9, 8, 1, 1, 3, 3, 5, 1, 1, 2, 1, 2, 1, 9, 8, 3, 9, 8, 2, 10, 9, 1, 8, 1, 10, 9, 10, 1, 2, 3, 8, 1, 3, 1, 9, 9, 8, 1, 9, 8, 8, 9, 1, 9, 2, 8, 8, 2, 13, 8, 10, 8, 9, 3, 2, 1, 3, 1, 12, 10, 10, 1, 11, 1, 2, 4, 2, 10, 1, 8, 11, 1, 1, 1, 2, 2, 8, 2, 9, 8, 9, 9, 12, 8, 1, 9, 2, 4, 1, 8, 3, 9, 1, 6, 5, 8, 9, 3, 3, 2, 1, 1, 1, 8, 11, 1, 8, 7, 1, 11, 9, 1, 7, 9, 9, 8, 8, 8, 12, 8, 1, 2, 9, 8, 8, 2, 10, 9, 8, 8, 4, 10, 9, 8, 2, 10, 10, 2, 1, 2, 1, 2, 1, 4, 1, 7, 1, 1, 3, 12, 9, 8, 5, 9, 10, 1, 9, 9, 2, 7, 4, 1, 1, 8, 12, 8, 2, 2, 9, 4, 1, 1, 5, 9, 1, 8, 12, 8, 1, 1, 4, 9, 10, 2, 3, 1, 3, 3, 3, 8, 1, 2, 1, 2, 1, 2, 9, 1, 2, 8, 9, 4, 8, 8, 10, 2, 12, 5, 5, 1, 8, 1, 7, 8, 1, 1, 8, 9, 12, 4, 9, 3, 1, 2, 5, 9, 2, 1, 2, 2, 1, 2, 8, 1, 8, 8, 2, 2, 1, 8, 4, 1, 2, 10, 9, 10, 8, 1, 10, 4, 8, 8, 10, 2, 8, 1, 1, 3, 10, 1, 4, 2, 8, 3, 3, 2, 9, 8, 5, 5, 9, 3, 10, 8, 1, 2, 1, 2, 9, 1, 1, 2, 9, 9, 8, 8, 11, 9, 4, 1, 8, 2, 7, 1, 2, 8, 2, 9, 9, 8, 2, 9, 9, 8, 8, 1, 2, 8, 1, 1, 2, 9, 8, 1, 4, 9, 1, 8, 12, 1, 12, 2, 8, 2, 9, 1, 12, 1, 2, 9, 1, 1, 9, 3, 2, 9, 9, 2, 11, 8, 7, 9, 9, 9, 8, 8, 1, 2, 8, 1, 1, 4, 1, 2, 10, 1, 9, 2, 1, 1, 1, 9, 1, 13, 4, 3, 2, 1, 1, 2, 2, 7, 8, 7, 1, 1, 2, 8, 8, 3, 4, 8, 2, 10, 13, 8, 8, 9, 2, 2, 1, 1, 10, 4, 2, 7, 9, 8, 2, 1, 9, 8, 1, 1, 9, 8, 9, 8, 2, 8, 2, 2, 9, 2, 1, 9, 1, 2, 4, 8, 2, 1, 1, 8, 1, 4, 1, 9, 3, 9, 2, 7, 1, 9, 6, 1, 10, 2, 2, 2, 2, 2, 10, 10, 10, 9, 9, 9, 3, 12, 10, 1, 1, 10, 1, 1, 2, 2, 1, 2, 3, 12, 8, 8, 1, 2, 9, 9, 1, 1, 10, 8, 9, 8, 3, 1, 1, 3, 1, 10, 1, 1, 1, 4, 1, 1, 1, 7, 10, 2, 1, 8, 1, 9, 3, 1, 10, 8, 8, 1, 5, 9, 1, 2, 1, 8, 8, 1, 3, 1, 10, 2, 1, 1, 2, 8, 2, 5, 3, 5, 2, 1, 1, 9, 1, 7, 9, 9, 2, 8, 1, 12, 4, 1, 4, 9, 9, 4, 8, 1, 10, 10, 8, 8, 8, 9, 2, 3, 5, 1, 8, 1, 1, 1, 7, 10, 1, 4, 12, 3, 2, 2, 9, 1, 1, 1, 2, 8, 4, 1, 7, 3, 12, 8, 6, 2, 2, 7, 9, 11, 1, 10, 9, 1, 8, 12, 2, 11, 1, 2, 3, 1, 1, 1, 8, 9, 2, 2, 2, 2, 3, 3, 8, 10, 4, 1, 2, 9, 8, 2, 2, 9, 1, 8, 11, 4, 2, 8, 7, 1, 1, 7, 3, 9, 9, 4, 5, 8, 10, 2, 9, 9, 9, 8, 1, 9, 2, 2, 2, 1, 2, 9, 4, 3, 12, 4, 3, 2, 3, 8, 3, 10, 1, 10, 1, 1, 8, 10, 6, 8, 9, 9, 1, 2, 9, 2, 9, 3, 8, 1, 1, 12, 1, 5, 1, 10, 8, 10, 2, 7, 1, 1, 1, 1, 3, 2, 3, 5, 9, 1, 2, 1, 9, 8, 10, 9, 8, 1, 8, 1, 8, 2, 8, 1, 2, 8, 1, 2, 5, 8, 12, 2, 1, 1, 1, 1, 1, 8, 8, 2, 1, 4, 2, 8, 8, 8, 2, 9, 9, 11, 1, 2, 9, 3, 1, 1, 8, 9, 2, 4, 10, 1, 9, 8, 4, 9, 8, 10, 8, 8, 9, 2, 8, 9, 3, 3, 3, 4, 3, 2, 2, 10, 8, 2, 1, 5, 1, 9, 1, 1, 2, 1, 2, 3, 1, 1, 8, 8, 1, 10, 8, 8, 1, 6, 4, 8, 2, 5, 8, 1, 3, 8, 2, 8, 9, 1, 1, 8, 12, 10, 1, 5, 8, 2, 8, 10, 9, 9, 1, 6, 9, 1, 10, 8, 2, 9, 10, 1, 2, 1, 1, 8, 8, 3, 9, 8, 1, 10, 2, 8, 1, 10, 1, 5, 1, 1, 1, 5, 1, 1, 1, 4, 1, 1, 1, 8, 2, 8, 1, 8, 3, 8, 9, 1, 8, 1, 8, 1, 1, 2, 2, 1, 12, 9, 9, 1, 8, 2, 1, 2, 8, 1, 9, 1, 1, 2, 1, 2, 2, 2, 1, 9, 9, 8, 8, 1, 1, 9, 10, 8, 4, 3, 3, 4, 9, 1, 3, 3, 10, 2, 2, 1, 8, 4, 1, 9, 4, 1, 1, 9, 8, 10, 4, 9, 9, 8, 2, 1, 3, 4, 9, 3, 8, 9, 1, 1, 2, 1, 7, 8, 2, 9, 1, 9, 2, 6, 9, 10, 8, 1, 1, 5, 9, 5, 1, 9, 10, 9, 3, 3, 8, 8, 2, 9, 2, 8, 2, 1, 8, 5, 8, 3, 10, 1, 1, 2, 1, 8, 1, 4, 3, 2, 9, 4, 9, 8, 8, 8, 1, 3, 9, 1, 9, 9, 1, 2, 1, 9, 8, 9, 8, 1, 1, 1, 4, 2, 2, 9, 9, 1, 1, 1, 3, 6, 1, 2, 3, 1, 4, 2, 9, 1, 9, 9, 1, 8, 2, 1, 9, 1, 8, 1, 8, 8, 2, 1, 9, 9, 6, 8, 8, 9, 8, 10, 8, 9, 5, 1, 1, 1, 1, 8, 1, 8, 12, 8, 1, 12, 9, 2, 8, 1, 1, 2, 1, 8, 6, 9, 9, 8, 1, 8, 9, 7, 7, 8, 9, 9, 1, 8, 3, 8, 1, 3, 3, 8, 9, 8, 2, 8, 1, 2, 9, 8, 1, 1, 1, 1, 9, 1, 9, 8, 12, 3, 8, 8, 1, 10, 10, 10, 2, 2, 1, 10, 2, 2, 10, 8, 12, 8, 1, 1, 1, 2, 1, 1, 3, 8, 1, 2, 2, 2, 1, 1, 6, 2, 8, 8, 8, 1, 1, 1, 9, 9, 2, 8, 10, 2, 8, 2, 1, 2, 9, 9, 2, 1, 1, 8, 8, 1, 3, 1, 8, 9, 1, 10, 9, 1, 1, 1, 1, 7, 2, 2, 1, 2, 8, 8, 1, 2, 1, 3, 2, 1, 8, 3, 9, 2, 10, 2, 10, 1, 2, 1, 1, 13, 9, 10, 8, 2, 2, 1, 1, 8, 2, 2, 1, 9, 1, 1, 8, 9, 9, 2, 9, 2, 2, 1, 1, 1, 8, 9, 4, 9, 9, 1, 8, 2, 1, 1, 8, 2, 2, 2, 8, 1, 1, 8, 2, 10, 2, 9, 9, 7, 1, 1, 2, 2, 8, 3, 1, 2, 1, 1, 8, 1, 1, 1, 9, 1, 1, 8, 8, 1, 9, 6, 1, 9, 1, 8, 1, 8, 8, 8, 1, 3, 8, 8, 2, 6, 3, 2, 1, 10, 1, 8, 2, 1, 6, 1, 1, 1, 8, 1, 10, 1, 1, 8, 9, 2, 6, 9, 2, 9, 4, 1, 8, 1, 3, 7, 8, 8, 5, 8, 7, 1, 1, 1, 13, 8, 3, 1, 1, 1, 1, 2, 8, 2, 12, 8, 1, 2, 5, 1, 8, 2, 10, 8, 2, 10, 1, 5, 2, 1, 1, 5, 2, 2, 7, 8, 2, 9, 9, 1, 10, 1, 8, 2, 5, 8, 1, 5, 1, 10, 1, 1, 9, 8, 6, 1, 8, 9, 8, 1, 8, 2, 2, 8, 3, 9, 1, 9, 3, 8, 4, 4, 3, 3, 1, 1, 1, 8, 9, 1, 1, 8, 3, 1, 2, 8, 2, 1, 1, 10, 1, 2, 2, 1, 1, 8, 2, 8, 2, 10, 2, 2, 10, 8, 8, 8, 13, 2, 2, 9, 2, 5, 9, 2, 1, 8, 8, 8, 1, 12, 12, 2, 9, 2, 1, 8, 2, 1, 8, 1, 9, 9, 2, 7, 1, 1, 7, 1, 4, 3, 1, 10, 3, 10, 9, 4, 6, 7, 5, 2, 1, 8, 8, 1, 4, 9, 2, 1, 8, 1, 1, 1, 1, 1, 8, 9, 8, 8, 8, 8, 9, 8, 10, 1, 8, 2, 7, 8, 9, 1, 2, 5, 9, 10, 8, 9, 12, 1, 6, 1, 2, 10, 9, 4, 1, 8, 10, 10, 1, 1, 1, 1, 1, 2, 3, 8, 1, 2, 10, 2, 1, 2, 4, 2, 2, 9, 1, 4, 2, 1, 1, 12, 12, 9, 9, 7, 1, 8, 4, 9, 9, 8, 1, 7, 3, 2, 1, 1, 4, 8, 1, 5, 8, 2, 8, 1, 14, 9, 12, 1, 10, 2, 1, 1, 8, 8, 6, 6, 3, 1, 2, 8, 1, 3, 2, 1, 8, 8, 1, 10, 8, 2, 8, 2, 5, 9, 1, 8, 8, 1, 1, 8, 8, 13, 1, 3, 8, 4, 1, 9, 7, 8, 8, 8, 3, 8, 1, 4, 2, 8, 8, 8, 7, 1, 1, 2, 8, 8, 9, 8, 8, 2, 3, 9, 9, 2, 1, 2, 2, 1, 8, 2, 6, 2, 1, 1, 9, 10, 3, 8, 2, 3, 2, 8, 8, 1, 8, 8, 8, 9, 1, 4, 1, 9, 2, 1, 8, 0, 1, 8, 1, 1, 8, 9, 9, 1, 3, 1, 2, 8, 8, 7, 1, 1, 2, 9, 2, 10, 2, 8, 2, 2, 2, 7, 1, 9, 8, 1, 3, 9, 2, 1, 10, 8, 1, 4, 1, 8, 5, 9, 8, 8, 1, 2, 2, 1, 8, 8, 6, 8, 1, 1, 8, 3, 2, 2, 1, 8, 1, 7, 6, 8, 1, 1, 1, 9, 1, 1, 1, 2, 1, 11, 10, 10, 11, 9]\n",
            "8419\n",
            "Average Length 490.60577265708514\n",
            "Found 8419 texts.\n",
            "Found 15 labels.\n",
            "['8', '1', '8', '2', '8', '8', '8', '9', '7', '8', '1', '2', '1', '1', '8', '4', '8', '8', '12', '3', '3', '7', '3', '12', '1', '8', '8', '8', '8', '8', '8', '8', '1', '9', '5', '9', '9', '9', '11', '8', '8', '8', '4', '8', '8', '8', '8', '1', '3', '9', '3', '7', '1', '2', '9', '9', '7', '8', '8', '1', '10', '7', '8', '8', '9', '8', '7', '9', '9', '12', '7', '2', '8', '1', '11', '11', '1', '7', '7', '12', '1', '9', '8', '10', '12', '7', '8', '2', '8', '9', '9', '1', '8', '9', '1', '7', '12', '10', '10', '10', '8', '3', '7', '9', '8', '9', '1', '8', '8', '2', '7', '2', '9', '9', '11', '8', '8', '12', '12', '7', '8', '12', '4', '9', '3', '1', '12', '1', '1', '8', '8', '3', '8', '8', '8', '8', '9', '1', '8', '8', '10', '1', '8', '2', '8', '8', '7', '3', '8', '2', '4', '4', '9', '8', '10', '12', '12', '1', '1', '9', '1', '1', '1', '8', '2', '2', '8', '1', '1', '2', '2', '1', '2', '8', '1', '9', '9', '8', '8', '4', '2', '9', '9', '8', '3', '4', '3', '1', '8', '8', '2', '1', '9', '7', '8', '8', '1', '12', '3', '8', '2', '4', '2', '9', '12', '1', '4', '1', '8', '8', '8', '2', '2', '8', '9', '8', '8', '8', '10', '9', '8', '7', '9', '1', '1', '9', '4', '2', '4', '2', '2', '1', '7', '8', '11', '11', '3', '9', '2', '4', '8', '9', '1', '8', '1', '1', '4', '9', '1', '1', '8', '8', '2', '1', '8', '4', '2', '8', '9', '8', '8', '2', '8', '8', '8', '7', '1', '1', '1', '2', '1', '1', '8', '7', '8', '8', '12', '2', '12', '12', '8', '10', '12', '8', '3', '3', '12', '10', '1', '8', '12', '1', '8', '8', '2', '8', '4', '7', '8', '7', '10', '8', '10', '9', '8', '12', '12', '1', '8', '8', '3', '8', '8', '8', '8', '8', '1', '9', '8', '11', '1', '1', '1', '9', '8', '1', '9', '2', '3', '11', '8', '9', '9', '9', '2', '1', '8', '8', '9', '7', '1', '4', '9', '4', '8', '8', '4', '8', '12', '9', '4', '8', '2', '10', '10', '10', '8', '9', '9', '8', '8', '12', '7', '1', '8', '8', '8', '4', '1', '1', '1', '1', '1', '1', '8', '1', '9', '8', '9', '9', '4', '8', '12', '9', '8', '8', '2', '8', '8', '8', '6', '9', '8', '3', '7', '8', '8', '4', '12', '8', '8', '9', '12', '12', '9', '8', '2', '9', '2', '3', '1', '12', '8', '10', '9', '9', '9', '10', '10', '3', '8', '12', '1', '4', '2', '1', '10', '8', '2', '8', '4', '8', '9', '1', '9', '9', '10', '10', '1', '4', '9', '2', '4', '9', '1', '1', '3', '10', '3', '3', '8', '7', '3', '8', '9', '9', '12', '4', '8', '12', '2', '2', '4', '1', '9', '9', '4', '1', '4', '2', '8', '12', '2', '3', '10', '10', '9', '8', '9', '9', '1', '12', '8', '8', '8', '12', '4', '1', '8', '8', '1', '9', '8', '8', '2', '1', '8', '9', '8', '3', '3', '3', '1', '8', '8', '9', '1', '10', '9', '9', '9', '9', '5', '9', '9', '8', '8', '8', '8', '8', '8', '8', '8', '11', '12', '8', '8', '1', '8', '9', '11', '2', '2', '2', '2', '3', '1', '2', '2', '8', '2', '4', '9', '1', '2', '9', '8', '2', '8', '9', '9', '3', '10', '9', '9', '2', '8', '9', '8', '12', '12', '1', '3', '8', '8', '8', '2', '7', '7', '7', '7', '3', '9', '1', '9', '8', '9', '9', '1', '1', '1', '2', '9', '9', '9', '11', '1', '8', '8', '9', '1', '9', '8', '8', '8', '1', '1', '8', '7', '1', '1', '8', '8', '9', '4', '4', '8', '2', '2', '8', '8', '8', '8', '8', '8', '11', '8', '2', '9', '4', '9', '3', '9', '9', '1', '3', '9', '3', '1', '12', '8', '9', '12', '1', '8', '4', '2', '1', '4', '8', '3', '3', '8', '2', '8', '9', '7', '8', '8', '8', '5', '8', '3', '9', '8', '8', '13', '12', '1', '1', '2', '8', '4', '1', '9', '9', '12', '8', '9', '12', '9', '1', '9', '9', '9', '9', '3', '2', '9', '9', '4', '8', '12', '2', '4', '9', '3', '1', '9', '7', '8', '9', '9', '8', '4', '8', '8', '7', '9', '10', '3', '8', '8', '8', '1', '1', '1', '1', '8', '8', '4', '1', '10', '1', '5', '7', '7', '1', '8', '9', '3', '7', '2', '7', '7', '2', '4', '8', '12', '7', '4', '2', '9', '9', '12', '6', '10', '8', '2', '4', '12', '9', '9', '3', '8', '8', '1', '2', '10', '9', '9', '8', '4', '12', '2', '1', '8', '8', '8', '12', '10', '10', '9', '3', '8', '8', '9', '2', '8', '10', '1', '1', '1', '1', '2', '1', '1', '1', '1', '9', '8', '12', '9', '4', '8', '8', '9', '1', '9', '3', '9', '8', '8', '1', '7', '7', '10', '1', '8', '8', '1', '9', '8', '10', '3', '1', '7', '1', '8', '8', '12', '8', '8', '1', '8', '7', '1', '7', '7', '8', '2', '1', '8', '8', '2', '10', '8', '8', '8', '8', '8', '10', '1', '8', '8', '12', '8', '3', '3', '2', '2', '2', '10', '8', '8', '8', '2', '9', '1', '8', '9', '3', '2', '8', '10', '8', '6', '1', '1', '8', '4', '1', '9', '10', '8', '1', '7', '1', '2', '8', '1', '1', '1', '12', '1', '9', '12', '8', '12', '12', '12', '8', '8', '12', '4', '8', '8', '8', '8', '9', '9', '1', '3', '3', '3', '3', '1', '12', '12', '9', '10', '8', '8', '1', '9', '2', '2', '13', '9', '8', '9', '2', '1', '9', '1', '8', '8', '8', '4', '8', '1', '1', '1', '12', '12', '7', '2', '2', '2', '8', '3', '8', '9', '2', '10', '7', '8', '9', '2', '1', '2', '12', '12', '8', '8', '9', '2', '2', '9', '11', '1', '8', '1', '10', '9', '2', '1', '4', '7', '7', '7', '7', '7', '12', '8', '8', '8', '1', '1', '10', '1', '12', '1', '8', '2', '1', '1', '12', '8', '7', '9', '12', '8', '9', '3', '9', '8', '8', '8', '8', '3', '11', '2', '2', '9', '8', '8', '10', '8', '2', '7', '3', '1', '4', '7', '8', '8', '1', '8', '3', '7', '12', '8', '10', '9', '9', '8', '8', '2', '8', '9', '9', '1', '2', '8', '8', '9', '8', '3', '8', '1', '8', '10', '9', '8', '9', '9', '12', '4', '4', '8', '9', '9', '8', '2', '10', '1', '2', '8', '9', '1', '9', '9', '9', '7', '12', '12', '8', '1', '1', '1', '1', '8', '3', '1', '1', '8', '1', '8', '8', '7', '8', '8', '8', '8', '3', '2', '2', '10', '10', '10', '7', '8', '1', '2', '12', '7', '9', '8', '7', '8', '12', '2', '8', '9', '2', '6', '6', '7', '9', '8', '1', '8', '9', '8', '1', '12', '1', '2', '8', '7', '7', '7', '8', '2', '2', '8', '1', '2', '2', '9', '9', '1', '8', '8', '4', '3', '3', '1', '6', '3', '3', '12', '3', '8', '9', '1', '4', '3', '1', '8', '3', '9', '2', '8', '2', '8', '8', '8', '1', '1', '1', '9', '9', '8', '1', '9', '8', '1', '1', '3', '10', '8', '1', '1', '3', '9', '1', '4', '4', '1', '8', '9', '9', '2', '0', '0', '1', '8', '3', '1', '8', '8', '9', '8', '8', '1', '1', '8', '9', '8', '8', '8', '7', '9', '8', '8', '8', '10', '9', '8', '1', '2', '6', '1', '9', '9', '8', '12', '12', '12', '8', '8', '2', '8', '1', '2', '2', '2', '1', '9', '8', '2', '12', '2', '8', '12', '8', '9', '8', '8', '9', '7', '1', '1', '1', '1', '1', '8', '8', '1', '8', '8', '1', '1', '3', '2', '8', '8', '9', '10', '10', '2', '2', '1', '9', '2', '9', '9', '4', '12', '12', '12', '10', '7', '3', '3', '4', '2', '2', '9', '2', '8', '4', '2', '4', '1', '10', '9', '7', '8', '7', '1', '1', '3', '3', '1', '1', '3', '3', '3', '1', '1', '1', '1', '8', '2', '3', '1', '1', '2', '8', '8', '12', '8', '8', '8', '8', '11', '9', '1', '8', '9', '2', '8', '8', '8', '3', '9', '1', '9', '2', '7', '2', '8', '2', '8', '10', '8', '1', '10', '1', '1', '9', '9', '8', '8', '1', '8', '8', '8', '12', '8', '8', '8', '1', '8', '8', '8', '1', '9', '1', '1', '8', '1', '8', '9', '8', '2', '12', '9', '9', '0', '1', '8', '8', '1', '8', '12', '8', '8', '10', '8', '8', '8', '7', '8', '1', '8', '7', '3', '10', '1', '8', '9', '1', '8', '8', '8', '10', '1', '10', '3', '9', '1', '8', '9', '2', '8', '3', '3', '9', '9', '7', '9', '1', '1', '9', '2', '1', '1', '1', '7', '1', '1', '8', '8', '1', '1', '8', '1', '8', '3', '12', '9', '3', '3', '8', '8', '8', '8', '3', '1', '3', '3', '1', '11', '0', '8', '8', '7', '8', '12', '1', '8', '9', '8', '9', '8', '8', '3', '8', '8', '1', '1', '1', '9', '2', '2', '2', '8', '7', '12', '8', '8', '9', '10', '10', '7', '8', '1', '9', '8', '7', '3', '1', '3', '8', '2', '2', '3', '9', '8', '4', '4', '8', '9', '2', '1', '1', '7', '8', '9', '9', '7', '8', '7', '7', '8', '2', '2', '8', '4', '9', '7', '10', '0', '9', '8', '3', '7', '8', '1', '1', '8', '9', '9', '2', '2', '10', '1', '9', '10', '10', '10', '8', '3', '2', '12', '9', '9', '10', '12', '9', '12', '12', '9', '1', '2', '4', '12', '12', '7', '8', '9', '7', '7', '7', '3', '9', '8', '9', '1', '12', '8', '9', '4', '1', '3', '12', '12', '12', '12', '8', '8', '2', '1', '1', '2', '1', '1', '1', '12', '12', '8', '12', '2', '2', '12', '3', '3', '12', '8', '2', '8', '8', '12', '2', '1', '10', '3', '2', '8', '7', '1', '8', '1', '3', '7', '8', '9', '8', '3', '1', '1', '7', '8', '8', '9', '8', '2', '9', '2', '2', '9', '8', '1', '8', '8', '1', '3', '3', '1', '1', '10', '1', '2', '8', '1', '1', '1', '1', '9', '1', '4', '1', '7', '7', '7', '7', '2', '2', '8', '8', '12', '1', '9', '1', '7', '3', '3', '1', '8', '8', '10', '8', '9', '2', '9', '1', '3', '8', '8', '3', '12', '2', '8', '12', '2', '9', '1', '3', '3', '3', '3', '2', '8', '7', '9', '8', '3', '3', '1', '7', '8', '3', '1', '1', '12', '8', '9', '1', '2', '3', '8', '1', '1', '3', '3', '9', '1', '1', '1', '12', '1', '7', '3', '3', '1', '8', '8', '8', '1', '2', '4', '8', '1', '10', '2', '5', '3', '3', '12', '10', '9', '9', '12', '9', '0', '2', '8', '8', '9', '9', '9', '8', '1', '3', '1', '1', '4', '8', '1', '10', '8', '7', '2', '8', '2', '8', '4', '7', '8', '1', '9', '1', '9', '8', '2', '8', '2', '7', '9', '2', '2', '9', '1', '8', '12', '1', '8', '1', '4', '1', '9', '9', '1', '10', '12', '4', '8', '1', '7', '3', '9', '2', '12', '7', '8', '8', '2', '1', '12', '9', '8', '1', '2', '2', '8', '10', '2', '1', '7', '7', '7', '12', '3', '3', '8', '3', '8', '8', '3', '9', '8', '9', '1', '1', '8', '7', '9', '3', '3', '8', '1', '0', '9', '9', '9', '1', '8', '9', '9', '10', '1', '8', '7', '8', '8', '8', '9', '9', '8', '9', '10', '4', '9', '3', '7', '12', '1', '9', '9', '8', '9', '1', '9', '3', '1', '8', '4', '12', '10', '9', '8', '7', '10', '8', '12', '12', '3', '10', '8', '12', '2', '1', '2', '3', '9', '8', '8', '7', '1', '1', '2', '2', '1', '2', '2', '7', '1', '3', '9', '9', '3', '8', '8', '8', '8', '8', '7', '8', '8', '10', '8', '1', '8', '2', '8', '2', '2', '2', '2', '2', '1', '7', '12', '10', '1', '2', '8', '1', '4', '7', '8', '1', '12', '8', '7', '9', '2', '2', '2', '8', '1', '8', '1', '1', '0', '2', '2', '6', '1', '8', '2', '1', '8', '1', '1', '2', '2', '3', '2', '2', '10', '10', '9', '1', '7', '7', '8', '8', '1', '12', '10', '12', '3', '8', '8', '8', '3', '8', '3', '10', '2', '2', '2', '1', '2', '2', '1', '0', '1', '8', '9', '1', '1', '1', '2', '2', '2', '2', '2', '1', '1', '1', '1', '12', '9', '9', '1', '10', '11', '12', '9', '1', '1', '8', '8', '1', '2', '12', '8', '3', '7', '2', '10', '9', '7', '8', '1', '2', '2', '7', '9', '12', '2', '2', '1', '8', '9', '2', '3', '2', '2', '2', '9', '9', '8', '9', '2', '3', '8', '8', '9', '7', '3', '10', '8', '8', '9', '1', '1', '2', '8', '1', '10', '8', '8', '9', '7', '1', '7', '12', '8', '1', '7', '2', '1', '3', '9', '2', '8', '8', '1', '2', '3', '9', '3', '8', '9', '7', '7', '1', '10', '2', '8', '8', '8', '1', '8', '2', '8', '8', '1', '2', '8', '10', '2', '1', '0', '8', '3', '8', '10', '10', '12', '3', '8', '9', '3', '10', '8', '8', '8', '1', '8', '8', '2', '2', '2', '2', '2', '2', '1', '1', '10', '1', '10', '8', '2', '1', '2', '2', '8', '3', '3', '2', '2', '1', '8', '1', '3', '1', '9', '2', '2', '1', '3', '2', '2', '3', '2', '2', '3', '2', '1', '1', '2', '1', '2', '7', '8', '2', '1', '12', '12', '3', '1', '9', '9', '7', '8', '7', '2', '7', '9', '2', '2', '2', '8', '9', '7', '9', '2', '8', '9', '9', '2', '9', '1', '1', '9', '8', '3', '3', '8', '2', '7', '8', '11', '2', '8', '9', '1', '8', '3', '1', '2', '1', '2', '2', '2', '2', '8', '3', '9', '2', '10', '9', '9', '2', '7', '7', '7', '1', '3', '8', '8', '1', '1', '8', '7', '1', '8', '8', '9', '3', '3', '3', '2', '4', '8', '12', '8', '1', '12', '9', '2', '8', '2', '12', '2', '1', '3', '8', '12', '12', '11', '8', '10', '9', '2', '9', '4', '10', '1', '12', '12', '9', '3', '8', '9', '12', '9', '9', '2', '2', '2', '3', '5', '1', '1', '1', '7', '7', '8', '2', '2', '8', '2', '1', '7', '3', '2', '9', '8', '9', '1', '1', '9', '8', '9', '3', '3', '2', '9', '4', '9', '8', '8', '1', '8', '10', '2', '0', '3', '8', '8', '8', '9', '12', '9', '8', '2', '2', '8', '10', '9', '8', '2', '2', '4', '1', '9', '9', '8', '8', '10', '3', '1', '1', '2', '8', '7', '8', '2', '1', '1', '8', '12', '2', '9', '4', '8', '3', '3', '3', '8', '2', '12', '12', '8', '9', '12', '8', '2', '12', '7', '9', '2', '2', '1', '3', '1', '3', '11', '9', '8', '1', '10', '2', '12', '3', '8', '4', '1', '2', '8', '8', '3', '9', '3', '8', '7', '1', '1', '3', '1', '8', '2', '9', '8', '12', '1', '1', '1', '9', '9', '1', '8', '8', '8', '2', '2', '12', '3', '1', '1', '1', '9', '9', '3', '2', '1', '1', '9', '9', '1', '9', '9', '1', '9', '3', '9', '1', '8', '1', '9', '8', '3', '8', '8', '9', '9', '8', '2', '8', '1', '2', '2', '10', '1', '2', '1', '1', '9', '1', '9', '3', '7', '7', '2', '10', '3', '3', '1', '1', '9', '1', '2', '1', '3', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '8', '8', '7', '1', '1', '8', '8', '2', '1', '12', '1', '8', '1', '9', '8', '8', '2', '1', '9', '9', '2', '2', '8', '1', '7', '7', '9', '8', '1', '6', '8', '8', '2', '2', '8', '3', '8', '3', '2', '3', '8', '1', '2', '2', '2', '8', '9', '9', '9', '12', '1', '9', '2', '1', '9', '2', '9', '9', '10', '8', '1', '1', '9', '2', '1', '7', '1', '3', '7', '1', '1', '1', '3', '8', '8', '8', '9', '9', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '1', '0', '1', '1', '1', '2', '2', '3', '1', '1', '2', '3', '3', '3', '7', '3', '1', '9', '3', '9', '1', '4', '1', '1', '9', '10', '9', '8', '2', '3', '10', '9', '3', '10', '12', '8', '9', '8', '2', '1', '9', '8', '1', '7', '8', '1', '9', '1', '2', '10', '7', '7', '8', '1', '3', '3', '9', '3', '3', '1', '1', '1', '9', '1', '3', '8', '8', '8', '1', '8', '1', '9', '7', '8', '8', '2', '1', '3', '8', '2', '1', '6', '1', '8', '8', '2', '8', '2', '2', '9', '8', '1', '1', '6', '8', '6', '10', '2', '1', '1', '8', '9', '3', '3', '3', '1', '3', '9', '6', '8', '1', '8', '3', '1', '2', '2', '12', '7', '1', '1', '1', '1', '12', '1', '8', '8', '3', '2', '1', '9', '2', '3', '3', '2', '2', '7', '2', '2', '2', '3', '1', '9', '8', '7', '1', '1', '3', '1', '9', '4', '3', '9', '2', '1', '1', '9', '8', '8', '7', '2', '1', '3', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '10', '1', '1', '8', '2', '8', '1', '8', '1', '3', '1', '2', '1', '1', '3', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '8', '1', '9', '8', '8', '1', '10', '8', '8', '1', '3', '9', '8', '9', '8', '2', '1', '3', '4', '1', '12', '1', '9', '8', '2', '7', '2', '1', '2', '9', '2', '1', '3', '8', '1', '2', '3', '8', '2', '10', '10', '10', '9', '9', '9', '3', '8', '3', '1', '1', '1', '1', '1', '1', '2', '1', '9', '2', '7', '9', '8', '7', '9', '1', '1', '1', '1', '8', '2', '2', '3', '3', '2', '12', '8', '3', '1', '1', '12', '9', '8', '2', '2', '9', '1', '2', '2', '9', '1', '1', '2', '4', '8', '1', '8', '10', '2', '9', '9', '9', '1', '2', '1', '1', '2', '2', '2', '12', '1', '2', '8', '3', '9', '9', '3', '2', '9', '9', '7', '2', '8', '8', '9', '2', '9', '1', '1', '1', '1', '1', '2', '8', '2', '1', '2', '2', '8', '3', '1', '1', '9', '1', '3', '10', '7', '9', '8', '8', '2', '2', '9', '2', '2', '2', '2', '2', '2', '9', '1', '3', '6', '4', '2', '2', '9', '1', '9', '8', '1', '1', '1', '7', '3', '2', '9', '9', '1', '9', '7', '2', '8', '9', '9', '12', '10', '8', '10', '2', '3', '1', '2', '2', '12', '12', '3', '12', '1', '2', '1', '2', '1', '2', '8', '2', '3', '12', '12', '8', '2', '2', '9', '2', '9', '2', '3', '3', '1', '1', '1', '12', '3', '7', '1', '3', '1', '2', '9', '2', '7', '2', '1', '8', '3', '7', '8', '1', '1', '3', '8', '3', '2', '9', '3', '1', '1', '1', '1', '11', '1', '2', '6', '1', '2', '3', '8', '9', '9', '2', '9', '2', '1', '1', '3', '1', '12', '9', '1', '1', '9', '1', '9', '9', '8', '9', '8', '1', '2', '7', '1', '0', '9', '8', '2', '3', '2', '4', '1', '1', '1', '8', '1', '12', '1', '2', '3', '3', '9', '9', '9', '9', '9', '7', '9', '3', '9', '1', '7', '3', '3', '3', '3', '7', '8', '2', '2', '2', '8', '2', '3', '9', '9', '3', '1', '8', '9', '12', '8', '8', '3', '2', '1', '6', '1', '9', '1', '1', '1', '1', '1', '1', '2', '2', '1', '2', '2', '2', '2', '9', '2', '5', '3', '2', '2', '8', '2', '1', '8', '3', '3', '8', '3', '1', '3', '9', '2', '8', '9', '4', '4', '9', '8', '8', '7', '7', '3', '1', '8', '8', '3', '2', '2', '10', '3', '3', '2', '2', '2', '2', '12', '3', '1', '2', '7', '7', '12', '2', '1', '2', '1', '1', '2', '1', '3', '3', '3', '1', '3', '9', '4', '8', '8', '4', '2', '4', '2', '8', '9', '1', '1', '2', '2', '2', '8', '7', '2', '8', '2', '9', '1', '8', '1', '1', '2', '1', '1', '1', '2', '9', '9', '8', '1', '8', '1', '4', '8', '1', '2', '7', '9', '2', '1', '8', '9', '8', '9', '1', '1', '2', '3', '2', '12', '7', '1', '2', '4', '4', '4', '2', '2', '2', '9', '8', '8', '1', '12', '3', '3', '2', '2', '3', '12', '1', '5', '1', '1', '3', '2', '8', '8', '2', '2', '2', '3', '9', '8', '8', '9', '8', '8', '11', '8', '2', '9', '2', '3', '1', '7', '1', '8', '2', '8', '1', '1', '1', '8', '1', '1', '1', '7', '8', '8', '2', '3', '2', '1', '8', '8', '1', '8', '4', '8', '9', '8', '9', '8', '1', '2', '3', '2', '1', '2', '2', '3', '1', '9', '4', '8', '1', '1', '9', '1', '1', '8', '2', '2', '2', '1', '7', '3', '3', '1', '3', '3', '12', '3', '1', '1', '3', '1', '1', '4', '8', '4', '4', '3', '3', '3', '4', '8', '1', '9', '9', '9', '4', '1', '7', '4', '8', '4', '9', '8', '1', '1', '3', '8', '9', '1', '9', '7', '1', '1', '9', '1', '8', '8', '8', '1', '1', '8', '2', '2', '2', '9', '4', '4', '1', '2', '1', '2', '9', '1', '1', '8', '5', '5', '5', '9', '12', '4', '1', '2', '1', '8', '8', '1', '9', '9', '2', '12', '1', '1', '7', '8', '8', '4', '1', '2', '8', '11', '2', '3', '2', '2', '1', '11', '2', '2', '2', '2', '9', '9', '2', '2', '9', '3', '1', '9', '1', '1', '1', '7', '8', '1', '8', '9', '1', '2', '9', '8', '1', '2', '9', '8', '12', '2', '2', '10', '8', '2', '2', '8', '8', '1', '2', '6', '1', '1', '7', '7', '2', '3', '2', '1', '1', '8', '1', '10', '8', '12', '6', '4', '1', '4', '1', '2', '9', '8', '9', '4', '8', '8', '10', '8', '8', '8', '8', '8', '2', '2', '8', '4', '9', '3', '3', '3', '3', '3', '9', '2', '1', '1', '2', '3', '2', '1', '2', '3', '3', '3', '2', '2', '3', '3', '2', '1', '2', '3', '3', '3', '3', '12', '9', '3', '2', '2', '3', '1', '5', '1', '1', '3', '2', '2', '1', '2', '9', '3', '9', '8', '1', '8', '7', '7', '9', '1', '1', '7', '9', '10', '1', '7', '1', '4', '3', '8', '9', '4', '9', '9', '2', '9', '2', '8', '4', '2', '2', '9', '5', '2', '1', '10', '9', '3', '1', '1', '1', '2', '1', '2', '9', '1', '7', '9', '9', '8', '2', '2', '8', '9', '1', '9', '8', '2', '3', '2', '2', '1', '2', '2', '2', '1', '1', '8', '1', '9', '4', '12', '8', '2', '7', '2', '2', '1', '9', '3', '1', '8', '12', '1', '1', '2', '1', '10', '2', '6', '12', '12', '4', '9', '1', '9', '10', '1', '2', '8', '2', '1', '8', '6', '12', '9', '9', '2', '1', '7', '8', '9', '5', '8', '1', '8', '8', '3', '1', '8', '2', '8', '2', '2', '1', '2', '9', '2', '8', '1', '12', '8', '2', '7', '3', '3', '12', '2', '3', '3', '9', '9', '3', '3', '3', '3', '3', '2', '1', '4', '1', '4', '8', '8', '2', '1', '2', '9', '12', '1', '10', '12', '1', '2', '9', '4', '8', '10', '3', '2', '8', '7', '4', '8', '9', '2', '7', '1', '10', '2', '2', '2', '8', '4', '2', '2', '1', '1', '8', '7', '9', '2', '1', '9', '8', '9', '12', '4', '8', '2', '8', '7', '7', '1', '9', '2', '1', '1', '9', '1', '8', '2', '3', '9', '9', '1', '3', '2', '9', '2', '2', '8', '1', '1', '2', '1', '2', '1', '9', '8', '2', '2', '4', '8', '8', '9', '5', '5', '9', '8', '9', '6', '2', '1', '12', '2', '3', '8', '8', '9', '2', '2', '1', '3', '2', '10', '9', '10', '7', '2', '8', '4', '2', '8', '9', '8', '1', '3', '8', '8', '1', '8', '3', '8', '8', '1', '10', '3', '1', '5', '8', '8', '9', '2', '2', '9', '2', '1', '9', '1', '4', '1', '12', '8', '8', '2', '1', '1', '1', '1', '1', '9', '2', '9', '8', '9', '5', '9', '1', '8', '2', '4', '1', '1', '1', '9', '12', '4', '1', '1', '9', '8', '4', '1', '8', '9', '8', '8', '9', '9', '9', '9', '9', '9', '1', '3', '4', '2', '2', '8', '2', '9', '2', '3', '8', '3', '1', '7', '2', '1', '1', '4', '2', '9', '2', '1', '3', '2', '9', '2', '9', '3', '8', '1', '9', '1', '1', '2', '8', '8', '8', '2', '3', '9', '9', '8', '2', '4', '1', '5', '1', '1', '9', '9', '2', '1', '1', '1', '9', '9', '1', '3', '9', '2', '2', '9', '9', '8', '3', '9', '9', '8', '2', '2', '8', '9', '2', '2', '8', '9', '10', '10', '2', '8', '7', '9', '9', '4', '2', '4', '11', '2', '1', '7', '8', '8', '8', '9', '4', '9', '8', '8', '2', '1', '1', '9', '8', '3', '3', '8', '8', '7', '9', '1', '3', '4', '8', '10', '2', '4', '4', '8', '2', '8', '2', '8', '9', '2', '1', '2', '2', '3', '1', '9', '4', '5', '9', '9', '1', '1', '1', '1', '1', '1', '7', '1', '1', '1', '8', '1', '1', '1', '1', '1', '9', '1', '2', '1', '12', '9', '3', '9', '9', '4', '1', '9', '1', '1', '2', '11', '9', '3', '2', '2', '2', '4', '2', '3', '2', '7', '7', '8', '1', '10', '9', '5', '7', '1', '10', '8', '1', '2', '7', '1', '12', '5', '8', '4', '2', '9', '9', '8', '2', '9', '8', '8', '10', '2', '3', '2', '7', '2', '8', '10', '3', '2', '9', '9', '9', '1', '1', '1', '1', '8', '2', '10', '9', '8', '1', '2', '2', '2', '1', '2', '1', '3', '9', '12', '2', '2', '4', '8', '1', '3', '9', '4', '9', '1', '9', '9', '2', '1', '1', '9', '7', '10', '3', '10', '2', '9', '2', '9', '2', '8', '2', '1', '2', '3', '1', '1', '1', '8', '5', '8', '3', '1', '1', '4', '2', '2', '1', '3', '8', '2', '1', '1', '1', '2', '9', '4', '1', '8', '1', '2', '8', '2', '9', '2', '2', '5', '5', '2', '5', '2', '1', '8', '8', '1', '3', '12', '2', '4', '3', '2', '2', '2', '6', '2', '3', '3', '1', '8', '2', '2', '1', '1', '8', '8', '10', '1', '9', '2', '9', '12', '0', '2', '1', '3', '2', '2', '1', '2', '1', '9', '9', '2', '9', '8', '8', '1', '7', '8', '1', '2', '6', '9', '8', '10', '1', '12', '2', '2', '1', '8', '2', '1', '12', '7', '4', '2', '10', '2', '2', '1', '2', '1', '2', '1', '1', '2', '1', '9', '8', '10', '2', '10', '9', '9', '12', '5', '3', '2', '8', '2', '8', '3', '3', '1', '4', '9', '10', '2', '4', '8', '1', '2', '10', '12', '12', '3', '1', '1', '2', '9', '6', '6', '1', '9', '1', '8', '1', '8', '8', '8', '8', '2', '2', '2', '8', '8', '2', '1', '1', '1', '1', '1', '8', '8', '5', '8', '8', '1', '8', '9', '9', '1', '7', '12', '9', '9', '7', '2', '2', '7', '8', '9', '8', '2', '9', '6', '3', '4', '8', '4', '1', '2', '9', '8', '8', '8', '2', '1', '1', '8', '8', '3', '1', '9', '9', '7', '1', '2', '2', '2', '9', '4', '1', '2', '12', '1', '8', '2', '1', '9', '1', '8', '9', '9', '2', '5', '4', '2', '1', '2', '8', '12', '8', '10', '3', '8', '8', '8', '2', '2', '8', '2', '8', '2', '4', '8', '10', '2', '7', '2', '1', '8', '8', '9', '5', '8', '1', '12', '7', '10', '2', '2', '2', '1', '4', '8', '12', '1', '8', '2', '2', '9', '1', '8', '3', '1', '1', '5', '10', '2', '1', '2', '4', '8', '9', '3', '2', '8', '7', '4', '4', '9', '9', '2', '8', '1', '1', '2', '4', '7', '1', '9', '1', '1', '1', '8', '4', '1', '3', '1', '2', '2', '9', '1', '8', '8', '2', '2', '9', '9', '1', '8', '8', '1', '9', '8', '8', '2', '2', '2', '2', '1', '1', '1', '7', '4', '1', '1', '4', '2', '3', '3', '2', '3', '9', '2', '8', '2', '1', '5', '1', '2', '2', '1', '3', '5', '2', '9', '1', '1', '9', '8', '1', '4', '8', '1', '8', '2', '4', '8', '4', '7', '9', '8', '1', '2', '2', '4', '4', '11', '3', '11', '1', '3', '8', '1', '9', '6', '8', '9', '3', '9', '8', '9', '2', '3', '3', '7', '1', '7', '2', '9', '9', '1', '8', '8', '1', '5', '5', '8', '8', '1', '2', '1', '3', '9', '9', '5', '9', '8', '1', '4', '3', '8', '1', '1', '2', '1', '8', '9', '8', '2', '2', '2', '1', '2', '4', '10', '8', '1', '9', '1', '8', '1', '1', '9', '9', '8', '11', '1', '8', '2', '1', '2', '8', '2', '8', '8', '2', '9', '6', '10', '1', '8', '6', '4', '5', '11', '2', '2', '8', '1', '8', '1', '8', '1', '4', '8', '1', '1', '1', '8', '3', '7', '3', '3', '7', '1', '1', '4', '8', '1', '6', '4', '2', '2', '1', '1', '1', '1', '6', '2', '2', '8', '1', '8', '5', '5', '2', '1', '1', '2', '3', '7', '1', '1', '6', '2', '9', '3', '9', '8', '9', '2', '1', '4', '2', '9', '13', '9', '2', '8', '12', '4', '1', '1', '9', '5', '1', '1', '1', '1', '8', '2', '1', '1', '2', '9', '0', '12', '1', '1', '8', '9', '8', '3', '2', '2', '12', '8', '2', '2', '2', '1', '10', '1', '9', '8', '9', '5', '2', '2', '9', '2', '8', '4', '8', '3', '7', '9', '2', '2', '7', '2', '2', '8', '1', '1', '9', '10', '9', '8', '2', '9', '0', '7', '1', '1', '1', '9', '8', '2', '8', '12', '8', '3', '2', '8', '8', '7', '7', '8', '12', '2', '1', '3', '9', '2', '2', '8', '2', '8', '8', '12', '8', '8', '1', '8', '9', '2', '4', '4', '7', '2', '1', '1', '9', '3', '7', '1', '3', '9', '8', '2', '2', '3', '1', '3', '10', '2', '3', '7', '1', '8', '1', '1', '10', '3', '10', '8', '4', '1', '2', '4', '3', '10', '9', '3', '9', '5', '8', '7', '2', '9', '3', '3', '2', '11', '8', '1', '1', '7', '2', '7', '2', '9', '4', '8', '1', '12', '8', '7', '9', '1', '0', '2', '6', '4', '9', '3', '2', '4', '12', '9', '8', '5', '9', '2', '8', '4', '6', '8', '9', '3', '1', '8', '7', '3', '1', '1', '1', '8', '9', '1', '8', '7', '9', '8', '2', '1', '2', '2', '3', '2', '2', '1', '1', '4', '9', '7', '3', '2', '8', '8', '9', '1', '9', '7', '4', '2', '2', '8', '5', '9', '1', '5', '7', '1', '4', '6', '9', '10', '1', '8', '2', '9', '1', '9', '2', '9', '8', '2', '9', '9', '11', '2', '12', '2', '2', '9', '4', '8', '1', '9', '9', '2', '8', '9', '1', '2', '9', '3', '8', '8', '1', '7', '8', '8', '2', '3', '2', '2', '2', '2', '9', '8', '10', '2', '2', '1', '9', '11', '1', '8', '8', '2', '4', '2', '1', '2', '8', '8', '9', '2', '8', '9', '2', '3', '1', '2', '1', '3', '10', '8', '1', '2', '4', '1', '9', '8', '9', '3', '3', '9', '8', '2', '11', '3', '7', '1', '8', '7', '1', '8', '8', '8', '1', '4', '8', '8', '1', '9', '3', '1', '1', '2', '8', '8', '8', '2', '1', '8', '10', '2', '12', '8', '8', '9', '1', '8', '1', '3', '2', '2', '10', '7', '2', '2', '1', '1', '8', '2', '9', '1', '2', '9', '3', '3', '10', '1', '4', '7', '10', '12', '2', '4', '10', '8', '6', '2', '9', '1', '8', '3', '1', '2', '8', '8', '2', '12', '10', '2', '10', '9', '1', '2', '5', '8', '12', '8', '8', '7', '8', '8', '1', '8', '2', '2', '9', '1', '8', '10', '5', '5', '5', '8', '1', '9', '1', '13', '1', '2', '2', '1', '2', '4', '9', '2', '1', '9', '13', '11', '1', '9', '9', '3', '10', '8', '7', '8', '8', '4', '2', '1', '9', '4', '3', '1', '1', '10', '9', '2', '8', '6', '2', '1', '1', '3', '2', '8', '1', '1', '1', '1', '2', '4', '1', '1', '10', '1', '8', '1', '1', '9', '1', '7', '1', '1', '9', '9', '2', '12', '9', '1', '8', '1', '12', '1', '8', '3', '8', '1', '8', '1', '2', '10', '1', '1', '2', '2', '9', '3', '9', '12', '1', '9', '1', '2', '8', '7', '2', '1', '1', '3', '2', '8', '4', '4', '5', '12', '7', '8', '9', '6', '1', '8', '9', '2', '1', '9', '1', '4', '1', '8', '2', '1', '1', '8', '7', '4', '9', '1', '8', '4', '2', '7', '5', '1', '3', '9', '2', '8', '2', '1', '2', '9', '1', '1', '2', '3', '4', '3', '1', '2', '2', '10', '2', '2', '8', '1', '1', '2', '4', '9', '2', '11', '9', '8', '9', '2', '1', '10', '4', '1', '1', '10', '7', '2', '10', '8', '1', '10', '8', '8', '8', '8', '8', '8', '2', '2', '2', '8', '3', '4', '1', '1', '1', '2', '1', '8', '8', '2', '8', '3', '8', '3', '1', '2', '3', '1', '1', '10', '1', '4', '4', '3', '3', '1', '9', '1', '1', '2', '1', '1', '6', '1', '1', '1', '9', '1', '4', '1', '1', '1', '1', '1', '1', '2', '12', '8', '8', '1', '9', '12', '10', '8', '2', '12', '1', '1', '2', '1', '7', '10', '7', '1', '2', '1', '10', '8', '2', '2', '8', '2', '2', '1', '9', '8', '8', '8', '8', '3', '1', '4', '2', '8', '3', '10', '10', '1', '9', '1', '9', '1', '9', '1', '8', '3', '1', '1', '8', '8', '8', '6', '3', '4', '1', '1', '1', '9', '9', '5', '2', '10', '2', '6', '2', '2', '7', '1', '8', '2', '11', '1', '1', '1', '2', '1', '9', '4', '4', '2', '8', '4', '6', '8', '8', '10', '10', '2', '1', '2', '9', '1', '8', '8', '3', '4', '8', '8', '2', '8', '8', '1', '2', '1', '2', '9', '4', '1', '3', '3', '3', '8', '8', '8', '2', '6', '4', '3', '3', '12', '3', '4', '9', '6', '8', '7', '7', '8', '6', '4', '1', '10', '6', '3', '3', '8', '1', '1', '8', '1', '11', '8', '1', '1', '2', '3', '11', '7', '2', '1', '1', '1', '9', '1', '2', '1', '1', '9', '8', '1', '1', '8', '0', '4', '1', '1', '2', '1', '1', '2', '2', '9', '1', '10', '1', '3', '8', '9', '3', '3', '1', '10', '1', '9', '1', '1', '7', '4', '1', '8', '10', '1', '2', '10', '1', '1', '2', '3', '3', '9', '1', '8', '10', '1', '7', '9', '1', '9', '6', '3', '9', '2', '8', '4', '12', '12', '3', '1', '1', '9', '1', '9', '2', '1', '1', '1', '1', '1', '9', '2', '1', '2', '10', '9', '8', '8', '10', '8', '2', '3', '2', '1', '12', '8', '12', '2', '9', '1', '3', '2', '5', '2', '2', '8', '2', '2', '4', '10', '9', '10', '9', '4', '2', '4', '12', '8', '2', '1', '8', '3', '9', '2', '9', '4', '1', '1', '1', '1', '1', '9', '6', '2', '9', '2', '1', '3', '2', '2', '5', '8', '9', '1', '6', '3', '1', '2', '2', '2', '6', '1', '8', '10', '8', '3', '3', '13', '2', '9', '9', '10', '6', '12', '8', '2', '9', '2', '3', '8', '8', '1', '2', '2', '3', '2', '10', '1', '8', '9', '1', '8', '9', '8', '8', '2', '10', '2', '1', '1', '1', '9', '9', '12', '1', '1', '4', '8', '3', '2', '2', '4', '4', '2', '2', '1', '1', '1', '9', '2', '2', '4', '1', '1', '8', '8', '8', '9', '2', '13', '9', '9', '4', '1', '9', '7', '10', '10', '8', '1', '9', '1', '1', '1', '8', '12', '4', '1', '2', '1', '1', '1', '7', '8', '3', '3', '1', '2', '2', '7', '2', '2', '10', '1', '8', '4', '0', '1', '9', '4', '1', '1', '2', '10', '10', '7', '9', '3', '12', '11', '2', '8', '10', '8', '9', '4', '3', '4', '10', '1', '1', '9', '3', '10', '1', '5', '3', '3', '2', '2', '1', '1', '6', '1', '7', '1', '1', '12', '1', '1', '1', '10', '1', '8', '8', '1', '3', '8', '3', '1', '2', '8', '3', '4', '2', '8', '8', '6', '1', '1', '4', '1', '2', '9', '5', '1', '7', '8', '9', '2', '4', '9', '8', '5', '9', '9', '9', '1', '2', '1', '3', '8', '9', '2', '9', '8', '9', '1', '8', '13', '9', '3', '8', '1', '4', '1', '3', '1', '6', '4', '10', '2', '2', '7', '8', '8', '12', '8', '9', '9', '9', '10', '3', '12', '12', '2', '9', '10', '9', '7', '2', '3', '4', '10', '10', '2', '7', '7', '1', '7', '3', '9', '1', '9', '8', '2', '9', '1', '8', '1', '10', '8', '8', '2', '7', '8', '1', '8', '9', '8', '1', '4', '1', '8', '8', '8', '1', '1', '10', '3', '2', '2', '6', '8', '9', '8', '2', '1', '1', '3', '8', '8', '1', '4', '4', '3', '9', '10', '4', '2', '4', '2', '9', '2', '2', '9', '1', '1', '10', '1', '1', '2', '1', '1', '1', '9', '1', '8', '8', '8', '2', '3', '8', '1', '6', '7', '3', '1', '9', '1', '2', '1', '6', '1', '2', '10', '1', '4', '2', '3', '2', '9', '9', '4', '9', '9', '1', '2', '8', '4', '7', '8', '7', '13', '9', '1', '2', '1', '9', '3', '3', '6', '8', '9', '10', '9', '2', '2', '3', '12', '1', '1', '1', '13', '2', '1', '7', '10', '8', '9', '1', '2', '9', '1', '1', '1', '2', '1', '12', '5', '6', '9', '10', '3', '1', '10', '1', '3', '2', '8', '9', '2', '10', '8', '8', '9', '2', '8', '9', '2', '2', '2', '8', '8', '2', '3', '1', '4', '8', '1', '9', '9', '2', '8', '10', '9', '1', '2', '12', '8', '8', '0', '2', '1', '1', '9', '10', '1', '6', '2', '2', '10', '2', '2', '4', '2', '2', '12', '1', '6', '7', '8', '9', '1', '3', '5', '7', '3', '1', '3', '1', '1', '3', '2', '6', '3', '2', '1', '8', '3', '5', '2', '1', '1', '8', '1', '1', '0', '2', '3', '5', '3', '1', '1', '9', '8', '8', '8', '8', '4', '7', '2', '9', '12', '5', '9', '3', '12', '3', '9', '1', '9', '1', '7', '3', '9', '3', '10', '1', '2', '1', '4', '9', '8', '2', '9', '11', '2', '8', '9', '4', '1', '1', '1', '1', '1', '1', '1', '9', '1', '9', '1', '1', '1', '12', '3', '10', '3', '6', '1', '7', '10', '8', '3', '7', '1', '1', '2', '6', '1', '3', '9', '2', '8', '1', '8', '8', '1', '8', '10', '12', '1', '10', '12', '10', '1', '8', '8', '1', '4', '7', '9', '2', '1', '9', '3', '8', '12', '10', '6', '1', '6', '8', '3', '1', '3', '1', '10', '10', '9', '8', '1', '2', '9', '8', '8', '1', '9', '8', '8', '3', '1', '3', '9', '12', '1', '8', '1', '5', '8', '11', '5', '5', '1', '2', '1', '3', '1', '1', '1', '9', '8', '8', '1', '9', '10', '8', '4', '1', '1', '8', '10', '8', '9', '1', '10', '1', '7', '2', '1', '1', '9', '6', '2', '9', '8', '1', '1', '1', '9', '8', '8', '1', '9', '9', '1', '1', '2', '7', '9', '2', '9', '9', '8', '7', '6', '8', '7', '8', '2', '9', '2', '1', '8', '8', '8', '2', '6', '3', '1', '8', '12', '12', '8', '7', '1', '2', '2', '7', '1', '9', '8', '1', '4', '1', '1', '8', '5', '8', '1', '8', '8', '8', '8', '1', '2', '11', '1', '1', '1', '2', '7', '1', '9', '2', '2', '2', '9', '8', '9', '2', '9', '1', '8', '1', '7', '11', '13', '1', '9', '8', '2', '2', '1', '2', '3', '10', '3', '10', '4', '3', '9', '1', '8', '1', '1', '13', '1', '1', '3', '8', '1', '2', '2', '2', '9', '4', '1', '8', '1', '9', '3', '6', '8', '5', '2', '8', '2', '8', '1', '9', '2', '2', '8', '1', '1', '4', '8', '9', '2', '2', '7', '1', '8', '12', '2', '12', '8', '2', '9', '9', '3', '8', '1', '1', '9', '9', '9', '2', '8', '1', '9', '1', '8', '9', '8', '2', '2', '4', '1', '9', '10', '10', '8', '8', '1', '1', '2', '1', '4', '1', '2', '1', '1', '3', '12', '8', '8', '8', '8', '10', '2', '8', '12', '1', '9', '9', '8', '9', '1', '2', '1', '8', '8', '8', '2', '8', '8', '3', '10', '8', '9', '1', '1', '1', '3', '4', '8', '10', '6', '3', '1', '3', '2', '8', '9', '3', '5', '4', '1', '5', '2', '9', '9', '9', '1', '1', '1', '9', '9', '6', '10', '9', '8', '12', '2', '9', '1', '2', '1', '1', '1', '8', '1', '12', '1', '12', '1', '9', '1', '8', '1', '2', '1', '2', '8', '8', '10', '1', '9', '1', '2', '2', '8', '8', '3', '12', '1', '11', '2', '10', '12', '11', '2', '1', '10', '1', '1', '9', '3', '10', '2', '7', '1', '8', '1', '9', '9', '2', '1', '3', '12', '5', '9', '9', '8', '1', '8', '8', '8', '1', '1', '3', '9', '8', '9', '8', '3', '10', '3', '7', '8', '9', '2', '3', '1', '9', '10', '9', '2', '8', '2', '6', '4', '1', '1', '3', '8', '2', '3', '9', '1', '2', '1', '8', '1', '2', '2', '2', '2', '9', '9', '4', '8', '9', '1', '1', '2', '9', '1', '5', '2', '9', '8', '10', '1', '2', '10', '8', '5', '6', '4', '8', '1', '1', '1', '8', '9', '2', '8', '8', '8', '12', '2', '2', '1', '8', '1', '2', '1', '9', '8', '8', '9', '1', '1', '8', '7', '1', '8', '0', '2', '3', '8', '1', '1', '8', '1', '1', '12', '3', '2', '10', '8', '10', '6', '1', '8', '8', '10', '8', '8', '1', '4', '8', '1', '2', '9', '8', '1', '1', '3', '3', '5', '1', '1', '2', '1', '2', '1', '9', '8', '3', '9', '8', '2', '10', '9', '1', '8', '1', '10', '9', '10', '1', '2', '3', '8', '1', '3', '1', '9', '9', '8', '1', '9', '8', '8', '9', '1', '9', '2', '8', '8', '2', '13', '8', '10', '8', '9', '3', '2', '1', '3', '1', '12', '10', '10', '1', '11', '1', '2', '4', '2', '10', '1', '8', '11', '1', '1', '1', '2', '2', '8', '2', '9', '8', '9', '9', '12', '8', '1', '9', '2', '4', '1', '8', '3', '9', '1', '6', '5', '8', '9', '3', '3', '2', '1', '1', '1', '8', '11', '1', '8', '7', '1', '11', '9', '1', '7', '9', '9', '8', '8', '8', '12', '8', '1', '2', '9', '8', '8', '2', '10', '9', '8', '8', '4', '10', '9', '8', '2', '10', '10', '2', '1', '2', '1', '2', '1', '4', '1', '7', '1', '1', '3', '12', '9', '8', '5', '9', '10', '1', '9', '9', '2', '7', '4', '1', '1', '8', '12', '8', '2', '2', '9', '4', '1', '1', '5', '9', '1', '8', '12', '8', '1', '1', '4', '9', '10', '2', '3', '1', '3', '3', '3', '8', '1', '2', '1', '2', '1', '2', '9', '1', '2', '8', '9', '4', '8', '8', '10', '2', '12', '5', '5', '1', '8', '1', '7', '8', '1', '1', '8', '9', '12', '4', '9', '3', '1', '2', '5', '9', '2', '1', '2', '2', '1', '2', '8', '1', '8', '8', '2', '2', '1', '8', '4', '1', '2', '10', '9', '10', '8', '1', '10', '4', '8', '8', '10', '2', '8', '1', '1', '3', '10', '1', '4', '2', '8', '3', '3', '2', '9', '8', '5', '5', '9', '3', '10', '8', '1', '2', '1', '2', '9', '1', '1', '2', '9', '9', '8', '8', '11', '9', '4', '1', '8', '2', '7', '1', '2', '8', '2', '9', '9', '8', '2', '9', '9', '8', '8', '1', '2', '8', '1', '1', '2', '9', '8', '1', '4', '9', '1', '8', '12', '1', '12', '2', '8', '2', '9', '1', '12', '1', '2', '9', '1', '1', '9', '3', '2', '9', '9', '2', '11', '8', '7', '9', '9', '9', '8', '8', '1', '2', '8', '1', '1', '4', '1', '2', '10', '1', '9', '2', '1', '1', '1', '9', '1', '13', '4', '3', '2', '1', '1', '2', '2', '7', '8', '7', '1', '1', '2', '8', '8', '3', '4', '8', '2', '10', '13', '8', '8', '9', '2', '2', '1', '1', '10', '4', '2', '7', '9', '8', '2', '1', '9', '8', '1', '1', '9', '8', '9', '8', '2', '8', '2', '2', '9', '2', '1', '9', '1', '2', '4', '8', '2', '1', '1', '8', '1', '4', '1', '9', '3', '9', '2', '7', '1', '9', '6', '1', '10', '2', '2', '2', '2', '2', '10', '10', '10', '9', '9', '9', '3', '12', '10', '1', '1', '10', '1', '1', '2', '2', '1', '2', '3', '12', '8', '8', '1', '2', '9', '9', '1', '1', '10', '8', '9', '8', '3', '1', '1', '3', '1', '10', '1', '1', '1', '4', '1', '1', '1', '7', '10', '2', '1', '8', '1', '9', '3', '1', '10', '8', '8', '1', '5', '9', '1', '2', '1', '8', '8', '1', '3', '1', '10', '2', '1', '1', '2', '8', '2', '5', '3', '5', '2', '1', '1', '9', '1', '7', '9', '9', '2', '8', '1', '12', '4', '1', '4', '9', '9', '4', '8', '1', '10', '10', '8', '8', '8', '9', '2', '3', '5', '1', '8', '1', '1', '1', '7', '10', '1', '4', '12', '3', '2', '2', '9', '1', '1', '1', '2', '8', '4', '1', '7', '3', '12', '8', '6', '2', '2', '7', '9', '11', '1', '10', '9', '1', '8', '12', '2', '11', '1', '2', '3', '1', '1', '1', '8', '9', '2', '2', '2', '2', '3', '3', '8', '10', '4', '1', '2', '9', '8', '2', '2', '9', '1', '8', '11', '4', '2', '8', '7', '1', '1', '7', '3', '9', '9', '4', '5', '8', '10', '2', '9', '9', '9', '8', '1', '9', '2', '2', '2', '1', '2', '9', '4', '3', '12', '4', '3', '2', '3', '8', '3', '10', '1', '10', '1', '1', '8', '10', '6', '8', '9', '9', '1', '2', '9', '2', '9', '3', '8', '1', '1', '12', '1', '5', '1', '10', '8', '10', '2', '7', '1', '1', '1', '1', '3', '2', '3', '5', '9', '1', '2', '1', '9', '8', '10', '9', '8', '1', '8', '1', '8', '2', '8', '1', '2', '8', '1', '2', '5', '8', '12', '2', '1', '1', '1', '1', '1', '8', '8', '2', '1', '4', '2', '8', '8', '8', '2', '9', '9', '11', '1', '2', '9', '3', '1', '1', '8', '9', '2', '4', '10', '1', '9', '8', '4', '9', '8', '10', '8', '8', '9', '2', '8', '9', '3', '3', '3', '4', '3', '2', '2', '10', '8', '2', '1', '5', '1', '9', '1', '1', '2', '1', '2', '3', '1', '1', '8', '8', '1', '10', '8', '8', '1', '6', '4', '8', '2', '5', '8', '1', '3', '8', '2', '8', '9', '1', '1', '8', '12', '10', '1', '5', '8', '2', '8', '10', '9', '9', '1', '6', '9', '1', '10', '8', '2', '9', '10', '1', '2', '1', '1', '8', '8', '3', '9', '8', '1', '10', '2', '8', '1', '10', '1', '5', '1', '1', '1', '5', '1', '1', '1', '4', '1', '1', '1', '8', '2', '8', '1', '8', '3', '8', '9', '1', '8', '1', '8', '1', '1', '2', '2', '1', '12', '9', '9', '1', '8', '2', '1', '2', '8', '1', '9', '1', '1', '2', '1', '2', '2', '2', '1', '9', '9', '8', '8', '1', '1', '9', '10', '8', '4', '3', '3', '4', '9', '1', '3', '3', '10', '2', '2', '1', '8', '4', '1', '9', '4', '1', '1', '9', '8', '10', '4', '9', '9', '8', '2', '1', '3', '4', '9', '3', '8', '9', '1', '1', '2', '1', '7', '8', '2', '9', '1', '9', '2', '6', '9', '10', '8', '1', '1', '5', '9', '5', '1', '9', '10', '9', '3', '3', '8', '8', '2', '9', '2', '8', '2', '1', '8', '5', '8', '3', '10', '1', '1', '2', '1', '8', '1', '4', '3', '2', '9', '4', '9', '8', '8', '8', '1', '3', '9', '1', '9', '9', '1', '2', '1', '9', '8', '9', '8', '1', '1', '1', '4', '2', '2', '9', '9', '1', '1', '1', '3', '6', '1', '2', '3', '1', '4', '2', '9', '1', '9', '9', '1', '8', '2', '1', '9', '1', '8', '1', '8', '8', '2', '1', '9', '9', '6', '8', '8', '9', '8', '10', '8', '9', '5', '1', '1', '1', '1', '8', '1', '8', '12', '8', '1', '12', '9', '2', '8', '1', '1', '2', '1', '8', '6', '9', '9', '8', '1', '8', '9', '7', '7', '8', '9', '9', '1', '8', '3', '8', '1', '3', '3', '8', '9', '8', '2', '8', '1', '2', '9', '8', '1', '1', '1', '1', '9', '1', '9', '8', '12', '3', '8', '8', '1', '10', '10', '10', '2', '2', '1', '10', '2', '2', '10', '8', '12', '8', '1', '1', '1', '2', '1', '1', '3', '8', '1', '2', '2', '2', '1', '1', '6', '2', '8', '8', '8', '1', '1', '1', '9', '9', '2', '8', '10', '2', '8', '2', '1', '2', '9', '9', '2', '1', '1', '8', '8', '1', '3', '1', '8', '9', '1', '10', '9', '1', '1', '1', '1', '7', '2', '2', '1', '2', '8', '8', '1', '2', '1', '3', '2', '1', '8', '3', '9', '2', '10', '2', '10', '1', '2', '1', '1', '13', '9', '10', '8', '2', '2', '1', '1', '8', '2', '2', '1', '9', '1', '1', '8', '9', '9', '2', '9', '2', '2', '1', '1', '1', '8', '9', '4', '9', '9', '1', '8', '2', '1', '1', '8', '2', '2', '2', '8', '1', '1', '8', '2', '10', '2', '9', '9', '7', '1', '1', '2', '2', '8', '3', '1', '2', '1', '1', '8', '1', '1', '1', '9', '1', '1', '8', '8', '1', '9', '6', '1', '9', '1', '8', '1', '8', '8', '8', '1', '3', '8', '8', '2', '6', '3', '2', '1', '10', '1', '8', '2', '1', '6', '1', '1', '1', '8', '1', '10', '1', '1', '8', '9', '2', '6', '9', '2', '9', '4', '1', '8', '1', '3', '7', '8', '8', '5', '8', '7', '1', '1', '1', '13', '8', '3', '1', '1', '1', '1', '2', '8', '2', '12', '8', '1', '2', '5', '1', '8', '2', '10', '8', '2', '10', '1', '5', '2', '1', '1', '5', '2', '2', '7', '8', '2', '9', '9', '1', '10', '1', '8', '2', '5', '8', '1', '5', '1', '10', '1', '1', '9', '8', '6', '1', '8', '9', '8', '1', '8', '2', '2', '8', '3', '9', '1', '9', '3', '8', '4', '4', '3', '3', '1', '1', '1', '8', '9', '1', '1', '8', '3', '1', '2', '8', '2', '1', '1', '10', '1', '2', '2', '1', '1', '8', '2', '8', '2', '10', '2', '2', '10', '8', '8', '8', '13', '2', '2', '9', '2', '5', '9', '2', '1', '8', '8', '8', '1', '12', '12', '2', '9', '2', '1', '8', '2', '1', '8', '1', '9', '9', '2', '7', '1', '1', '7', '1', '4', '3', '1', '10', '3', '10', '9', '4', '6', '7', '5', '2', '1', '8', '8', '1', '4', '9', '2', '1', '8', '1', '1', '1', '1', '1', '8', '9', '8', '8', '8', '8', '9', '8', '10', '1', '8', '2', '7', '8', '9', '1', '2', '5', '9', '10', '8', '9', '12', '1', '6', '1', '2', '10', '9', '4', '1', '8', '10', '10', '1', '1', '1', '1', '1', '2', '3', '8', '1', '2', '10', '2', '1', '2', '4', '2', '2', '9', '1', '4', '2', '1', '1', '12', '12', '9', '9', '7', '1', '8', '4', '9', '9', '8', '1', '7', '3', '2', '1', '1', '4', '8', '1', '5', '8', '2', '8', '1', '14', '9', '12', '1', '10', '2', '1', '1', '8', '8', '6', '6', '3', '1', '2', '8', '1', '3', '2', '1', '8', '8', '1', '10', '8', '2', '8', '2', '5', '9', '1', '8', '8', '1', '1', '8', '8', '13', '1', '3', '8', '4', '1', '9', '7', '8', '8', '8', '3', '8', '1', '4', '2', '8', '8', '8', '7', '1', '1', '2', '8', '8', '9', '8', '8', '2', '3', '9', '9', '2', '1', '2', '2', '1', '8', '2', '6', '2', '1', '1', '9', '10', '3', '8', '2', '3', '2', '8', '8', '1', '8', '8', '8', '9', '1', '4', '1', '9', '2', '1', '8', '0', '1', '8', '1', '1', '8', '9', '9', '1', '3', '1', '2', '8', '8', '7', '1', '1', '2', '9', '2', '10', '2', '8', '2', '2', '2', '7', '1', '9', '8', '1', '3', '9', '2', '1', '10', '8', '1', '4', '1', '8', '5', '9', '8', '8', '1', '2', '2', '1', '8', '8', '6', '8', '1', '1', '8', '3', '2', '2', '1', '8', '1', '7', '6', '8', '1', '1', '1', '9', '1', '1', '1', '2', '1', '11', '10', '10', '11', '9', '']\n",
            "['8', '1', '8', '2', '8', '8', '8', '9', '7', '8', '1', '2', '1', '1', '8', '4', '8', '8', '12', '3', '3', '7', '3', '12', '1', '8', '8', '8', '8', '8', '8', '8', '1', '9', '5', '9', '9', '9', '11', '8', '8', '8', '4', '8', '8', '8', '8', '1', '3', '9', '3', '7', '1', '2', '9', '9', '7', '8', '8', '1', '10', '7', '8', '8', '9', '8', '7', '9', '9', '12', '7', '2', '8', '1', '11', '11', '1', '7', '7', '12', '1', '9', '8', '10', '12', '7', '8', '2', '8', '9', '9', '1', '8', '9', '1', '7', '12', '10', '10', '10', '8', '3', '7', '9', '8', '9', '1', '8', '8', '2', '7', '2', '9', '9', '11', '8', '8', '12', '12', '7', '8', '12', '4', '9', '3', '1', '12', '1', '1', '8', '8', '3', '8', '8', '8', '8', '9', '1', '8', '8', '10', '1', '8', '2', '8', '8', '7', '3', '8', '2', '4', '4', '9', '8', '10', '12', '12', '1', '1', '9', '1', '1', '1', '8', '2', '2', '8', '1', '1', '2', '2', '1', '2', '8', '1', '9', '9', '8', '8', '4', '2', '9', '9', '8', '3', '4', '3', '1', '8', '8', '2', '1', '9', '7', '8', '8', '1', '12', '3', '8', '2', '4', '2', '9', '12', '1', '4', '1', '8', '8', '8', '2', '2', '8', '9', '8', '8', '8', '10', '9', '8', '7', '9', '1', '1', '9', '4', '2', '4', '2', '2', '1', '7', '8', '11', '11', '3', '9', '2', '4', '8', '9', '1', '8', '1', '1', '4', '9', '1', '1', '8', '8', '2', '1', '8', '4', '2', '8', '9', '8', '8', '2', '8', '8', '8', '7', '1', '1', '1', '2', '1', '1', '8', '7', '8', '8', '12', '2', '12', '12', '8', '10', '12', '8', '3', '3', '12', '10', '1', '8', '12', '1', '8', '8', '2', '8', '4', '7', '8', '7', '10', '8', '10', '9', '8', '12', '12', '1', '8', '8', '3', '8', '8', '8', '8', '8', '1', '9', '8', '11', '1', '1', '1', '9', '8', '1', '9', '2', '3', '11', '8', '9', '9', '9', '2', '1', '8', '8', '9', '7', '1', '4', '9', '4', '8', '8', '4', '8', '12', '9', '4', '8', '2', '10', '10', '10', '8', '9', '9', '8', '8', '12', '7', '1', '8', '8', '8', '4', '1', '1', '1', '1', '1', '1', '8', '1', '9', '8', '9', '9', '4', '8', '12', '9', '8', '8', '2', '8', '8', '8', '6', '9', '8', '3', '7', '8', '8', '4', '12', '8', '8', '9', '12', '12', '9', '8', '2', '9', '2', '3', '1', '12', '8', '10', '9', '9', '9', '10', '10', '3', '8', '12', '1', '4', '2', '1', '10', '8', '2', '8', '4', '8', '9', '1', '9', '9', '10', '10', '1', '4', '9', '2', '4', '9', '1', '1', '3', '10', '3', '3', '8', '7', '3', '8', '9', '9', '12', '4', '8', '12', '2', '2', '4', '1', '9', '9', '4', '1', '4', '2', '8', '12', '2', '3', '10', '10', '9', '8', '9', '9', '1', '12', '8', '8', '8', '12', '4', '1', '8', '8', '1', '9', '8', '8', '2', '1', '8', '9', '8', '3', '3', '3', '1', '8', '8', '9', '1', '10', '9', '9', '9', '9', '5', '9', '9', '8', '8', '8', '8', '8', '8', '8', '8', '11', '12', '8', '8', '1', '8', '9', '11', '2', '2', '2', '2', '3', '1', '2', '2', '8', '2', '4', '9', '1', '2', '9', '8', '2', '8', '9', '9', '3', '10', '9', '9', '2', '8', '9', '8', '12', '12', '1', '3', '8', '8', '8', '2', '7', '7', '7', '7', '3', '9', '1', '9', '8', '9', '9', '1', '1', '1', '2', '9', '9', '9', '11', '1', '8', '8', '9', '1', '9', '8', '8', '8', '1', '1', '8', '7', '1', '1', '8', '8', '9', '4', '4', '8', '2', '2', '8', '8', '8', '8', '8', '8', '11', '8', '2', '9', '4', '9', '3', '9', '9', '1', '3', '9', '3', '1', '12', '8', '9', '12', '1', '8', '4', '2', '1', '4', '8', '3', '3', '8', '2', '8', '9', '7', '8', '8', '8', '5', '8', '3', '9', '8', '8', '13', '12', '1', '1', '2', '8', '4', '1', '9', '9', '12', '8', '9', '12', '9', '1', '9', '9', '9', '9', '3', '2', '9', '9', '4', '8', '12', '2', '4', '9', '3', '1', '9', '7', '8', '9', '9', '8', '4', '8', '8', '7', '9', '10', '3', '8', '8', '8', '1', '1', '1', '1', '8', '8', '4', '1', '10', '1', '5', '7', '7', '1', '8', '9', '3', '7', '2', '7', '7', '2', '4', '8', '12', '7', '4', '2', '9', '9', '12', '6', '10', '8', '2', '4', '12', '9', '9', '3', '8', '8', '1', '2', '10', '9', '9', '8', '4', '12', '2', '1', '8', '8', '8', '12', '10', '10', '9', '3', '8', '8', '9', '2', '8', '10', '1', '1', '1', '1', '2', '1', '1', '1', '1', '9', '8', '12', '9', '4', '8', '8', '9', '1', '9', '3', '9', '8', '8', '1', '7', '7', '10', '1', '8', '8', '1', '9', '8', '10', '3', '1', '7', '1', '8', '8', '12', '8', '8', '1', '8', '7', '1', '7', '7', '8', '2', '1', '8', '8', '2', '10', '8', '8', '8', '8', '8', '10', '1', '8', '8', '12', '8', '3', '3', '2', '2', '2', '10', '8', '8', '8', '2', '9', '1', '8', '9', '3', '2', '8', '10', '8', '6', '1', '1', '8', '4', '1', '9', '10', '8', '1', '7', '1', '2', '8', '1', '1', '1', '12', '1', '9', '12', '8', '12', '12', '12', '8', '8', '12', '4', '8', '8', '8', '8', '9', '9', '1', '3', '3', '3', '3', '1', '12', '12', '9', '10', '8', '8', '1', '9', '2', '2', '13', '9', '8', '9', '2', '1', '9', '1', '8', '8', '8', '4', '8', '1', '1', '1', '12', '12', '7', '2', '2', '2', '8', '3', '8', '9', '2', '10', '7', '8', '9', '2', '1', '2', '12', '12', '8', '8', '9', '2', '2', '9', '11', '1', '8', '1', '10', '9', '2', '1', '4', '7', '7', '7', '7', '7', '12', '8', '8', '8', '1', '1', '10', '1', '12', '1', '8', '2', '1', '1', '12', '8', '7', '9', '12', '8', '9', '3', '9', '8', '8', '8', '8', '3', '11', '2', '2', '9', '8', '8', '10', '8', '2', '7', '3', '1', '4', '7', '8', '8', '1', '8', '3', '7', '12', '8', '10', '9', '9', '8', '8', '2', '8', '9', '9', '1', '2', '8', '8', '9', '8', '3', '8', '1', '8', '10', '9', '8', '9', '9', '12', '4', '4', '8', '9', '9', '8', '2', '10', '1', '2', '8', '9', '1', '9', '9', '9', '7', '12', '12', '8', '1', '1', '1', '1', '8', '3', '1', '1', '8', '1', '8', '8', '7', '8', '8', '8', '8', '3', '2', '2', '10', '10', '10', '7', '8', '1', '2', '12', '7', '9', '8', '7', '8', '12', '2', '8', '9', '2', '6', '6', '7', '9', '8', '1', '8', '9', '8', '1', '12', '1', '2', '8', '7', '7', '7', '8', '2', '2', '8', '1', '2', '2', '9', '9', '1', '8', '8', '4', '3', '3', '1', '6', '3', '3', '12', '3', '8', '9', '1', '4', '3', '1', '8', '3', '9', '2', '8', '2', '8', '8', '8', '1', '1', '1', '9', '9', '8', '1', '9', '8', '1', '1', '3', '10', '8', '1', '1', '3', '9', '1', '4', '4', '1', '8', '9', '9', '2', '0', '0', '1', '8', '3', '1', '8', '8', '9', '8', '8', '1', '1', '8', '9', '8', '8', '8', '7', '9', '8', '8', '8', '10', '9', '8', '1', '2', '6', '1', '9', '9', '8', '12', '12', '12', '8', '8', '2', '8', '1', '2', '2', '2', '1', '9', '8', '2', '12', '2', '8', '12', '8', '9', '8', '8', '9', '7', '1', '1', '1', '1', '1', '8', '8', '1', '8', '8', '1', '1', '3', '2', '8', '8', '9', '10', '10', '2', '2', '1', '9', '2', '9', '9', '4', '12', '12', '12', '10', '7', '3', '3', '4', '2', '2', '9', '2', '8', '4', '2', '4', '1', '10', '9', '7', '8', '7', '1', '1', '3', '3', '1', '1', '3', '3', '3', '1', '1', '1', '1', '8', '2', '3', '1', '1', '2', '8', '8', '12', '8', '8', '8', '8', '11', '9', '1', '8', '9', '2', '8', '8', '8', '3', '9', '1', '9', '2', '7', '2', '8', '2', '8', '10', '8', '1', '10', '1', '1', '9', '9', '8', '8', '1', '8', '8', '8', '12', '8', '8', '8', '1', '8', '8', '8', '1', '9', '1', '1', '8', '1', '8', '9', '8', '2', '12', '9', '9', '0', '1', '8', '8', '1', '8', '12', '8', '8', '10', '8', '8', '8', '7', '8', '1', '8', '7', '3', '10', '1', '8', '9', '1', '8', '8', '8', '10', '1', '10', '3', '9', '1', '8', '9', '2', '8', '3', '3', '9', '9', '7', '9', '1', '1', '9', '2', '1', '1', '1', '7', '1', '1', '8', '8', '1', '1', '8', '1', '8', '3', '12', '9', '3', '3', '8', '8', '8', '8', '3', '1', '3', '3', '1', '11', '0', '8', '8', '7', '8', '12', '1', '8', '9', '8', '9', '8', '8', '3', '8', '8', '1', '1', '1', '9', '2', '2', '2', '8', '7', '12', '8', '8', '9', '10', '10', '7', '8', '1', '9', '8', '7', '3', '1', '3', '8', '2', '2', '3', '9', '8', '4', '4', '8', '9', '2', '1', '1', '7', '8', '9', '9', '7', '8', '7', '7', '8', '2', '2', '8', '4', '9', '7', '10', '0', '9', '8', '3', '7', '8', '1', '1', '8', '9', '9', '2', '2', '10', '1', '9', '10', '10', '10', '8', '3', '2', '12', '9', '9', '10', '12', '9', '12', '12', '9', '1', '2', '4', '12', '12', '7', '8', '9', '7', '7', '7', '3', '9', '8', '9', '1', '12', '8', '9', '4', '1', '3', '12', '12', '12', '12', '8', '8', '2', '1', '1', '2', '1', '1', '1', '12', '12', '8', '12', '2', '2', '12', '3', '3', '12', '8', '2', '8', '8', '12', '2', '1', '10', '3', '2', '8', '7', '1', '8', '1', '3', '7', '8', '9', '8', '3', '1', '1', '7', '8', '8', '9', '8', '2', '9', '2', '2', '9', '8', '1', '8', '8', '1', '3', '3', '1', '1', '10', '1', '2', '8', '1', '1', '1', '1', '9', '1', '4', '1', '7', '7', '7', '7', '2', '2', '8', '8', '12', '1', '9', '1', '7', '3', '3', '1', '8', '8', '10', '8', '9', '2', '9', '1', '3', '8', '8', '3', '12', '2', '8', '12', '2', '9', '1', '3', '3', '3', '3', '2', '8', '7', '9', '8', '3', '3', '1', '7', '8', '3', '1', '1', '12', '8', '9', '1', '2', '3', '8', '1', '1', '3', '3', '9', '1', '1', '1', '12', '1', '7', '3', '3', '1', '8', '8', '8', '1', '2', '4', '8', '1', '10', '2', '5', '3', '3', '12', '10', '9', '9', '12', '9', '0', '2', '8', '8', '9', '9', '9', '8', '1', '3', '1', '1', '4', '8', '1', '10', '8', '7', '2', '8', '2', '8', '4', '7', '8', '1', '9', '1', '9', '8', '2', '8', '2', '7', '9', '2', '2', '9', '1', '8', '12', '1', '8', '1', '4', '1', '9', '9', '1', '10', '12', '4', '8', '1', '7', '3', '9', '2', '12', '7', '8', '8', '2', '1', '12', '9', '8', '1', '2', '2', '8', '10', '2', '1', '7', '7', '7', '12', '3', '3', '8', '3', '8', '8', '3', '9', '8', '9', '1', '1', '8', '7', '9', '3', '3', '8', '1', '0', '9', '9', '9', '1', '8', '9', '9', '10', '1', '8', '7', '8', '8', '8', '9', '9', '8', '9', '10', '4', '9', '3', '7', '12', '1', '9', '9', '8', '9', '1', '9', '3', '1', '8', '4', '12', '10', '9', '8', '7', '10', '8', '12', '12', '3', '10', '8', '12', '2', '1', '2', '3', '9', '8', '8', '7', '1', '1', '2', '2', '1', '2', '2', '7', '1', '3', '9', '9', '3', '8', '8', '8', '8', '8', '7', '8', '8', '10', '8', '1', '8', '2', '8', '2', '2', '2', '2', '2', '1', '7', '12', '10', '1', '2', '8', '1', '4', '7', '8', '1', '12', '8', '7', '9', '2', '2', '2', '8', '1', '8', '1', '1', '0', '2', '2', '6', '1', '8', '2', '1', '8', '1', '1', '2', '2', '3', '2', '2', '10', '10', '9', '1', '7', '7', '8', '8', '1', '12', '10', '12', '3', '8', '8', '8', '3', '8', '3', '10', '2', '2', '2', '1', '2', '2', '1', '0', '1', '8', '9', '1', '1', '1', '2', '2', '2', '2', '2', '1', '1', '1', '1', '12', '9', '9', '1', '10', '11', '12', '9', '1', '1', '8', '8', '1', '2', '12', '8', '3', '7', '2', '10', '9', '7', '8', '1', '2', '2', '7', '9', '12', '2', '2', '1', '8', '9', '2', '3', '2', '2', '2', '9', '9', '8', '9', '2', '3', '8', '8', '9', '7', '3', '10', '8', '8', '9', '1', '1', '2', '8', '1', '10', '8', '8', '9', '7', '1', '7', '12', '8', '1', '7', '2', '1', '3', '9', '2', '8', '8', '1', '2', '3', '9', '3', '8', '9', '7', '7', '1', '10', '2', '8', '8', '8', '1', '8', '2', '8', '8', '1', '2', '8', '10', '2', '1', '0', '8', '3', '8', '10', '10', '12', '3', '8', '9', '3', '10', '8', '8', '8', '1', '8', '8', '2', '2', '2', '2', '2', '2', '1', '1', '10', '1', '10', '8', '2', '1', '2', '2', '8', '3', '3', '2', '2', '1', '8', '1', '3', '1', '9', '2', '2', '1', '3', '2', '2', '3', '2', '2', '3', '2', '1', '1', '2', '1', '2', '7', '8', '2', '1', '12', '12', '3', '1', '9', '9', '7', '8', '7', '2', '7', '9', '2', '2', '2', '8', '9', '7', '9', '2', '8', '9', '9', '2', '9', '1', '1', '9', '8', '3', '3', '8', '2', '7', '8', '11', '2', '8', '9', '1', '8', '3', '1', '2', '1', '2', '2', '2', '2', '8', '3', '9', '2', '10', '9', '9', '2', '7', '7', '7', '1', '3', '8', '8', '1', '1', '8', '7', '1', '8', '8', '9', '3', '3', '3', '2', '4', '8', '12', '8', '1', '12', '9', '2', '8', '2', '12', '2', '1', '3', '8', '12', '12', '11', '8', '10', '9', '2', '9', '4', '10', '1', '12', '12', '9', '3', '8', '9', '12', '9', '9', '2', '2', '2', '3', '5', '1', '1', '1', '7', '7', '8', '2', '2', '8', '2', '1', '7', '3', '2', '9', '8', '9', '1', '1', '9', '8', '9', '3', '3', '2', '9', '4', '9', '8', '8', '1', '8', '10', '2', '0', '3', '8', '8', '8', '9', '12', '9', '8', '2', '2', '8', '10', '9', '8', '2', '2', '4', '1', '9', '9', '8', '8', '10', '3', '1', '1', '2', '8', '7', '8', '2', '1', '1', '8', '12', '2', '9', '4', '8', '3', '3', '3', '8', '2', '12', '12', '8', '9', '12', '8', '2', '12', '7', '9', '2', '2', '1', '3', '1', '3', '11', '9', '8', '1', '10', '2', '12', '3', '8', '4', '1', '2', '8', '8', '3', '9', '3', '8', '7', '1', '1', '3', '1', '8', '2', '9', '8', '12', '1', '1', '1', '9', '9', '1', '8', '8', '8', '2', '2', '12', '3', '1', '1', '1', '9', '9', '3', '2', '1', '1', '9', '9', '1', '9', '9', '1', '9', '3', '9', '1', '8', '1', '9', '8', '3', '8', '8', '9', '9', '8', '2', '8', '1', '2', '2', '10', '1', '2', '1', '1', '9', '1', '9', '3', '7', '7', '2', '10', '3', '3', '1', '1', '9', '1', '2', '1', '3', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '8', '8', '7', '1', '1', '8', '8', '2', '1', '12', '1', '8', '1', '9', '8', '8', '2', '1', '9', '9', '2', '2', '8', '1', '7', '7', '9', '8', '1', '6', '8', '8', '2', '2', '8', '3', '8', '3', '2', '3', '8', '1', '2', '2', '2', '8', '9', '9', '9', '12', '1', '9', '2', '1', '9', '2', '9', '9', '10', '8', '1', '1', '9', '2', '1', '7', '1', '3', '7', '1', '1', '1', '3', '8', '8', '8', '9', '9', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '1', '0', '1', '1', '1', '2', '2', '3', '1', '1', '2', '3', '3', '3', '7', '3', '1', '9', '3', '9', '1', '4', '1', '1', '9', '10', '9', '8', '2', '3', '10', '9', '3', '10', '12', '8', '9', '8', '2', '1', '9', '8', '1', '7', '8', '1', '9', '1', '2', '10', '7', '7', '8', '1', '3', '3', '9', '3', '3', '1', '1', '1', '9', '1', '3', '8', '8', '8', '1', '8', '1', '9', '7', '8', '8', '2', '1', '3', '8', '2', '1', '6', '1', '8', '8', '2', '8', '2', '2', '9', '8', '1', '1', '6', '8', '6', '10', '2', '1', '1', '8', '9', '3', '3', '3', '1', '3', '9', '6', '8', '1', '8', '3', '1', '2', '2', '12', '7', '1', '1', '1', '1', '12', '1', '8', '8', '3', '2', '1', '9', '2', '3', '3', '2', '2', '7', '2', '2', '2', '3', '1', '9', '8', '7', '1', '1', '3', '1', '9', '4', '3', '9', '2', '1', '1', '9', '8', '8', '7', '2', '1', '3', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '10', '1', '1', '8', '2', '8', '1', '8', '1', '3', '1', '2', '1', '1', '3', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '8', '1', '9', '8', '8', '1', '10', '8', '8', '1', '3', '9', '8', '9', '8', '2', '1', '3', '4', '1', '12', '1', '9', '8', '2', '7', '2', '1', '2', '9', '2', '1', '3', '8', '1', '2', '3', '8', '2', '10', '10', '10', '9', '9', '9', '3', '8', '3', '1', '1', '1', '1', '1', '1', '2', '1', '9', '2', '7', '9', '8', '7', '9', '1', '1', '1', '1', '8', '2', '2', '3', '3', '2', '12', '8', '3', '1', '1', '12', '9', '8', '2', '2', '9', '1', '2', '2', '9', '1', '1', '2', '4', '8', '1', '8', '10', '2', '9', '9', '9', '1', '2', '1', '1', '2', '2', '2', '12', '1', '2', '8', '3', '9', '9', '3', '2', '9', '9', '7', '2', '8', '8', '9', '2', '9', '1', '1', '1', '1', '1', '2', '8', '2', '1', '2', '2', '8', '3', '1', '1', '9', '1', '3', '10', '7', '9', '8', '8', '2', '2', '9', '2', '2', '2', '2', '2', '2', '9', '1', '3', '6', '4', '2', '2', '9', '1', '9', '8', '1', '1', '1', '7', '3', '2', '9', '9', '1', '9', '7', '2', '8', '9', '9', '12', '10', '8', '10', '2', '3', '1', '2', '2', '12', '12', '3', '12', '1', '2', '1', '2', '1', '2', '8', '2', '3', '12', '12', '8', '2', '2', '9', '2', '9', '2', '3', '3', '1', '1', '1', '12', '3', '7', '1', '3', '1', '2', '9', '2', '7', '2', '1', '8', '3', '7', '8', '1', '1', '3', '8', '3', '2', '9', '3', '1', '1', '1', '1', '11', '1', '2', '6', '1', '2', '3', '8', '9', '9', '2', '9', '2', '1', '1', '3', '1', '12', '9', '1', '1', '9', '1', '9', '9', '8', '9', '8', '1', '2', '7', '1', '0', '9', '8', '2', '3', '2', '4', '1', '1', '1', '8', '1', '12', '1', '2', '3', '3', '9', '9', '9', '9', '9', '7', '9', '3', '9', '1', '7', '3', '3', '3', '3', '7', '8', '2', '2', '2', '8', '2', '3', '9', '9', '3', '1', '8', '9', '12', '8', '8', '3', '2', '1', '6', '1', '9', '1', '1', '1', '1', '1', '1', '2', '2', '1', '2', '2', '2', '2', '9', '2', '5', '3', '2', '2', '8', '2', '1', '8', '3', '3', '8', '3', '1', '3', '9', '2', '8', '9', '4', '4', '9', '8', '8', '7', '7', '3', '1', '8', '8', '3', '2', '2', '10', '3', '3', '2', '2', '2', '2', '12', '3', '1', '2', '7', '7', '12', '2', '1', '2', '1', '1', '2', '1', '3', '3', '3', '1', '3', '9', '4', '8', '8', '4', '2', '4', '2', '8', '9', '1', '1', '2', '2', '2', '8', '7', '2', '8', '2', '9', '1', '8', '1', '1', '2', '1', '1', '1', '2', '9', '9', '8', '1', '8', '1', '4', '8', '1', '2', '7', '9', '2', '1', '8', '9', '8', '9', '1', '1', '2', '3', '2', '12', '7', '1', '2', '4', '4', '4', '2', '2', '2', '9', '8', '8', '1', '12', '3', '3', '2', '2', '3', '12', '1', '5', '1', '1', '3', '2', '8', '8', '2', '2', '2', '3', '9', '8', '8', '9', '8', '8', '11', '8', '2', '9', '2', '3', '1', '7', '1', '8', '2', '8', '1', '1', '1', '8', '1', '1', '1', '7', '8', '8', '2', '3', '2', '1', '8', '8', '1', '8', '4', '8', '9', '8', '9', '8', '1', '2', '3', '2', '1', '2', '2', '3', '1', '9', '4', '8', '1', '1', '9', '1', '1', '8', '2', '2', '2', '1', '7', '3', '3', '1', '3', '3', '12', '3', '1', '1', '3', '1', '1', '4', '8', '4', '4', '3', '3', '3', '4', '8', '1', '9', '9', '9', '4', '1', '7', '4', '8', '4', '9', '8', '1', '1', '3', '8', '9', '1', '9', '7', '1', '1', '9', '1', '8', '8', '8', '1', '1', '8', '2', '2', '2', '9', '4', '4', '1', '2', '1', '2', '9', '1', '1', '8', '5', '5', '5', '9', '12', '4', '1', '2', '1', '8', '8', '1', '9', '9', '2', '12', '1', '1', '7', '8', '8', '4', '1', '2', '8', '11', '2', '3', '2', '2', '1', '11', '2', '2', '2', '2', '9', '9', '2', '2', '9', '3', '1', '9', '1', '1', '1', '7', '8', '1', '8', '9', '1', '2', '9', '8', '1', '2', '9', '8', '12', '2', '2', '10', '8', '2', '2', '8', '8', '1', '2', '6', '1', '1', '7', '7', '2', '3', '2', '1', '1', '8', '1', '10', '8', '12', '6', '4', '1', '4', '1', '2', '9', '8', '9', '4', '8', '8', '10', '8', '8', '8', '8', '8', '2', '2', '8', '4', '9', '3', '3', '3', '3', '3', '9', '2', '1', '1', '2', '3', '2', '1', '2', '3', '3', '3', '2', '2', '3', '3', '2', '1', '2', '3', '3', '3', '3', '12', '9', '3', '2', '2', '3', '1', '5', '1', '1', '3', '2', '2', '1', '2', '9', '3', '9', '8', '1', '8', '7', '7', '9', '1', '1', '7', '9', '10', '1', '7', '1', '4', '3', '8', '9', '4', '9', '9', '2', '9', '2', '8', '4', '2', '2', '9', '5', '2', '1', '10', '9', '3', '1', '1', '1', '2', '1', '2', '9', '1', '7', '9', '9', '8', '2', '2', '8', '9', '1', '9', '8', '2', '3', '2', '2', '1', '2', '2', '2', '1', '1', '8', '1', '9', '4', '12', '8', '2', '7', '2', '2', '1', '9', '3', '1', '8', '12', '1', '1', '2', '1', '10', '2', '6', '12', '12', '4', '9', '1', '9', '10', '1', '2', '8', '2', '1', '8', '6', '12', '9', '9', '2', '1', '7', '8', '9', '5', '8', '1', '8', '8', '3', '1', '8', '2', '8', '2', '2', '1', '2', '9', '2', '8', '1', '12', '8', '2', '7', '3', '3', '12', '2', '3', '3', '9', '9', '3', '3', '3', '3', '3', '2', '1', '4', '1', '4', '8', '8', '2', '1', '2', '9', '12', '1', '10', '12', '1', '2', '9', '4', '8', '10', '3', '2', '8', '7', '4', '8', '9', '2', '7', '1', '10', '2', '2', '2', '8', '4', '2', '2', '1', '1', '8', '7', '9', '2', '1', '9', '8', '9', '12', '4', '8', '2', '8', '7', '7', '1', '9', '2', '1', '1', '9', '1', '8', '2', '3', '9', '9', '1', '3', '2', '9', '2', '2', '8', '1', '1', '2', '1', '2', '1', '9', '8', '2', '2', '4', '8', '8', '9', '5', '5', '9', '8', '9', '6', '2', '1', '12', '2', '3', '8', '8', '9', '2', '2', '1', '3', '2', '10', '9', '10', '7', '2', '8', '4', '2', '8', '9', '8', '1', '3', '8', '8', '1', '8', '3', '8', '8', '1', '10', '3', '1', '5', '8', '8', '9', '2', '2', '9', '2', '1', '9', '1', '4', '1', '12', '8', '8', '2', '1', '1', '1', '1', '1', '9', '2', '9', '8', '9', '5', '9', '1', '8', '2', '4', '1', '1', '1', '9', '12', '4', '1', '1', '9', '8', '4', '1', '8', '9', '8', '8', '9', '9', '9', '9', '9', '9', '1', '3', '4', '2', '2', '8', '2', '9', '2', '3', '8', '3', '1', '7', '2', '1', '1', '4', '2', '9', '2', '1', '3', '2', '9', '2', '9', '3', '8', '1', '9', '1', '1', '2', '8', '8', '8', '2', '3', '9', '9', '8', '2', '4', '1', '5', '1', '1', '9', '9', '2', '1', '1', '1', '9', '9', '1', '3', '9', '2', '2', '9', '9', '8', '3', '9', '9', '8', '2', '2', '8', '9', '2', '2', '8', '9', '10', '10', '2', '8', '7', '9', '9', '4', '2', '4', '11', '2', '1', '7', '8', '8', '8', '9', '4', '9', '8', '8', '2', '1', '1', '9', '8', '3', '3', '8', '8', '7', '9', '1', '3', '4', '8', '10', '2', '4', '4', '8', '2', '8', '2', '8', '9', '2', '1', '2', '2', '3', '1', '9', '4', '5', '9', '9', '1', '1', '1', '1', '1', '1', '7', '1', '1', '1', '8', '1', '1', '1', '1', '1', '9', '1', '2', '1', '12', '9', '3', '9', '9', '4', '1', '9', '1', '1', '2', '11', '9', '3', '2', '2', '2', '4', '2', '3', '2', '7', '7', '8', '1', '10', '9', '5', '7', '1', '10', '8', '1', '2', '7', '1', '12', '5', '8', '4', '2', '9', '9', '8', '2', '9', '8', '8', '10', '2', '3', '2', '7', '2', '8', '10', '3', '2', '9', '9', '9', '1', '1', '1', '1', '8', '2', '10', '9', '8', '1', '2', '2', '2', '1', '2', '1', '3', '9', '12', '2', '2', '4', '8', '1', '3', '9', '4', '9', '1', '9', '9', '2', '1', '1', '9', '7', '10', '3', '10', '2', '9', '2', '9', '2', '8', '2', '1', '2', '3', '1', '1', '1', '8', '5', '8', '3', '1', '1', '4', '2', '2', '1', '3', '8', '2', '1', '1', '1', '2', '9', '4', '1', '8', '1', '2', '8', '2', '9', '2', '2', '5', '5', '2', '5', '2', '1', '8', '8', '1', '3', '12', '2', '4', '3', '2', '2', '2', '6', '2', '3', '3', '1', '8', '2', '2', '1', '1', '8', '8', '10', '1', '9', '2', '9', '12', '0', '2', '1', '3', '2', '2', '1', '2', '1', '9', '9', '2', '9', '8', '8', '1', '7', '8', '1', '2', '6', '9', '8', '10', '1', '12', '2', '2', '1', '8', '2', '1', '12', '7', '4', '2', '10', '2', '2', '1', '2', '1', '2', '1', '1', '2', '1', '9', '8', '10', '2', '10', '9', '9', '12', '5', '3', '2', '8', '2', '8', '3', '3', '1', '4', '9', '10', '2', '4', '8', '1', '2', '10', '12', '12', '3', '1', '1', '2', '9', '6', '6', '1', '9', '1', '8', '1', '8', '8', '8', '8', '2', '2', '2', '8', '8', '2', '1', '1', '1', '1', '1', '8', '8', '5', '8', '8', '1', '8', '9', '9', '1', '7', '12', '9', '9', '7', '2', '2', '7', '8', '9', '8', '2', '9', '6', '3', '4', '8', '4', '1', '2', '9', '8', '8', '8', '2', '1', '1', '8', '8', '3', '1', '9', '9', '7', '1', '2', '2', '2', '9', '4', '1', '2', '12', '1', '8', '2', '1', '9', '1', '8', '9', '9', '2', '5', '4', '2', '1', '2', '8', '12', '8', '10', '3', '8', '8', '8', '2', '2', '8', '2', '8', '2', '4', '8', '10', '2', '7', '2', '1', '8', '8', '9', '5', '8', '1', '12', '7', '10', '2', '2', '2', '1', '4', '8', '12', '1', '8', '2', '2', '9', '1', '8', '3', '1', '1', '5', '10', '2', '1', '2', '4', '8', '9', '3', '2', '8', '7', '4', '4', '9', '9', '2', '8', '1', '1', '2', '4', '7', '1', '9', '1', '1', '1', '8', '4', '1', '3', '1', '2', '2', '9', '1', '8', '8', '2', '2', '9', '9', '1', '8', '8', '1', '9', '8', '8', '2', '2', '2', '2', '1', '1', '1', '7', '4', '1', '1', '4', '2', '3', '3', '2', '3', '9', '2', '8', '2', '1', '5', '1', '2', '2', '1', '3', '5', '2', '9', '1', '1', '9', '8', '1', '4', '8', '1', '8', '2', '4', '8', '4', '7', '9', '8', '1', '2', '2', '4', '4', '11', '3', '11', '1', '3', '8', '1', '9', '6', '8', '9', '3', '9', '8', '9', '2', '3', '3', '7', '1', '7', '2', '9', '9', '1', '8', '8', '1', '5', '5', '8', '8', '1', '2', '1', '3', '9', '9', '5', '9', '8', '1', '4', '3', '8', '1', '1', '2', '1', '8', '9', '8', '2', '2', '2', '1', '2', '4', '10', '8', '1', '9', '1', '8', '1', '1', '9', '9', '8', '11', '1', '8', '2', '1', '2', '8', '2', '8', '8', '2', '9', '6', '10', '1', '8', '6', '4', '5', '11', '2', '2', '8', '1', '8', '1', '8', '1', '4', '8', '1', '1', '1', '8', '3', '7', '3', '3', '7', '1', '1', '4', '8', '1', '6', '4', '2', '2', '1', '1', '1', '1', '6', '2', '2', '8', '1', '8', '5', '5', '2', '1', '1', '2', '3', '7', '1', '1', '6', '2', '9', '3', '9', '8', '9', '2', '1', '4', '2', '9', '13', '9', '2', '8', '12', '4', '1', '1', '9', '5', '1', '1', '1', '1', '8', '2', '1', '1', '2', '9', '0', '12', '1', '1', '8', '9', '8', '3', '2', '2', '12', '8', '2', '2', '2', '1', '10', '1', '9', '8', '9', '5', '2', '2', '9', '2', '8', '4', '8', '3', '7', '9', '2', '2', '7', '2', '2', '8', '1', '1', '9', '10', '9', '8', '2', '9', '0', '7', '1', '1', '1', '9', '8', '2', '8', '12', '8', '3', '2', '8', '8', '7', '7', '8', '12', '2', '1', '3', '9', '2', '2', '8', '2', '8', '8', '12', '8', '8', '1', '8', '9', '2', '4', '4', '7', '2', '1', '1', '9', '3', '7', '1', '3', '9', '8', '2', '2', '3', '1', '3', '10', '2', '3', '7', '1', '8', '1', '1', '10', '3', '10', '8', '4', '1', '2', '4', '3', '10', '9', '3', '9', '5', '8', '7', '2', '9', '3', '3', '2', '11', '8', '1', '1', '7', '2', '7', '2', '9', '4', '8', '1', '12', '8', '7', '9', '1', '0', '2', '6', '4', '9', '3', '2', '4', '12', '9', '8', '5', '9', '2', '8', '4', '6', '8', '9', '3', '1', '8', '7', '3', '1', '1', '1', '8', '9', '1', '8', '7', '9', '8', '2', '1', '2', '2', '3', '2', '2', '1', '1', '4', '9', '7', '3', '2', '8', '8', '9', '1', '9', '7', '4', '2', '2', '8', '5', '9', '1', '5', '7', '1', '4', '6', '9', '10', '1', '8', '2', '9', '1', '9', '2', '9', '8', '2', '9', '9', '11', '2', '12', '2', '2', '9', '4', '8', '1', '9', '9', '2', '8', '9', '1', '2', '9', '3', '8', '8', '1', '7', '8', '8', '2', '3', '2', '2', '2', '2', '9', '8', '10', '2', '2', '1', '9', '11', '1', '8', '8', '2', '4', '2', '1', '2', '8', '8', '9', '2', '8', '9', '2', '3', '1', '2', '1', '3', '10', '8', '1', '2', '4', '1', '9', '8', '9', '3', '3', '9', '8', '2', '11', '3', '7', '1', '8', '7', '1', '8', '8', '8', '1', '4', '8', '8', '1', '9', '3', '1', '1', '2', '8', '8', '8', '2', '1', '8', '10', '2', '12', '8', '8', '9', '1', '8', '1', '3', '2', '2', '10', '7', '2', '2', '1', '1', '8', '2', '9', '1', '2', '9', '3', '3', '10', '1', '4', '7', '10', '12', '2', '4', '10', '8', '6', '2', '9', '1', '8', '3', '1', '2', '8', '8', '2', '12', '10', '2', '10', '9', '1', '2', '5', '8', '12', '8', '8', '7', '8', '8', '1', '8', '2', '2', '9', '1', '8', '10', '5', '5', '5', '8', '1', '9', '1', '13', '1', '2', '2', '1', '2', '4', '9', '2', '1', '9', '13', '11', '1', '9', '9', '3', '10', '8', '7', '8', '8', '4', '2', '1', '9', '4', '3', '1', '1', '10', '9', '2', '8', '6', '2', '1', '1', '3', '2', '8', '1', '1', '1', '1', '2', '4', '1', '1', '10', '1', '8', '1', '1', '9', '1', '7', '1', '1', '9', '9', '2', '12', '9', '1', '8', '1', '12', '1', '8', '3', '8', '1', '8', '1', '2', '10', '1', '1', '2', '2', '9', '3', '9', '12', '1', '9', '1', '2', '8', '7', '2', '1', '1', '3', '2', '8', '4', '4', '5', '12', '7', '8', '9', '6', '1', '8', '9', '2', '1', '9', '1', '4', '1', '8', '2', '1', '1', '8', '7', '4', '9', '1', '8', '4', '2', '7', '5', '1', '3', '9', '2', '8', '2', '1', '2', '9', '1', '1', '2', '3', '4', '3', '1', '2', '2', '10', '2', '2', '8', '1', '1', '2', '4', '9', '2', '11', '9', '8', '9', '2', '1', '10', '4', '1', '1', '10', '7', '2', '10', '8', '1', '10', '8', '8', '8', '8', '8', '8', '2', '2', '2', '8', '3', '4', '1', '1', '1', '2', '1', '8', '8', '2', '8', '3', '8', '3', '1', '2', '3', '1', '1', '10', '1', '4', '4', '3', '3', '1', '9', '1', '1', '2', '1', '1', '6', '1', '1', '1', '9', '1', '4', '1', '1', '1', '1', '1', '1', '2', '12', '8', '8', '1', '9', '12', '10', '8', '2', '12', '1', '1', '2', '1', '7', '10', '7', '1', '2', '1', '10', '8', '2', '2', '8', '2', '2', '1', '9', '8', '8', '8', '8', '3', '1', '4', '2', '8', '3', '10', '10', '1', '9', '1', '9', '1', '9', '1', '8', '3', '1', '1', '8', '8', '8', '6', '3', '4', '1', '1', '1', '9', '9', '5', '2', '10', '2', '6', '2', '2', '7', '1', '8', '2', '11', '1', '1', '1', '2', '1', '9', '4', '4', '2', '8', '4', '6', '8', '8', '10', '10', '2', '1', '2', '9', '1', '8', '8', '3', '4', '8', '8', '2', '8', '8', '1', '2', '1', '2', '9', '4', '1', '3', '3', '3', '8', '8', '8', '2', '6', '4', '3', '3', '12', '3', '4', '9', '6', '8', '7', '7', '8', '6', '4', '1', '10', '6', '3', '3', '8', '1', '1', '8', '1', '11', '8', '1', '1', '2', '3', '11', '7', '2', '1', '1', '1', '9', '1', '2', '1', '1', '9', '8', '1', '1', '8', '0', '4', '1', '1', '2', '1', '1', '2', '2', '9', '1', '10', '1', '3', '8', '9', '3', '3', '1', '10', '1', '9', '1', '1', '7', '4', '1', '8', '10', '1', '2', '10', '1', '1', '2', '3', '3', '9', '1', '8', '10', '1', '7', '9', '1', '9', '6', '3', '9', '2', '8', '4', '12', '12', '3', '1', '1', '9', '1', '9', '2', '1', '1', '1', '1', '1', '9', '2', '1', '2', '10', '9', '8', '8', '10', '8', '2', '3', '2', '1', '12', '8', '12', '2', '9', '1', '3', '2', '5', '2', '2', '8', '2', '2', '4', '10', '9', '10', '9', '4', '2', '4', '12', '8', '2', '1', '8', '3', '9', '2', '9', '4', '1', '1', '1', '1', '1', '9', '6', '2', '9', '2', '1', '3', '2', '2', '5', '8', '9', '1', '6', '3', '1', '2', '2', '2', '6', '1', '8', '10', '8', '3', '3', '13', '2', '9', '9', '10', '6', '12', '8', '2', '9', '2', '3', '8', '8', '1', '2', '2', '3', '2', '10', '1', '8', '9', '1', '8', '9', '8', '8', '2', '10', '2', '1', '1', '1', '9', '9', '12', '1', '1', '4', '8', '3', '2', '2', '4', '4', '2', '2', '1', '1', '1', '9', '2', '2', '4', '1', '1', '8', '8', '8', '9', '2', '13', '9', '9', '4', '1', '9', '7', '10', '10', '8', '1', '9', '1', '1', '1', '8', '12', '4', '1', '2', '1', '1', '1', '7', '8', '3', '3', '1', '2', '2', '7', '2', '2', '10', '1', '8', '4', '0', '1', '9', '4', '1', '1', '2', '10', '10', '7', '9', '3', '12', '11', '2', '8', '10', '8', '9', '4', '3', '4', '10', '1', '1', '9', '3', '10', '1', '5', '3', '3', '2', '2', '1', '1', '6', '1', '7', '1', '1', '12', '1', '1', '1', '10', '1', '8', '8', '1', '3', '8', '3', '1', '2', '8', '3', '4', '2', '8', '8', '6', '1', '1', '4', '1', '2', '9', '5', '1', '7', '8', '9', '2', '4', '9', '8', '5', '9', '9', '9', '1', '2', '1', '3', '8', '9', '2', '9', '8', '9', '1', '8', '13', '9', '3', '8', '1', '4', '1', '3', '1', '6', '4', '10', '2', '2', '7', '8', '8', '12', '8', '9', '9', '9', '10', '3', '12', '12', '2', '9', '10', '9', '7', '2', '3', '4', '10', '10', '2', '7', '7', '1', '7', '3', '9', '1', '9', '8', '2', '9', '1', '8', '1', '10', '8', '8', '2', '7', '8', '1', '8', '9', '8', '1', '4', '1', '8', '8', '8', '1', '1', '10', '3', '2', '2', '6', '8', '9', '8', '2', '1', '1', '3', '8', '8', '1', '4', '4', '3', '9', '10', '4', '2', '4', '2', '9', '2', '2', '9', '1', '1', '10', '1', '1', '2', '1', '1', '1', '9', '1', '8', '8', '8', '2', '3', '8', '1', '6', '7', '3', '1', '9', '1', '2', '1', '6', '1', '2', '10', '1', '4', '2', '3', '2', '9', '9', '4', '9', '9', '1', '2', '8', '4', '7', '8', '7', '13', '9', '1', '2', '1', '9', '3', '3', '6', '8', '9', '10', '9', '2', '2', '3', '12', '1', '1', '1', '13', '2', '1', '7', '10', '8', '9', '1', '2', '9', '1', '1', '1', '2', '1', '12', '5', '6', '9', '10', '3', '1', '10', '1', '3', '2', '8', '9', '2', '10', '8', '8', '9', '2', '8', '9', '2', '2', '2', '8', '8', '2', '3', '1', '4', '8', '1', '9', '9', '2', '8', '10', '9', '1', '2', '12', '8', '8', '0', '2', '1', '1', '9', '10', '1', '6', '2', '2', '10', '2', '2', '4', '2', '2', '12', '1', '6', '7', '8', '9', '1', '3', '5', '7', '3', '1', '3', '1', '1', '3', '2', '6', '3', '2', '1', '8', '3', '5', '2', '1', '1', '8', '1', '1', '0', '2', '3', '5', '3', '1', '1', '9', '8', '8', '8', '8', '4', '7', '2', '9', '12', '5', '9', '3', '12', '3', '9', '1', '9', '1', '7', '3', '9', '3', '10', '1', '2', '1', '4', '9', '8', '2', '9', '11', '2', '8', '9', '4', '1', '1', '1', '1', '1', '1', '1', '9', '1', '9', '1', '1', '1', '12', '3', '10', '3', '6', '1', '7', '10', '8', '3', '7', '1', '1', '2', '6', '1', '3', '9', '2', '8', '1', '8', '8', '1', '8', '10', '12', '1', '10', '12', '10', '1', '8', '8', '1', '4', '7', '9', '2', '1', '9', '3', '8', '12', '10', '6', '1', '6', '8', '3', '1', '3', '1', '10', '10', '9', '8', '1', '2', '9', '8', '8', '1', '9', '8', '8', '3', '1', '3', '9', '12', '1', '8', '1', '5', '8', '11', '5', '5', '1', '2', '1', '3', '1', '1', '1', '9', '8', '8', '1', '9', '10', '8', '4', '1', '1', '8', '10', '8', '9', '1', '10', '1', '7', '2', '1', '1', '9', '6', '2', '9', '8', '1', '1', '1', '9', '8', '8', '1', '9', '9', '1', '1', '2', '7', '9', '2', '9', '9', '8', '7', '6', '8', '7', '8', '2', '9', '2', '1', '8', '8', '8', '2', '6', '3', '1', '8', '12', '12', '8', '7', '1', '2', '2', '7', '1', '9', '8', '1', '4', '1', '1', '8', '5', '8', '1', '8', '8', '8', '8', '1', '2', '11', '1', '1', '1', '2', '7', '1', '9', '2', '2', '2', '9', '8', '9', '2', '9', '1', '8', '1', '7', '11', '13', '1', '9', '8', '2', '2', '1', '2', '3', '10', '3', '10', '4', '3', '9', '1', '8', '1', '1', '13', '1', '1', '3', '8', '1', '2', '2', '2', '9', '4', '1', '8', '1', '9', '3', '6', '8', '5', '2', '8', '2', '8', '1', '9', '2', '2', '8', '1', '1', '4', '8', '9', '2', '2', '7', '1', '8', '12', '2', '12', '8', '2', '9', '9', '3', '8', '1', '1', '9', '9', '9', '2', '8', '1', '9', '1', '8', '9', '8', '2', '2', '4', '1', '9', '10', '10', '8', '8', '1', '1', '2', '1', '4', '1', '2', '1', '1', '3', '12', '8', '8', '8', '8', '10', '2', '8', '12', '1', '9', '9', '8', '9', '1', '2', '1', '8', '8', '8', '2', '8', '8', '3', '10', '8', '9', '1', '1', '1', '3', '4', '8', '10', '6', '3', '1', '3', '2', '8', '9', '3', '5', '4', '1', '5', '2', '9', '9', '9', '1', '1', '1', '9', '9', '6', '10', '9', '8', '12', '2', '9', '1', '2', '1', '1', '1', '8', '1', '12', '1', '12', '1', '9', '1', '8', '1', '2', '1', '2', '8', '8', '10', '1', '9', '1', '2', '2', '8', '8', '3', '12', '1', '11', '2', '10', '12', '11', '2', '1', '10', '1', '1', '9', '3', '10', '2', '7', '1', '8', '1', '9', '9', '2', '1', '3', '12', '5', '9', '9', '8', '1', '8', '8', '8', '1', '1', '3', '9', '8', '9', '8', '3', '10', '3', '7', '8', '9', '2', '3', '1', '9', '10', '9', '2', '8', '2', '6', '4', '1', '1', '3', '8', '2', '3', '9', '1', '2', '1', '8', '1', '2', '2', '2', '2', '9', '9', '4', '8', '9', '1', '1', '2', '9', '1', '5', '2', '9', '8', '10', '1', '2', '10', '8', '5', '6', '4', '8', '1', '1', '1', '8', '9', '2', '8', '8', '8', '12', '2', '2', '1', '8', '1', '2', '1', '9', '8', '8', '9', '1', '1', '8', '7', '1', '8', '0', '2', '3', '8', '1', '1', '8', '1', '1', '12', '3', '2', '10', '8', '10', '6', '1', '8', '8', '10', '8', '8', '1', '4', '8', '1', '2', '9', '8', '1', '1', '3', '3', '5', '1', '1', '2', '1', '2', '1', '9', '8', '3', '9', '8', '2', '10', '9', '1', '8', '1', '10', '9', '10', '1', '2', '3', '8', '1', '3', '1', '9', '9', '8', '1', '9', '8', '8', '9', '1', '9', '2', '8', '8', '2', '13', '8', '10', '8', '9', '3', '2', '1', '3', '1', '12', '10', '10', '1', '11', '1', '2', '4', '2', '10', '1', '8', '11', '1', '1', '1', '2', '2', '8', '2', '9', '8', '9', '9', '12', '8', '1', '9', '2', '4', '1', '8', '3', '9', '1', '6', '5', '8', '9', '3', '3', '2', '1', '1', '1', '8', '11', '1', '8', '7', '1', '11', '9', '1', '7', '9', '9', '8', '8', '8', '12', '8', '1', '2', '9', '8', '8', '2', '10', '9', '8', '8', '4', '10', '9', '8', '2', '10', '10', '2', '1', '2', '1', '2', '1', '4', '1', '7', '1', '1', '3', '12', '9', '8', '5', '9', '10', '1', '9', '9', '2', '7', '4', '1', '1', '8', '12', '8', '2', '2', '9', '4', '1', '1', '5', '9', '1', '8', '12', '8', '1', '1', '4', '9', '10', '2', '3', '1', '3', '3', '3', '8', '1', '2', '1', '2', '1', '2', '9', '1', '2', '8', '9', '4', '8', '8', '10', '2', '12', '5', '5', '1', '8', '1', '7', '8', '1', '1', '8', '9', '12', '4', '9', '3', '1', '2', '5', '9', '2', '1', '2', '2', '1', '2', '8', '1', '8', '8', '2', '2', '1', '8', '4', '1', '2', '10', '9', '10', '8', '1', '10', '4', '8', '8', '10', '2', '8', '1', '1', '3', '10', '1', '4', '2', '8', '3', '3', '2', '9', '8', '5', '5', '9', '3', '10', '8', '1', '2', '1', '2', '9', '1', '1', '2', '9', '9', '8', '8', '11', '9', '4', '1', '8', '2', '7', '1', '2', '8', '2', '9', '9', '8', '2', '9', '9', '8', '8', '1', '2', '8', '1', '1', '2', '9', '8', '1', '4', '9', '1', '8', '12', '1', '12', '2', '8', '2', '9', '1', '12', '1', '2', '9', '1', '1', '9', '3', '2', '9', '9', '2', '11', '8', '7', '9', '9', '9', '8', '8', '1', '2', '8', '1', '1', '4', '1', '2', '10', '1', '9', '2', '1', '1', '1', '9', '1', '13', '4', '3', '2', '1', '1', '2', '2', '7', '8', '7', '1', '1', '2', '8', '8', '3', '4', '8', '2', '10', '13', '8', '8', '9', '2', '2', '1', '1', '10', '4', '2', '7', '9', '8', '2', '1', '9', '8', '1', '1', '9', '8', '9', '8', '2', '8', '2', '2', '9', '2', '1', '9', '1', '2', '4', '8', '2', '1', '1', '8', '1', '4', '1', '9', '3', '9', '2', '7', '1', '9', '6', '1', '10', '2', '2', '2', '2', '2', '10', '10', '10', '9', '9', '9', '3', '12', '10', '1', '1', '10', '1', '1', '2', '2', '1', '2', '3', '12', '8', '8', '1', '2', '9', '9', '1', '1', '10', '8', '9', '8', '3', '1', '1', '3', '1', '10', '1', '1', '1', '4', '1', '1', '1', '7', '10', '2', '1', '8', '1', '9', '3', '1', '10', '8', '8', '1', '5', '9', '1', '2', '1', '8', '8', '1', '3', '1', '10', '2', '1', '1', '2', '8', '2', '5', '3', '5', '2', '1', '1', '9', '1', '7', '9', '9', '2', '8', '1', '12', '4', '1', '4', '9', '9', '4', '8', '1', '10', '10', '8', '8', '8', '9', '2', '3', '5', '1', '8', '1', '1', '1', '7', '10', '1', '4', '12', '3', '2', '2', '9', '1', '1', '1', '2', '8', '4', '1', '7', '3', '12', '8', '6', '2', '2', '7', '9', '11', '1', '10', '9', '1', '8', '12', '2', '11', '1', '2', '3', '1', '1', '1', '8', '9', '2', '2', '2', '2', '3', '3', '8', '10', '4', '1', '2', '9', '8', '2', '2', '9', '1', '8', '11', '4', '2', '8', '7', '1', '1', '7', '3', '9', '9', '4', '5', '8', '10', '2', '9', '9', '9', '8', '1', '9', '2', '2', '2', '1', '2', '9', '4', '3', '12', '4', '3', '2', '3', '8', '3', '10', '1', '10', '1', '1', '8', '10', '6', '8', '9', '9', '1', '2', '9', '2', '9', '3', '8', '1', '1', '12', '1', '5', '1', '10', '8', '10', '2', '7', '1', '1', '1', '1', '3', '2', '3', '5', '9', '1', '2', '1', '9', '8', '10', '9', '8', '1', '8', '1', '8', '2', '8', '1', '2', '8', '1', '2', '5', '8', '12', '2', '1', '1', '1', '1', '1', '8', '8', '2', '1', '4', '2', '8', '8', '8', '2', '9', '9', '11', '1', '2', '9', '3', '1', '1', '8', '9', '2', '4', '10', '1', '9', '8', '4', '9', '8', '10', '8', '8', '9', '2', '8', '9', '3', '3', '3', '4', '3', '2', '2', '10', '8', '2', '1', '5', '1', '9', '1', '1', '2', '1', '2', '3', '1', '1', '8', '8', '1', '10', '8', '8', '1', '6', '4', '8', '2', '5', '8', '1', '3', '8', '2', '8', '9', '1', '1', '8', '12', '10', '1', '5', '8', '2', '8', '10', '9', '9', '1', '6', '9', '1', '10', '8', '2', '9', '10', '1', '2', '1', '1', '8', '8', '3', '9', '8', '1', '10', '2', '8', '1', '10', '1', '5', '1', '1', '1', '5', '1', '1', '1', '4', '1', '1', '1', '8', '2', '8', '1', '8', '3', '8', '9', '1', '8', '1', '8', '1', '1', '2', '2', '1', '12', '9', '9', '1', '8', '2', '1', '2', '8', '1', '9', '1', '1', '2', '1', '2', '2', '2', '1', '9', '9', '8', '8', '1', '1', '9', '10', '8', '4', '3', '3', '4', '9', '1', '3', '3', '10', '2', '2', '1', '8', '4', '1', '9', '4', '1', '1', '9', '8', '10', '4', '9', '9', '8', '2', '1', '3', '4', '9', '3', '8', '9', '1', '1', '2', '1', '7', '8', '2', '9', '1', '9', '2', '6', '9', '10', '8', '1', '1', '5', '9', '5', '1', '9', '10', '9', '3', '3', '8', '8', '2', '9', '2', '8', '2', '1', '8', '5', '8', '3', '10', '1', '1', '2', '1', '8', '1', '4', '3', '2', '9', '4', '9', '8', '8', '8', '1', '3', '9', '1', '9', '9', '1', '2', '1', '9', '8', '9', '8', '1', '1', '1', '4', '2', '2', '9', '9', '1', '1', '1', '3', '6', '1', '2', '3', '1', '4', '2', '9', '1', '9', '9', '1', '8', '2', '1', '9', '1', '8', '1', '8', '8', '2', '1', '9', '9', '6', '8', '8', '9', '8', '10', '8', '9', '5', '1', '1', '1', '1', '8', '1', '8', '12', '8', '1', '12', '9', '2', '8', '1', '1', '2', '1', '8', '6', '9', '9', '8', '1', '8', '9', '7', '7', '8', '9', '9', '1', '8', '3', '8', '1', '3', '3', '8', '9', '8', '2', '8', '1', '2', '9', '8', '1', '1', '1', '1', '9', '1', '9', '8', '12', '3', '8', '8', '1', '10', '10', '10', '2', '2', '1', '10', '2', '2', '10', '8', '12', '8', '1', '1', '1', '2', '1', '1', '3', '8', '1', '2', '2', '2', '1', '1', '6', '2', '8', '8', '8', '1', '1', '1', '9', '9', '2', '8', '10', '2', '8', '2', '1', '2', '9', '9', '2', '1', '1', '8', '8', '1', '3', '1', '8', '9', '1', '10', '9', '1', '1', '1', '1', '7', '2', '2', '1', '2', '8', '8', '1', '2', '1', '3', '2', '1', '8', '3', '9', '2', '10', '2', '10', '1', '2', '1', '1', '13', '9', '10', '8', '2', '2', '1', '1', '8', '2', '2', '1', '9', '1', '1', '8', '9', '9', '2', '9', '2', '2', '1', '1', '1', '8', '9', '4', '9', '9', '1', '8', '2', '1', '1', '8', '2', '2', '2', '8', '1', '1', '8', '2', '10', '2', '9', '9', '7', '1', '1', '2', '2', '8', '3', '1', '2', '1', '1', '8', '1', '1', '1', '9', '1', '1', '8', '8', '1', '9', '6', '1', '9', '1', '8', '1', '8', '8', '8', '1', '3', '8', '8', '2', '6', '3', '2', '1', '10', '1', '8', '2', '1', '6', '1', '1', '1', '8', '1', '10', '1', '1', '8', '9', '2', '6', '9', '2', '9', '4', '1', '8', '1', '3', '7', '8', '8', '5', '8', '7', '1', '1', '1', '13', '8', '3', '1', '1', '1', '1', '2', '8', '2', '12', '8', '1', '2', '5', '1', '8', '2', '10', '8', '2', '10', '1', '5', '2', '1', '1', '5', '2', '2', '7', '8', '2', '9', '9', '1', '10', '1', '8', '2', '5', '8', '1', '5', '1', '10', '1', '1', '9', '8', '6', '1', '8', '9', '8', '1', '8', '2', '2', '8', '3', '9', '1', '9', '3', '8', '4', '4', '3', '3', '1', '1', '1', '8', '9', '1', '1', '8', '3', '1', '2', '8', '2', '1', '1', '10', '1', '2', '2', '1', '1', '8', '2', '8', '2', '10', '2', '2', '10', '8', '8', '8', '13', '2', '2', '9', '2', '5', '9', '2', '1', '8', '8', '8', '1', '12', '12', '2', '9', '2', '1', '8', '2', '1', '8', '1', '9', '9', '2', '7', '1', '1', '7', '1', '4', '3', '1', '10', '3', '10', '9', '4', '6', '7', '5', '2', '1', '8', '8', '1', '4', '9', '2', '1', '8', '1', '1', '1', '1', '1', '8', '9', '8', '8', '8', '8', '9', '8', '10', '1', '8', '2', '7', '8', '9', '1', '2', '5', '9', '10', '8', '9', '12', '1', '6', '1', '2', '10', '9', '4', '1', '8', '10', '10', '1', '1', '1', '1', '1', '2', '3', '8', '1', '2', '10', '2', '1', '2', '4', '2', '2', '9', '1', '4', '2', '1', '1', '12', '12', '9', '9', '7', '1', '8', '4', '9', '9', '8', '1', '7', '3', '2', '1', '1', '4', '8', '1', '5', '8', '2', '8', '1', '14', '9', '12', '1', '10', '2', '1', '1', '8', '8', '6', '6', '3', '1', '2', '8', '1', '3', '2', '1', '8', '8', '1', '10', '8', '2', '8', '2', '5', '9', '1', '8', '8', '1', '1', '8', '8', '13', '1', '3', '8', '4', '1', '9', '7', '8', '8', '8', '3', '8', '1', '4', '2', '8', '8', '8', '7', '1', '1', '2', '8', '8', '9', '8', '8', '2', '3', '9', '9', '2', '1', '2', '2', '1', '8', '2', '6', '2', '1', '1', '9', '10', '3', '8', '2', '3', '2', '8', '8', '1', '8', '8', '8', '9', '1', '4', '1', '9', '2', '1', '8', '0', '1', '8', '1', '1', '8', '9', '9', '1', '3', '1', '2', '8', '8', '7', '1', '1', '2', '9', '2', '10', '2', '8', '2', '2', '2', '7', '1', '9', '8', '1', '3', '9', '2', '1', '10', '8', '1', '4', '1', '8', '5', '9', '8', '8', '1', '2', '2', '1', '8', '8', '6', '8', '1', '1', '8', '3', '2', '2', '1', '8', '1', '7', '6', '8', '1', '1', '1', '9', '1', '1', '1', '2', '1', '11', '10', '10', '11', '9']\n"
          ]
        }
      ],
      "source": [
        "sc = SupremeCourt()\n",
        "print(sc.info)\n",
        "sc.download()\n",
        "\n",
        "texts = []  # list of text samples\n",
        "labels_index = {}  # dictionary mapping label name to numeric id\n",
        "labels = []  # list of label ids\n",
        "\n",
        "issue_codes = list(sc.issue_area_codes.keys()) # 15 labels\n",
        "print(issue_codes)\n",
        "issue_codes.sort()\n",
        "issue_codes = [str(ic) for ic in issue_codes]\n",
        "\n",
        "labels_index = dict(zip(issue_codes, np.arange(len(issue_codes))))\n",
        "print(labels_index)\n",
        "count=0\n",
        "\n",
        "for record in sc.records():\n",
        "\n",
        "        count=count+1\n",
        "        if record[1]['issue'] == None: # some cases have None as an issue\n",
        "            labels.append(labels_index['-1'])\n",
        "        else:\n",
        "            labels.append(labels_index[record[1]['issue'][:-4]])\n",
        "        \n",
        "        new_sen=record[0].split(\"Footnotes\")[0]\n",
        "        new_new_sen=new_sen.split()\n",
        "        if len(new_new_sen) >= 1024:\n",
        "          new_new_sen=new_new_sen[512:1024]\n",
        "        \n",
        "        elif len(new_new_sen) < 512:\n",
        "          new_new_sen=new_new_sen[0:len(new_new_sen)]\n",
        "        \n",
        "        else:\n",
        "          new_new_sen=new_new_sen[-512:]\n",
        "          \n",
        "        new_new_sen=' '.join(new_new_sen)\n",
        "\n",
        "        texts.append(new_new_sen)\n",
        "   \n",
        "len_list = [len(ele.split()) for ele in texts]\n",
        "\n",
        "print(labels)\n",
        "print(len(labels))\n",
        "\n",
        "res = 0 if len(len_list) == 0 else (float(sum(len_list)) / len(len_list))\n",
        "print(\"Average Length %s\" % res) \n",
        "print('Found %s texts.' % len(texts))\n",
        "print('Found %s labels.' % len(labels_index))\n",
        "\n",
        "temp_file = open(\"labels_sc.txt\", \"r\")\n",
        "\n",
        "data = temp_file.read()\n",
        "label_list = data.split(\"\\n\")\n",
        "print(label_list)\n",
        "label_list = label_list[0:-1]\n",
        "print(label_list)\n",
        "label_list = [int(i) for i in label_list]\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LprCHRM2aWb8",
        "outputId": "52d0984a-fa6f-4c7a-9586-51d2729b1b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text  label\n",
            "0     second, as it is in the open air, it would be ...      8\n",
            "1     no indication that a profit motive is a sine q...      1\n",
            "2     But we think it would expand the actual holdin...      8\n",
            "3     were moved from their original possessions to ...      2\n",
            "4     great, if not unusual, diligence,' and that 'n...      8\n",
            "...                                                 ...    ...\n",
            "8414  Opinion reported: Ante, p. 88. DECREE 1. It is...     11\n",
            "8415  325,000. For the purpose of giving effect to t...     10\n",
            "8416  of the Constitution and 28 U.S.C. 1251 (b), th...     10\n",
            "8417  latitude be established as shown upon Texas Ex...     11\n",
            "8418  time of its admission to the Union. Pollard's ...      9\n",
            "\n",
            "[8419 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "summarized_data = pd.DataFrame(texts,\n",
        "               columns =['text'])\n",
        "summarized_data['label'] = label_list\n",
        "print(summarized_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VoY1gHZoaZmG"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    inps = Input(shape = (max_len,), dtype='int64')\n",
        "    masks= Input(shape = (max_len,), dtype='int64')\n",
        "    dbert_layer = dbert_model(inps, attention_mask=masks)[0][:,0,:]\n",
        "    dense_0 = Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))(dbert_layer)\n",
        "    dropout_0= Dropout(0.5)(dense_0)\n",
        "    pred = Dense(15, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout_0)\n",
        "    model = tf.keras.Model(inputs=[inps,masks], outputs=pred)\n",
        "    print(model.summary())\n",
        "    return model   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "79114879299a406f9e1e65c93fbd2f4b",
            "278039a6d3c14a3eb9fbd8a7f7ec3acc",
            "2b13ecc1caa64db0863361f07d2ef667",
            "9e9a6aed5a2c4613b37ae939c7ca443b",
            "1216c3371c6b45468d6971f58faef01e",
            "255f6ae70e6849c5ad50be91f2151684",
            "fa7ee033ca674f59b684c7b61bb6b66a",
            "196b12a330534b82ab244ebdd77e6501",
            "cc159b86f7b94437b374abbfbcfa55ee",
            "aabf172d4003450a995761a56adae471",
            "9d3586d58b86472e9b5d595d6bd1a014",
            "87c0b91361944423a4eb927a96748767",
            "9924ac8848d34b0fbc5221119cfb36dc",
            "74d9b8d0b33a4ad3abde5d92cb6cfe8b",
            "46dcbabc3e704715b714008ea624f08f",
            "87f40d39cc46451e84a9d64600dbb6d7",
            "8f24e79cca9d4933b5e90af4bf80be88",
            "2226fec6a6284c068bfa64c19b16808d",
            "6c72e0f622b14a4bb71d247efb235c2a",
            "6cc65c50f859444ab3b3c10759546f9b",
            "05046b7c385b401f85134ba3b98e59c5",
            "3d10fb0631fa4d9986408b466cc6ed0b",
            "120a2cc21df548f895a37f5d249cfe64",
            "cfb3c785f8e248a5b71215b613bb5f4b",
            "23b2cd5e5e8349b58529444b609e4e6e",
            "cfdab07739354155aec068d6aac4637a",
            "c54a2649b5cd4231af0b42010117a987",
            "8ed2c9dd17aa41d189b8ad385651368e",
            "2a0a40b3362240bcb9dfeb6d98550fe1",
            "e48cbc4ad6d449e0a4b4b57585068873",
            "ce67524b2fc44b998e97f326e2a170b9",
            "db22400b29504b919a8a15c92e652ef6",
            "19099e605b6647f094cee15b773a0a97",
            "524480a1cef34c479ce7a47eab657889",
            "c150e6fb7db8426aaf1a5753c419fac7",
            "1a0c71612ad744e6aca83520fdf8f664",
            "fd64a2795724404d81f4dc805dae8fa0",
            "029d2fcc8a0048efa1900be14538ca82",
            "0b5ed791eb07423fadc96ad3e5428582",
            "e9e94f70c1d94cad8da84fa072051e73",
            "849326abc02b42ebb1b82798008a0ec4",
            "bc1c0b861514472f89a38c74d925268b",
            "99af75a92ce24dde858151fdd882fba9",
            "cb69a249007e4193a71a14fe4b520f65"
          ]
        },
        "id": "x9kO4eVwCHKg",
        "outputId": "e0becae7-d857-4b18-aa99-b10ed650b592"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79114879299a406f9e1e65c93fbd2f4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87c0b91361944423a4eb927a96748767"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "120a2cc21df548f895a37f5d249cfe64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "524480a1cef34c479ce7a47eab657889"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 26 21:25:35 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    38W / 300W |   1683MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 333s 336ms/step - loss: 7.1052 - accuracy: 0.5748 - val_loss: 6.1655 - val_accuracy: 0.6591\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 319s 336ms/step - loss: 5.5272 - accuracy: 0.7108 - val_loss: 5.1379 - val_accuracy: 0.6758\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 316s 333ms/step - loss: 4.4328 - accuracy: 0.7891 - val_loss: 4.4767 - val_accuracy: 0.6758\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 319s 336ms/step - loss: 3.5272 - accuracy: 0.8555 - val_loss: 3.8557 - val_accuracy: 0.6900\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 315s 333ms/step - loss: 2.7865 - accuracy: 0.9063 - val_loss: 3.5025 - val_accuracy: 0.6770\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.6900237529691211\n",
            "Weighted F1: 0.6799279050320086\n",
            "Micro F1: 0.6900237529691211\n",
            "Weighted Precision: 0.685209814250892\n",
            "Micro Precision: 0.6900237529691211\n",
            "Weighted Recall: 0.6900237529691211\n",
            "Micro Recall: 0.6900237529691211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 26 21:55:24 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    37W / 300W |  15237MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 334s 337ms/step - loss: 7.1331 - accuracy: 0.5729 - val_loss: 6.2430 - val_accuracy: 0.6461\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 319s 336ms/step - loss: 5.5431 - accuracy: 0.7133 - val_loss: 5.1498 - val_accuracy: 0.6758\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 319s 336ms/step - loss: 4.4297 - accuracy: 0.7937 - val_loss: 4.3872 - val_accuracy: 0.6924\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 315s 333ms/step - loss: 3.5205 - accuracy: 0.8550 - val_loss: 3.8180 - val_accuracy: 0.6746\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 315s 332ms/step - loss: 2.7728 - accuracy: 0.9070 - val_loss: 3.5467 - val_accuracy: 0.6627\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.6923990498812351\n",
            "Weighted F1: 0.6940426540023229\n",
            "Micro F1: 0.6923990498812351\n",
            "Weighted Precision: 0.7038633015031724\n",
            "Micro Precision: 0.6923990498812351\n",
            "Weighted Recall: 0.6923990498812351\n",
            "Micro Recall: 0.6923990498812351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 26 22:25:11 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    37W / 300W |  15237MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 335s 336ms/step - loss: 7.1682 - accuracy: 0.5597 - val_loss: 6.2570 - val_accuracy: 0.6449\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 318s 336ms/step - loss: 5.5777 - accuracy: 0.7069 - val_loss: 5.1937 - val_accuracy: 0.6698\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 318s 335ms/step - loss: 4.4756 - accuracy: 0.7894 - val_loss: 4.4937 - val_accuracy: 0.6746\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 315s 333ms/step - loss: 3.5535 - accuracy: 0.8594 - val_loss: 4.0130 - val_accuracy: 0.6591\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 318s 336ms/step - loss: 2.8084 - accuracy: 0.9038 - val_loss: 3.4900 - val_accuracy: 0.6888\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.6888361045130641\n",
            "Weighted F1: 0.6940723102407206\n",
            "Micro F1: 0.6888361045130641\n",
            "Weighted Precision: 0.7113714264263704\n",
            "Micro Precision: 0.6888361045130641\n",
            "Weighted Recall: 0.6888361045130641\n",
            "Micro Recall: 0.6888361045130641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 26 22:55:53 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    37W / 300W |  15237MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 334s 337ms/step - loss: 7.0984 - accuracy: 0.5668 - val_loss: 6.1790 - val_accuracy: 0.6698\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 319s 336ms/step - loss: 5.5433 - accuracy: 0.7152 - val_loss: 5.1903 - val_accuracy: 0.6746\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 319s 336ms/step - loss: 4.4561 - accuracy: 0.7937 - val_loss: 4.4132 - val_accuracy: 0.6770\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 319s 336ms/step - loss: 3.5536 - accuracy: 0.8621 - val_loss: 3.8916 - val_accuracy: 0.6865\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 316s 333ms/step - loss: 2.8149 - accuracy: 0.9113 - val_loss: 3.4933 - val_accuracy: 0.6758\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.6864608076009501\n",
            "Weighted F1: 0.6748923012986465\n",
            "Micro F1: 0.6864608076009501\n",
            "Weighted Precision: 0.6823916584895625\n",
            "Micro Precision: 0.6864608076009501\n",
            "Weighted Recall: 0.6864608076009501\n",
            "Micro Recall: 0.6864608076009501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 26 23:25:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    37W / 300W |  15237MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 334s 336ms/step - loss: 7.0834 - accuracy: 0.5721 - val_loss: 6.1752 - val_accuracy: 0.6485\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 318s 336ms/step - loss: 5.5281 - accuracy: 0.7083 - val_loss: 5.1187 - val_accuracy: 0.6853\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 315s 333ms/step - loss: 4.4469 - accuracy: 0.7888 - val_loss: 4.4295 - val_accuracy: 0.6675\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 315s 332ms/step - loss: 3.5453 - accuracy: 0.8600 - val_loss: 3.9721 - val_accuracy: 0.6781\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 315s 332ms/step - loss: 2.8013 - accuracy: 0.9097 - val_loss: 3.5824 - val_accuracy: 0.6627\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.6852731591448931\n",
            "Weighted F1: 0.6733306165982528\n",
            "Micro F1: 0.6852731591448931\n",
            "Weighted Precision: 0.679000900560724\n",
            "Micro Precision: 0.6852731591448931\n",
            "Weighted Recall: 0.6852731591448931\n",
            "Micro Recall: 0.6852731591448931\n",
            "Average Accuracy: 0.6885985748218527\n",
            "Average Weighted F1: 0.6832531574343903\n",
            "Average Micro F1: 0.6885985748218527\n",
            "Average Weighted Precision: 0.6923674202461443\n",
            "Average Micro Precision: 0.6885985748218527\n",
            "Average Weighted Recall: 0.6885985748218527\n",
            "Average Micro Recall: 0.6885985748218527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "total_accuracy=0\n",
        "total_weighted_f1=0\n",
        "total_micro_f1=0\n",
        "total_weighted_precision=0\n",
        "total_micro_precision=0\n",
        "total_weighted_recall=0\n",
        "total_micro_recall=0\n",
        "\n",
        "for i in range(5):\n",
        "  gc.collect()\n",
        "  tf.keras.backend.clear_session()\n",
        "  dbert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "  dbert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "  max_len=512\n",
        "  sentences=summarized_data['text']\n",
        "  labels=summarized_data['label']\n",
        "  len(sentences),len(labels)\n",
        "  model_0=create_model()\n",
        "  input_ids=[]\n",
        "  attention_masks=[]\n",
        "\n",
        "  for sent in sentences:\n",
        "    dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
        "    input_ids.append(dbert_inps['input_ids'])\n",
        "    attention_masks.append(dbert_inps['attention_mask'])\n",
        "  input_ids=np.asarray(input_ids)\n",
        "\n",
        "  attention_masks=np.array(attention_masks)\n",
        "  labels=np.array(labels)\n",
        "  train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.1,random_state=42)\n",
        "  log_dir='dbert_model'\n",
        "\n",
        "  model_save_path='./drive/MyDrive/Best-512/best-512-'+str(i)+'-15labels.h5'\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "  callbacks= [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,monitor='val_accuracy',mode='max',save_best_only=True,save_weights_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
        "  model_0.compile(loss=loss,optimizer=optimizer, metrics=[accuracy])\n",
        "  gpu_info = !nvidia-smi\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "  else:\n",
        "    print(gpu_info)\n",
        "  history=model_0.fit([train_inp,train_mask],train_label,batch_size=8,epochs=5,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)\n",
        "  pred_labels=[]\n",
        "\n",
        "  model_saved= create_model()\n",
        "  model_saved.compile(loss=loss,optimizer=optimizer, metrics=[accuracy])\n",
        "  model_saved.load_weights('./drive/MyDrive/Best-512/best-512-'+str(i)+'-15labels.h5')\n",
        "\n",
        "  for i in range(0,len(val_inp)):\n",
        "    pred=model_saved.predict([val_inp[i].reshape(1,512),val_mask[i].reshape(1,512)])\n",
        "    pred_label = pred.argmax(axis=1)\n",
        "    pred_labels.append(pred_label)\n",
        "  accuracy=accuracy_score(val_label, pred_labels)\n",
        "  print(\"Accuracy: \"+str(accuracy))\n",
        "  total_accuracy=total_accuracy+accuracy\n",
        "  \n",
        "  weighted_f1=f1_score(val_label,pred_labels, average='weighted')\n",
        "  print(\"Weighted F1: \"+ str(weighted_f1))\n",
        "  total_weighted_f1=total_weighted_f1+weighted_f1\n",
        "  micro_f1=f1_score(val_label,pred_labels, average='micro')\n",
        "  print(\"Micro F1: \"+ str(micro_f1))\n",
        "  total_micro_f1=total_micro_f1+micro_f1\n",
        "\n",
        "  weighted_precision=precision_score(val_label, pred_labels, average='weighted')\n",
        "  print(\"Weighted Precision: \" + str(weighted_precision))\n",
        "  total_weighted_precision=total_weighted_precision+weighted_precision\n",
        "  micro_precision=precision_score(val_label, pred_labels, average='micro')\n",
        "  print(\"Micro Precision: \" + str(micro_precision))\n",
        "  total_micro_precision=total_micro_precision+micro_precision\n",
        "\n",
        "  weighted_recall=recall_score(val_label, pred_labels, average='weighted')\n",
        "  print(\"Weighted Recall: \" + str(weighted_recall))\n",
        "  total_weighted_recall=total_weighted_recall+weighted_recall\n",
        "  micro_recall=recall_score(val_label, pred_labels, average='micro')\n",
        "  print(\"Micro Recall: \" + str(micro_recall))\n",
        "  total_micro_recall=total_micro_recall+micro_recall\n",
        "\n",
        "\n",
        "print(\"Average Accuracy: \"+str(total_accuracy/5))\n",
        "print(\"Average Weighted F1: \"+str(total_weighted_f1/5))\n",
        "print(\"Average Micro F1: \"+str(total_micro_f1/5))\n",
        "print(\"Average Weighted Precision: \"+str(total_weighted_precision/5))\n",
        "print(\"Average Micro Precision: \"+str(total_micro_precision/5))\n",
        "print(\"Average Weighted Recall: \"+str(total_weighted_recall/5))\n",
        "print(\"Average Micro Recall: \"+str(total_micro_recall/5))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Best-512_512:1024_15labels.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "79114879299a406f9e1e65c93fbd2f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_278039a6d3c14a3eb9fbd8a7f7ec3acc",
              "IPY_MODEL_2b13ecc1caa64db0863361f07d2ef667",
              "IPY_MODEL_9e9a6aed5a2c4613b37ae939c7ca443b"
            ],
            "layout": "IPY_MODEL_1216c3371c6b45468d6971f58faef01e"
          }
        },
        "278039a6d3c14a3eb9fbd8a7f7ec3acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_255f6ae70e6849c5ad50be91f2151684",
            "placeholder": "​",
            "style": "IPY_MODEL_fa7ee033ca674f59b684c7b61bb6b66a",
            "value": "Downloading: 100%"
          }
        },
        "2b13ecc1caa64db0863361f07d2ef667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_196b12a330534b82ab244ebdd77e6501",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc159b86f7b94437b374abbfbcfa55ee",
            "value": 231508
          }
        },
        "9e9a6aed5a2c4613b37ae939c7ca443b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aabf172d4003450a995761a56adae471",
            "placeholder": "​",
            "style": "IPY_MODEL_9d3586d58b86472e9b5d595d6bd1a014",
            "value": " 226k/226k [00:00&lt;00:00, 629kB/s]"
          }
        },
        "1216c3371c6b45468d6971f58faef01e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "255f6ae70e6849c5ad50be91f2151684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa7ee033ca674f59b684c7b61bb6b66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "196b12a330534b82ab244ebdd77e6501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc159b86f7b94437b374abbfbcfa55ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aabf172d4003450a995761a56adae471": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d3586d58b86472e9b5d595d6bd1a014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87c0b91361944423a4eb927a96748767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9924ac8848d34b0fbc5221119cfb36dc",
              "IPY_MODEL_74d9b8d0b33a4ad3abde5d92cb6cfe8b",
              "IPY_MODEL_46dcbabc3e704715b714008ea624f08f"
            ],
            "layout": "IPY_MODEL_87f40d39cc46451e84a9d64600dbb6d7"
          }
        },
        "9924ac8848d34b0fbc5221119cfb36dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f24e79cca9d4933b5e90af4bf80be88",
            "placeholder": "​",
            "style": "IPY_MODEL_2226fec6a6284c068bfa64c19b16808d",
            "value": "Downloading: 100%"
          }
        },
        "74d9b8d0b33a4ad3abde5d92cb6cfe8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c72e0f622b14a4bb71d247efb235c2a",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6cc65c50f859444ab3b3c10759546f9b",
            "value": 28
          }
        },
        "46dcbabc3e704715b714008ea624f08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05046b7c385b401f85134ba3b98e59c5",
            "placeholder": "​",
            "style": "IPY_MODEL_3d10fb0631fa4d9986408b466cc6ed0b",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.25kB/s]"
          }
        },
        "87f40d39cc46451e84a9d64600dbb6d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f24e79cca9d4933b5e90af4bf80be88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2226fec6a6284c068bfa64c19b16808d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c72e0f622b14a4bb71d247efb235c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cc65c50f859444ab3b3c10759546f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05046b7c385b401f85134ba3b98e59c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d10fb0631fa4d9986408b466cc6ed0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "120a2cc21df548f895a37f5d249cfe64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfb3c785f8e248a5b71215b613bb5f4b",
              "IPY_MODEL_23b2cd5e5e8349b58529444b609e4e6e",
              "IPY_MODEL_cfdab07739354155aec068d6aac4637a"
            ],
            "layout": "IPY_MODEL_c54a2649b5cd4231af0b42010117a987"
          }
        },
        "cfb3c785f8e248a5b71215b613bb5f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ed2c9dd17aa41d189b8ad385651368e",
            "placeholder": "​",
            "style": "IPY_MODEL_2a0a40b3362240bcb9dfeb6d98550fe1",
            "value": "Downloading: 100%"
          }
        },
        "23b2cd5e5e8349b58529444b609e4e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e48cbc4ad6d449e0a4b4b57585068873",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce67524b2fc44b998e97f326e2a170b9",
            "value": 570
          }
        },
        "cfdab07739354155aec068d6aac4637a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db22400b29504b919a8a15c92e652ef6",
            "placeholder": "​",
            "style": "IPY_MODEL_19099e605b6647f094cee15b773a0a97",
            "value": " 570/570 [00:00&lt;00:00, 23.0kB/s]"
          }
        },
        "c54a2649b5cd4231af0b42010117a987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ed2c9dd17aa41d189b8ad385651368e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a0a40b3362240bcb9dfeb6d98550fe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e48cbc4ad6d449e0a4b4b57585068873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce67524b2fc44b998e97f326e2a170b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db22400b29504b919a8a15c92e652ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19099e605b6647f094cee15b773a0a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "524480a1cef34c479ce7a47eab657889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c150e6fb7db8426aaf1a5753c419fac7",
              "IPY_MODEL_1a0c71612ad744e6aca83520fdf8f664",
              "IPY_MODEL_fd64a2795724404d81f4dc805dae8fa0"
            ],
            "layout": "IPY_MODEL_029d2fcc8a0048efa1900be14538ca82"
          }
        },
        "c150e6fb7db8426aaf1a5753c419fac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b5ed791eb07423fadc96ad3e5428582",
            "placeholder": "​",
            "style": "IPY_MODEL_e9e94f70c1d94cad8da84fa072051e73",
            "value": "Downloading: 100%"
          }
        },
        "1a0c71612ad744e6aca83520fdf8f664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_849326abc02b42ebb1b82798008a0ec4",
            "max": 536063208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc1c0b861514472f89a38c74d925268b",
            "value": 536063208
          }
        },
        "fd64a2795724404d81f4dc805dae8fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99af75a92ce24dde858151fdd882fba9",
            "placeholder": "​",
            "style": "IPY_MODEL_cb69a249007e4193a71a14fe4b520f65",
            "value": " 511M/511M [00:08&lt;00:00, 72.1MB/s]"
          }
        },
        "029d2fcc8a0048efa1900be14538ca82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b5ed791eb07423fadc96ad3e5428582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9e94f70c1d94cad8da84fa072051e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "849326abc02b42ebb1b82798008a0ec4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc1c0b861514472f89a38c74d925268b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99af75a92ce24dde858151fdd882fba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb69a249007e4193a71a14fe4b520f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}