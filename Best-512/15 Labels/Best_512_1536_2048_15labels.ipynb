{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCIR7rd5h9fv",
        "outputId": "8b5643ab-b680-4463-81f3-be9ae2b6f516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "#drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')\n",
        "#drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k8FHrSIiqDo",
        "outputId": "535e34cc-ff3c-4fa5-a556-405a768a9e1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 15.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 94.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 88.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 88.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 14.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 489.6 MB 18 kB/s \n",
            "\u001b[?25hCollecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 76.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.14.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (4.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.44.0)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 81.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.17.3)\n",
            "Collecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.21.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.37.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (13.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "Successfully installed gast-0.4.0 keras-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.4.0-py3-none-any.whl (574 kB)\n",
            "\u001b[K     |████████████████████████████████| 574 kB 15.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.11.0+cu113)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 69.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from stanza) (4.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (4.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (0.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (4.11.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (0.0.49)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->stanza) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->stanza) (3.8.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->stanza) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->stanza) (1.1.0)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=c9608b854acbf5d7017d8d2fd59f0de7a7e6af445349b5c217d88b1c9aae91a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-1.7.0 stanza-1.4.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Collecting textacy\n",
            "  Downloading textacy-0.11.0-py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 14.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.64.0)\n",
            "Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.2.4)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.6.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.21.6)\n",
            "Collecting jellyfish>=0.8.0\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 90.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.23.0)\n",
            "Collecting spacy>=3.0.0\n",
            "  Downloading spacy-3.2.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 84.2 MB/s \n",
            "\u001b[?25hCollecting cytoolz>=0.10.1\n",
            "  Downloading cytoolz-0.11.2.tar.gz (481 kB)\n",
            "\u001b[K     |████████████████████████████████| 481 kB 83.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.1.0)\n",
            "Collecting pyphen>=0.10.0\n",
            "  Downloading pyphen-0.12.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 67.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.0.2)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz>=0.10.1->textacy) (0.11.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.0->textacy) (3.1.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.4.1)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n",
            "\u001b[K     |████████████████████████████████| 653 kB 86.4 MB/s \n",
            "\u001b[?25hCollecting typing-extensions<4.0.0.0,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (7.1.2)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 65.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.11.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (21.3)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 91.1 MB/s \n",
            "\u001b[?25hCollecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
            "\u001b[K     |████████████████████████████████| 457 kB 71.9 MB/s \n",
            "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.9.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.0.6)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (57.4.0)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.0->textacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0.0->textacy) (3.0.8)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.0.0->textacy) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.0.0->textacy) (2.0.1)\n",
            "Building wheels for collected packages: cytoolz, jellyfish\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.11.2-cp37-cp37m-linux_x86_64.whl size=1230839 sha256=b4cabd5b10ca42685fe81e4adf4ab6cdc03a82b2b0bd66f3cc29695fc44d5409\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/70/71/ca13ea3d36ccd0b3d0ec7d7a4ca67522048d695b556bba4f59\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=73986 sha256=a8df19fc3fd66995dc51eecc58cb24694e67216dbc53f8dd7dbf86f03f64a8f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "Successfully built cytoolz jellyfish\n",
            "Installing collected packages: typing-extensions, catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy, pyphen, jellyfish, cytoolz, textacy\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.7 cytoolz-0.11.2 jellyfish-0.9.0 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 pyphen-0.12.0 spacy-3.2.4 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 textacy-0.11.0 thinc-8.0.15 typer-0.4.1 typing-extensions-3.10.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install tensorflow==2.7.0\n",
        "!pip install stanza\n",
        "!pip install transformers\n",
        "!pip install tensorflow-addons\n",
        "!pip install nltk\n",
        "!pip install textacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0rs0NoritMk",
        "outputId": "f87a6916-356c-4082-e083-336d3d049fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wYwcFK5gixXz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from textacy.datasets.supreme_court import SupremeCourt\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "import nltk\n",
        "#from transformers import pipeline\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense,Dropout, Input, BatchNormalization\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras import regularizers\n",
        "#from transformers import *\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "import numpy as np\n",
        "import gc\n",
        "import math\n",
        "import json\n",
        "import stanza\n",
        "from tensorflow.keras import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import *\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import TFRobertaModel,RobertaTokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.initializers import RandomUniform\n",
        "\n",
        "from numpy.random import seed\n",
        "import random as python_random\n",
        "import os\n",
        "import sys\n",
        "\n",
        "np.random.seed(1)\n",
        "python_random.seed(1)\n",
        "tf.random.set_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bffI5vYTUeFW"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/labels_sc.txt\" \"./labels_sc.txt\"\n",
        "!cp \"/content/drive/My Drive/labels_sc_279.txt\" \"./labels_sc_279.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZinwFiui-A3",
        "outputId": "9e1b19c0-938d-48a1-ddf0-128e006480c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'supreme_court', 'site_url': 'http://caselaw.findlaw.com/court/us-supreme-court', 'description': 'Collection of ~8.4k decisions issued by the U.S. Supreme Court between November 1946 and June 2016.'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 111M/111M [00:02<00:00, 39.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
            "{'-1': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14}\n",
            "[8, 1, 8, 2, 8, 8, 8, 9, 7, 8, 1, 2, 1, 1, 8, 4, 8, 8, 12, 3, 3, 7, 3, 12, 1, 8, 8, 8, 8, 8, 8, 8, 1, 9, 5, 9, 9, 9, 11, 8, 8, 8, 4, 8, 8, 8, 8, 1, 3, 9, 3, 7, 1, 2, 9, 9, 7, 8, 8, 1, 10, 7, 8, 8, 9, 8, 7, 9, 9, 12, 7, 2, 8, 1, 11, 11, 1, 7, 7, 12, 1, 9, 8, 10, 12, 7, 8, 2, 8, 9, 9, 1, 8, 9, 1, 7, 12, 10, 10, 10, 8, 3, 7, 9, 8, 9, 1, 8, 8, 2, 7, 2, 9, 9, 11, 8, 8, 12, 12, 7, 8, 12, 4, 9, 3, 1, 12, 1, 1, 8, 8, 3, 8, 8, 8, 8, 9, 1, 8, 8, 10, 1, 8, 2, 8, 8, 7, 3, 8, 2, 4, 4, 9, 8, 10, 12, 12, 1, 1, 9, 1, 1, 1, 8, 2, 2, 8, 1, 1, 2, 2, 1, 2, 8, 1, 9, 9, 8, 8, 4, 2, 9, 9, 8, 3, 4, 3, 1, 8, 8, 2, 1, 9, 7, 8, 8, 1, 12, 3, 8, 2, 4, 2, 9, 12, 1, 4, 1, 8, 8, 8, 2, 2, 8, 9, 8, 8, 8, 10, 9, 8, 7, 9, 1, 1, 9, 4, 2, 4, 2, 2, 1, 7, 8, 11, 11, 3, 9, 2, 4, 8, 9, 1, 8, 1, 1, 4, 9, 1, 1, 8, 8, 2, 1, 8, 4, 2, 8, 9, 8, 8, 2, 8, 8, 8, 7, 1, 1, 1, 2, 1, 1, 8, 7, 8, 8, 12, 2, 12, 12, 8, 10, 12, 8, 3, 3, 12, 10, 1, 8, 12, 1, 8, 8, 2, 8, 4, 7, 8, 7, 10, 8, 10, 9, 8, 12, 12, 1, 8, 8, 3, 8, 8, 8, 8, 8, 1, 9, 8, 11, 1, 1, 1, 9, 8, 1, 9, 2, 3, 11, 8, 9, 9, 9, 2, 1, 8, 8, 9, 7, 1, 4, 9, 4, 8, 8, 4, 8, 12, 9, 4, 8, 2, 10, 10, 10, 8, 9, 9, 8, 8, 12, 7, 1, 8, 8, 8, 4, 1, 1, 1, 1, 1, 1, 8, 1, 9, 8, 9, 9, 4, 8, 12, 9, 8, 8, 2, 8, 8, 8, 6, 9, 8, 3, 7, 8, 8, 4, 12, 8, 8, 9, 12, 12, 9, 8, 2, 9, 2, 3, 1, 12, 8, 10, 9, 9, 9, 10, 10, 3, 8, 12, 1, 4, 2, 1, 10, 8, 2, 8, 4, 8, 9, 1, 9, 9, 10, 10, 1, 4, 9, 2, 4, 9, 1, 1, 3, 10, 3, 3, 8, 7, 3, 8, 9, 9, 12, 4, 8, 12, 2, 2, 4, 1, 9, 9, 4, 1, 4, 2, 8, 12, 2, 3, 10, 10, 9, 8, 9, 9, 1, 12, 8, 8, 8, 12, 4, 1, 8, 8, 1, 9, 8, 8, 2, 1, 8, 9, 8, 3, 3, 3, 1, 8, 8, 9, 1, 10, 9, 9, 9, 9, 5, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 11, 12, 8, 8, 1, 8, 9, 11, 2, 2, 2, 2, 3, 1, 2, 2, 8, 2, 4, 9, 1, 2, 9, 8, 2, 8, 9, 9, 3, 10, 9, 9, 2, 8, 9, 8, 12, 12, 1, 3, 8, 8, 8, 2, 7, 7, 7, 7, 3, 9, 1, 9, 8, 9, 9, 1, 1, 1, 2, 9, 9, 9, 11, 1, 8, 8, 9, 1, 9, 8, 8, 8, 1, 1, 8, 7, 1, 1, 8, 8, 9, 4, 4, 8, 2, 2, 8, 8, 8, 8, 8, 8, 11, 8, 2, 9, 4, 9, 3, 9, 9, 1, 3, 9, 3, 1, 12, 8, 9, 12, 1, 8, 4, 2, 1, 4, 8, 3, 3, 8, 2, 8, 9, 7, 8, 8, 8, 5, 8, 3, 9, 8, 8, 13, 12, 1, 1, 2, 8, 4, 1, 9, 9, 12, 8, 9, 12, 9, 1, 9, 9, 9, 9, 3, 2, 9, 9, 4, 8, 12, 2, 4, 9, 3, 1, 9, 7, 8, 9, 9, 8, 4, 8, 8, 7, 9, 10, 3, 8, 8, 8, 1, 1, 1, 1, 8, 8, 4, 1, 10, 1, 5, 7, 7, 1, 8, 9, 3, 7, 2, 7, 7, 2, 4, 8, 12, 7, 4, 2, 9, 9, 12, 6, 10, 8, 2, 4, 12, 9, 9, 3, 8, 8, 1, 2, 10, 9, 9, 8, 4, 12, 2, 1, 8, 8, 8, 12, 10, 10, 9, 3, 8, 8, 9, 2, 8, 10, 1, 1, 1, 1, 2, 1, 1, 1, 1, 9, 8, 12, 9, 4, 8, 8, 9, 1, 9, 3, 9, 8, 8, 1, 7, 7, 10, 1, 8, 8, 1, 9, 8, 10, 3, 1, 7, 1, 8, 8, 12, 8, 8, 1, 8, 7, 1, 7, 7, 8, 2, 1, 8, 8, 2, 10, 8, 8, 8, 8, 8, 10, 1, 8, 8, 12, 8, 3, 3, 2, 2, 2, 10, 8, 8, 8, 2, 9, 1, 8, 9, 3, 2, 8, 10, 8, 6, 1, 1, 8, 4, 1, 9, 10, 8, 1, 7, 1, 2, 8, 1, 1, 1, 12, 1, 9, 12, 8, 12, 12, 12, 8, 8, 12, 4, 8, 8, 8, 8, 9, 9, 1, 3, 3, 3, 3, 1, 12, 12, 9, 10, 8, 8, 1, 9, 2, 2, 13, 9, 8, 9, 2, 1, 9, 1, 8, 8, 8, 4, 8, 1, 1, 1, 12, 12, 7, 2, 2, 2, 8, 3, 8, 9, 2, 10, 7, 8, 9, 2, 1, 2, 12, 12, 8, 8, 9, 2, 2, 9, 11, 1, 8, 1, 10, 9, 2, 1, 4, 7, 7, 7, 7, 7, 12, 8, 8, 8, 1, 1, 10, 1, 12, 1, 8, 2, 1, 1, 12, 8, 7, 9, 12, 8, 9, 3, 9, 8, 8, 8, 8, 3, 11, 2, 2, 9, 8, 8, 10, 8, 2, 7, 3, 1, 4, 7, 8, 8, 1, 8, 3, 7, 12, 8, 10, 9, 9, 8, 8, 2, 8, 9, 9, 1, 2, 8, 8, 9, 8, 3, 8, 1, 8, 10, 9, 8, 9, 9, 12, 4, 4, 8, 9, 9, 8, 2, 10, 1, 2, 8, 9, 1, 9, 9, 9, 7, 12, 12, 8, 1, 1, 1, 1, 8, 3, 1, 1, 8, 1, 8, 8, 7, 8, 8, 8, 8, 3, 2, 2, 10, 10, 10, 7, 8, 1, 2, 12, 7, 9, 8, 7, 8, 12, 2, 8, 9, 2, 6, 6, 7, 9, 8, 1, 8, 9, 8, 1, 12, 1, 2, 8, 7, 7, 7, 8, 2, 2, 8, 1, 2, 2, 9, 9, 1, 8, 8, 4, 3, 3, 1, 6, 3, 3, 12, 3, 8, 9, 1, 4, 3, 1, 8, 3, 9, 2, 8, 2, 8, 8, 8, 1, 1, 1, 9, 9, 8, 1, 9, 8, 1, 1, 3, 10, 8, 1, 1, 3, 9, 1, 4, 4, 1, 8, 9, 9, 2, 0, 0, 1, 8, 3, 1, 8, 8, 9, 8, 8, 1, 1, 8, 9, 8, 8, 8, 7, 9, 8, 8, 8, 10, 9, 8, 1, 2, 6, 1, 9, 9, 8, 12, 12, 12, 8, 8, 2, 8, 1, 2, 2, 2, 1, 9, 8, 2, 12, 2, 8, 12, 8, 9, 8, 8, 9, 7, 1, 1, 1, 1, 1, 8, 8, 1, 8, 8, 1, 1, 3, 2, 8, 8, 9, 10, 10, 2, 2, 1, 9, 2, 9, 9, 4, 12, 12, 12, 10, 7, 3, 3, 4, 2, 2, 9, 2, 8, 4, 2, 4, 1, 10, 9, 7, 8, 7, 1, 1, 3, 3, 1, 1, 3, 3, 3, 1, 1, 1, 1, 8, 2, 3, 1, 1, 2, 8, 8, 12, 8, 8, 8, 8, 11, 9, 1, 8, 9, 2, 8, 8, 8, 3, 9, 1, 9, 2, 7, 2, 8, 2, 8, 10, 8, 1, 10, 1, 1, 9, 9, 8, 8, 1, 8, 8, 8, 12, 8, 8, 8, 1, 8, 8, 8, 1, 9, 1, 1, 8, 1, 8, 9, 8, 2, 12, 9, 9, 0, 1, 8, 8, 1, 8, 12, 8, 8, 10, 8, 8, 8, 7, 8, 1, 8, 7, 3, 10, 1, 8, 9, 1, 8, 8, 8, 10, 1, 10, 3, 9, 1, 8, 9, 2, 8, 3, 3, 9, 9, 7, 9, 1, 1, 9, 2, 1, 1, 1, 7, 1, 1, 8, 8, 1, 1, 8, 1, 8, 3, 12, 9, 3, 3, 8, 8, 8, 8, 3, 1, 3, 3, 1, 11, 0, 8, 8, 7, 8, 12, 1, 8, 9, 8, 9, 8, 8, 3, 8, 8, 1, 1, 1, 9, 2, 2, 2, 8, 7, 12, 8, 8, 9, 10, 10, 7, 8, 1, 9, 8, 7, 3, 1, 3, 8, 2, 2, 3, 9, 8, 4, 4, 8, 9, 2, 1, 1, 7, 8, 9, 9, 7, 8, 7, 7, 8, 2, 2, 8, 4, 9, 7, 10, 0, 9, 8, 3, 7, 8, 1, 1, 8, 9, 9, 2, 2, 10, 1, 9, 10, 10, 10, 8, 3, 2, 12, 9, 9, 10, 12, 9, 12, 12, 9, 1, 2, 4, 12, 12, 7, 8, 9, 7, 7, 7, 3, 9, 8, 9, 1, 12, 8, 9, 4, 1, 3, 12, 12, 12, 12, 8, 8, 2, 1, 1, 2, 1, 1, 1, 12, 12, 8, 12, 2, 2, 12, 3, 3, 12, 8, 2, 8, 8, 12, 2, 1, 10, 3, 2, 8, 7, 1, 8, 1, 3, 7, 8, 9, 8, 3, 1, 1, 7, 8, 8, 9, 8, 2, 9, 2, 2, 9, 8, 1, 8, 8, 1, 3, 3, 1, 1, 10, 1, 2, 8, 1, 1, 1, 1, 9, 1, 4, 1, 7, 7, 7, 7, 2, 2, 8, 8, 12, 1, 9, 1, 7, 3, 3, 1, 8, 8, 10, 8, 9, 2, 9, 1, 3, 8, 8, 3, 12, 2, 8, 12, 2, 9, 1, 3, 3, 3, 3, 2, 8, 7, 9, 8, 3, 3, 1, 7, 8, 3, 1, 1, 12, 8, 9, 1, 2, 3, 8, 1, 1, 3, 3, 9, 1, 1, 1, 12, 1, 7, 3, 3, 1, 8, 8, 8, 1, 2, 4, 8, 1, 10, 2, 5, 3, 3, 12, 10, 9, 9, 12, 9, 0, 2, 8, 8, 9, 9, 9, 8, 1, 3, 1, 1, 4, 8, 1, 10, 8, 7, 2, 8, 2, 8, 4, 7, 8, 1, 9, 1, 9, 8, 2, 8, 2, 7, 9, 2, 2, 9, 1, 8, 12, 1, 8, 1, 4, 1, 9, 9, 1, 10, 12, 4, 8, 1, 7, 3, 9, 2, 12, 7, 8, 8, 2, 1, 12, 9, 8, 1, 2, 2, 8, 10, 2, 1, 7, 7, 7, 12, 3, 3, 8, 3, 8, 8, 3, 9, 8, 9, 1, 1, 8, 7, 9, 3, 3, 8, 1, 0, 9, 9, 9, 1, 8, 9, 9, 10, 1, 8, 7, 8, 8, 8, 9, 9, 8, 9, 10, 4, 9, 3, 7, 12, 1, 9, 9, 8, 9, 1, 9, 3, 1, 8, 4, 12, 10, 9, 8, 7, 10, 8, 12, 12, 3, 10, 8, 12, 2, 1, 2, 3, 9, 8, 8, 7, 1, 1, 2, 2, 1, 2, 2, 7, 1, 3, 9, 9, 3, 8, 8, 8, 8, 8, 7, 8, 8, 10, 8, 1, 8, 2, 8, 2, 2, 2, 2, 2, 1, 7, 12, 10, 1, 2, 8, 1, 4, 7, 8, 1, 12, 8, 7, 9, 2, 2, 2, 8, 1, 8, 1, 1, 0, 2, 2, 6, 1, 8, 2, 1, 8, 1, 1, 2, 2, 3, 2, 2, 10, 10, 9, 1, 7, 7, 8, 8, 1, 12, 10, 12, 3, 8, 8, 8, 3, 8, 3, 10, 2, 2, 2, 1, 2, 2, 1, 0, 1, 8, 9, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 12, 9, 9, 1, 10, 11, 12, 9, 1, 1, 8, 8, 1, 2, 12, 8, 3, 7, 2, 10, 9, 7, 8, 1, 2, 2, 7, 9, 12, 2, 2, 1, 8, 9, 2, 3, 2, 2, 2, 9, 9, 8, 9, 2, 3, 8, 8, 9, 7, 3, 10, 8, 8, 9, 1, 1, 2, 8, 1, 10, 8, 8, 9, 7, 1, 7, 12, 8, 1, 7, 2, 1, 3, 9, 2, 8, 8, 1, 2, 3, 9, 3, 8, 9, 7, 7, 1, 10, 2, 8, 8, 8, 1, 8, 2, 8, 8, 1, 2, 8, 10, 2, 1, 0, 8, 3, 8, 10, 10, 12, 3, 8, 9, 3, 10, 8, 8, 8, 1, 8, 8, 2, 2, 2, 2, 2, 2, 1, 1, 10, 1, 10, 8, 2, 1, 2, 2, 8, 3, 3, 2, 2, 1, 8, 1, 3, 1, 9, 2, 2, 1, 3, 2, 2, 3, 2, 2, 3, 2, 1, 1, 2, 1, 2, 7, 8, 2, 1, 12, 12, 3, 1, 9, 9, 7, 8, 7, 2, 7, 9, 2, 2, 2, 8, 9, 7, 9, 2, 8, 9, 9, 2, 9, 1, 1, 9, 8, 3, 3, 8, 2, 7, 8, 11, 2, 8, 9, 1, 8, 3, 1, 2, 1, 2, 2, 2, 2, 8, 3, 9, 2, 10, 9, 9, 2, 7, 7, 7, 1, 3, 8, 8, 1, 1, 8, 7, 1, 8, 8, 9, 3, 3, 3, 2, 4, 8, 12, 8, 1, 12, 9, 2, 8, 2, 12, 2, 1, 3, 8, 12, 12, 11, 8, 10, 9, 2, 9, 4, 10, 1, 12, 12, 9, 3, 8, 9, 12, 9, 9, 2, 2, 2, 3, 5, 1, 1, 1, 7, 7, 8, 2, 2, 8, 2, 1, 7, 3, 2, 9, 8, 9, 1, 1, 9, 8, 9, 3, 3, 2, 9, 4, 9, 8, 8, 1, 8, 10, 2, 0, 3, 8, 8, 8, 9, 12, 9, 8, 2, 2, 8, 10, 9, 8, 2, 2, 4, 1, 9, 9, 8, 8, 10, 3, 1, 1, 2, 8, 7, 8, 2, 1, 1, 8, 12, 2, 9, 4, 8, 3, 3, 3, 8, 2, 12, 12, 8, 9, 12, 8, 2, 12, 7, 9, 2, 2, 1, 3, 1, 3, 11, 9, 8, 1, 10, 2, 12, 3, 8, 4, 1, 2, 8, 8, 3, 9, 3, 8, 7, 1, 1, 3, 1, 8, 2, 9, 8, 12, 1, 1, 1, 9, 9, 1, 8, 8, 8, 2, 2, 12, 3, 1, 1, 1, 9, 9, 3, 2, 1, 1, 9, 9, 1, 9, 9, 1, 9, 3, 9, 1, 8, 1, 9, 8, 3, 8, 8, 9, 9, 8, 2, 8, 1, 2, 2, 10, 1, 2, 1, 1, 9, 1, 9, 3, 7, 7, 2, 10, 3, 3, 1, 1, 9, 1, 2, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 8, 8, 7, 1, 1, 8, 8, 2, 1, 12, 1, 8, 1, 9, 8, 8, 2, 1, 9, 9, 2, 2, 8, 1, 7, 7, 9, 8, 1, 6, 8, 8, 2, 2, 8, 3, 8, 3, 2, 3, 8, 1, 2, 2, 2, 8, 9, 9, 9, 12, 1, 9, 2, 1, 9, 2, 9, 9, 10, 8, 1, 1, 9, 2, 1, 7, 1, 3, 7, 1, 1, 1, 3, 8, 8, 8, 9, 9, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 1, 1, 1, 2, 2, 3, 1, 1, 2, 3, 3, 3, 7, 3, 1, 9, 3, 9, 1, 4, 1, 1, 9, 10, 9, 8, 2, 3, 10, 9, 3, 10, 12, 8, 9, 8, 2, 1, 9, 8, 1, 7, 8, 1, 9, 1, 2, 10, 7, 7, 8, 1, 3, 3, 9, 3, 3, 1, 1, 1, 9, 1, 3, 8, 8, 8, 1, 8, 1, 9, 7, 8, 8, 2, 1, 3, 8, 2, 1, 6, 1, 8, 8, 2, 8, 2, 2, 9, 8, 1, 1, 6, 8, 6, 10, 2, 1, 1, 8, 9, 3, 3, 3, 1, 3, 9, 6, 8, 1, 8, 3, 1, 2, 2, 12, 7, 1, 1, 1, 1, 12, 1, 8, 8, 3, 2, 1, 9, 2, 3, 3, 2, 2, 7, 2, 2, 2, 3, 1, 9, 8, 7, 1, 1, 3, 1, 9, 4, 3, 9, 2, 1, 1, 9, 8, 8, 7, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 10, 1, 1, 8, 2, 8, 1, 8, 1, 3, 1, 2, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 8, 1, 9, 8, 8, 1, 10, 8, 8, 1, 3, 9, 8, 9, 8, 2, 1, 3, 4, 1, 12, 1, 9, 8, 2, 7, 2, 1, 2, 9, 2, 1, 3, 8, 1, 2, 3, 8, 2, 10, 10, 10, 9, 9, 9, 3, 8, 3, 1, 1, 1, 1, 1, 1, 2, 1, 9, 2, 7, 9, 8, 7, 9, 1, 1, 1, 1, 8, 2, 2, 3, 3, 2, 12, 8, 3, 1, 1, 12, 9, 8, 2, 2, 9, 1, 2, 2, 9, 1, 1, 2, 4, 8, 1, 8, 10, 2, 9, 9, 9, 1, 2, 1, 1, 2, 2, 2, 12, 1, 2, 8, 3, 9, 9, 3, 2, 9, 9, 7, 2, 8, 8, 9, 2, 9, 1, 1, 1, 1, 1, 2, 8, 2, 1, 2, 2, 8, 3, 1, 1, 9, 1, 3, 10, 7, 9, 8, 8, 2, 2, 9, 2, 2, 2, 2, 2, 2, 9, 1, 3, 6, 4, 2, 2, 9, 1, 9, 8, 1, 1, 1, 7, 3, 2, 9, 9, 1, 9, 7, 2, 8, 9, 9, 12, 10, 8, 10, 2, 3, 1, 2, 2, 12, 12, 3, 12, 1, 2, 1, 2, 1, 2, 8, 2, 3, 12, 12, 8, 2, 2, 9, 2, 9, 2, 3, 3, 1, 1, 1, 12, 3, 7, 1, 3, 1, 2, 9, 2, 7, 2, 1, 8, 3, 7, 8, 1, 1, 3, 8, 3, 2, 9, 3, 1, 1, 1, 1, 11, 1, 2, 6, 1, 2, 3, 8, 9, 9, 2, 9, 2, 1, 1, 3, 1, 12, 9, 1, 1, 9, 1, 9, 9, 8, 9, 8, 1, 2, 7, 1, 0, 9, 8, 2, 3, 2, 4, 1, 1, 1, 8, 1, 12, 1, 2, 3, 3, 9, 9, 9, 9, 9, 7, 9, 3, 9, 1, 7, 3, 3, 3, 3, 7, 8, 2, 2, 2, 8, 2, 3, 9, 9, 3, 1, 8, 9, 12, 8, 8, 3, 2, 1, 6, 1, 9, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 9, 2, 5, 3, 2, 2, 8, 2, 1, 8, 3, 3, 8, 3, 1, 3, 9, 2, 8, 9, 4, 4, 9, 8, 8, 7, 7, 3, 1, 8, 8, 3, 2, 2, 10, 3, 3, 2, 2, 2, 2, 12, 3, 1, 2, 7, 7, 12, 2, 1, 2, 1, 1, 2, 1, 3, 3, 3, 1, 3, 9, 4, 8, 8, 4, 2, 4, 2, 8, 9, 1, 1, 2, 2, 2, 8, 7, 2, 8, 2, 9, 1, 8, 1, 1, 2, 1, 1, 1, 2, 9, 9, 8, 1, 8, 1, 4, 8, 1, 2, 7, 9, 2, 1, 8, 9, 8, 9, 1, 1, 2, 3, 2, 12, 7, 1, 2, 4, 4, 4, 2, 2, 2, 9, 8, 8, 1, 12, 3, 3, 2, 2, 3, 12, 1, 5, 1, 1, 3, 2, 8, 8, 2, 2, 2, 3, 9, 8, 8, 9, 8, 8, 11, 8, 2, 9, 2, 3, 1, 7, 1, 8, 2, 8, 1, 1, 1, 8, 1, 1, 1, 7, 8, 8, 2, 3, 2, 1, 8, 8, 1, 8, 4, 8, 9, 8, 9, 8, 1, 2, 3, 2, 1, 2, 2, 3, 1, 9, 4, 8, 1, 1, 9, 1, 1, 8, 2, 2, 2, 1, 7, 3, 3, 1, 3, 3, 12, 3, 1, 1, 3, 1, 1, 4, 8, 4, 4, 3, 3, 3, 4, 8, 1, 9, 9, 9, 4, 1, 7, 4, 8, 4, 9, 8, 1, 1, 3, 8, 9, 1, 9, 7, 1, 1, 9, 1, 8, 8, 8, 1, 1, 8, 2, 2, 2, 9, 4, 4, 1, 2, 1, 2, 9, 1, 1, 8, 5, 5, 5, 9, 12, 4, 1, 2, 1, 8, 8, 1, 9, 9, 2, 12, 1, 1, 7, 8, 8, 4, 1, 2, 8, 11, 2, 3, 2, 2, 1, 11, 2, 2, 2, 2, 9, 9, 2, 2, 9, 3, 1, 9, 1, 1, 1, 7, 8, 1, 8, 9, 1, 2, 9, 8, 1, 2, 9, 8, 12, 2, 2, 10, 8, 2, 2, 8, 8, 1, 2, 6, 1, 1, 7, 7, 2, 3, 2, 1, 1, 8, 1, 10, 8, 12, 6, 4, 1, 4, 1, 2, 9, 8, 9, 4, 8, 8, 10, 8, 8, 8, 8, 8, 2, 2, 8, 4, 9, 3, 3, 3, 3, 3, 9, 2, 1, 1, 2, 3, 2, 1, 2, 3, 3, 3, 2, 2, 3, 3, 2, 1, 2, 3, 3, 3, 3, 12, 9, 3, 2, 2, 3, 1, 5, 1, 1, 3, 2, 2, 1, 2, 9, 3, 9, 8, 1, 8, 7, 7, 9, 1, 1, 7, 9, 10, 1, 7, 1, 4, 3, 8, 9, 4, 9, 9, 2, 9, 2, 8, 4, 2, 2, 9, 5, 2, 1, 10, 9, 3, 1, 1, 1, 2, 1, 2, 9, 1, 7, 9, 9, 8, 2, 2, 8, 9, 1, 9, 8, 2, 3, 2, 2, 1, 2, 2, 2, 1, 1, 8, 1, 9, 4, 12, 8, 2, 7, 2, 2, 1, 9, 3, 1, 8, 12, 1, 1, 2, 1, 10, 2, 6, 12, 12, 4, 9, 1, 9, 10, 1, 2, 8, 2, 1, 8, 6, 12, 9, 9, 2, 1, 7, 8, 9, 5, 8, 1, 8, 8, 3, 1, 8, 2, 8, 2, 2, 1, 2, 9, 2, 8, 1, 12, 8, 2, 7, 3, 3, 12, 2, 3, 3, 9, 9, 3, 3, 3, 3, 3, 2, 1, 4, 1, 4, 8, 8, 2, 1, 2, 9, 12, 1, 10, 12, 1, 2, 9, 4, 8, 10, 3, 2, 8, 7, 4, 8, 9, 2, 7, 1, 10, 2, 2, 2, 8, 4, 2, 2, 1, 1, 8, 7, 9, 2, 1, 9, 8, 9, 12, 4, 8, 2, 8, 7, 7, 1, 9, 2, 1, 1, 9, 1, 8, 2, 3, 9, 9, 1, 3, 2, 9, 2, 2, 8, 1, 1, 2, 1, 2, 1, 9, 8, 2, 2, 4, 8, 8, 9, 5, 5, 9, 8, 9, 6, 2, 1, 12, 2, 3, 8, 8, 9, 2, 2, 1, 3, 2, 10, 9, 10, 7, 2, 8, 4, 2, 8, 9, 8, 1, 3, 8, 8, 1, 8, 3, 8, 8, 1, 10, 3, 1, 5, 8, 8, 9, 2, 2, 9, 2, 1, 9, 1, 4, 1, 12, 8, 8, 2, 1, 1, 1, 1, 1, 9, 2, 9, 8, 9, 5, 9, 1, 8, 2, 4, 1, 1, 1, 9, 12, 4, 1, 1, 9, 8, 4, 1, 8, 9, 8, 8, 9, 9, 9, 9, 9, 9, 1, 3, 4, 2, 2, 8, 2, 9, 2, 3, 8, 3, 1, 7, 2, 1, 1, 4, 2, 9, 2, 1, 3, 2, 9, 2, 9, 3, 8, 1, 9, 1, 1, 2, 8, 8, 8, 2, 3, 9, 9, 8, 2, 4, 1, 5, 1, 1, 9, 9, 2, 1, 1, 1, 9, 9, 1, 3, 9, 2, 2, 9, 9, 8, 3, 9, 9, 8, 2, 2, 8, 9, 2, 2, 8, 9, 10, 10, 2, 8, 7, 9, 9, 4, 2, 4, 11, 2, 1, 7, 8, 8, 8, 9, 4, 9, 8, 8, 2, 1, 1, 9, 8, 3, 3, 8, 8, 7, 9, 1, 3, 4, 8, 10, 2, 4, 4, 8, 2, 8, 2, 8, 9, 2, 1, 2, 2, 3, 1, 9, 4, 5, 9, 9, 1, 1, 1, 1, 1, 1, 7, 1, 1, 1, 8, 1, 1, 1, 1, 1, 9, 1, 2, 1, 12, 9, 3, 9, 9, 4, 1, 9, 1, 1, 2, 11, 9, 3, 2, 2, 2, 4, 2, 3, 2, 7, 7, 8, 1, 10, 9, 5, 7, 1, 10, 8, 1, 2, 7, 1, 12, 5, 8, 4, 2, 9, 9, 8, 2, 9, 8, 8, 10, 2, 3, 2, 7, 2, 8, 10, 3, 2, 9, 9, 9, 1, 1, 1, 1, 8, 2, 10, 9, 8, 1, 2, 2, 2, 1, 2, 1, 3, 9, 12, 2, 2, 4, 8, 1, 3, 9, 4, 9, 1, 9, 9, 2, 1, 1, 9, 7, 10, 3, 10, 2, 9, 2, 9, 2, 8, 2, 1, 2, 3, 1, 1, 1, 8, 5, 8, 3, 1, 1, 4, 2, 2, 1, 3, 8, 2, 1, 1, 1, 2, 9, 4, 1, 8, 1, 2, 8, 2, 9, 2, 2, 5, 5, 2, 5, 2, 1, 8, 8, 1, 3, 12, 2, 4, 3, 2, 2, 2, 6, 2, 3, 3, 1, 8, 2, 2, 1, 1, 8, 8, 10, 1, 9, 2, 9, 12, 0, 2, 1, 3, 2, 2, 1, 2, 1, 9, 9, 2, 9, 8, 8, 1, 7, 8, 1, 2, 6, 9, 8, 10, 1, 12, 2, 2, 1, 8, 2, 1, 12, 7, 4, 2, 10, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 9, 8, 10, 2, 10, 9, 9, 12, 5, 3, 2, 8, 2, 8, 3, 3, 1, 4, 9, 10, 2, 4, 8, 1, 2, 10, 12, 12, 3, 1, 1, 2, 9, 6, 6, 1, 9, 1, 8, 1, 8, 8, 8, 8, 2, 2, 2, 8, 8, 2, 1, 1, 1, 1, 1, 8, 8, 5, 8, 8, 1, 8, 9, 9, 1, 7, 12, 9, 9, 7, 2, 2, 7, 8, 9, 8, 2, 9, 6, 3, 4, 8, 4, 1, 2, 9, 8, 8, 8, 2, 1, 1, 8, 8, 3, 1, 9, 9, 7, 1, 2, 2, 2, 9, 4, 1, 2, 12, 1, 8, 2, 1, 9, 1, 8, 9, 9, 2, 5, 4, 2, 1, 2, 8, 12, 8, 10, 3, 8, 8, 8, 2, 2, 8, 2, 8, 2, 4, 8, 10, 2, 7, 2, 1, 8, 8, 9, 5, 8, 1, 12, 7, 10, 2, 2, 2, 1, 4, 8, 12, 1, 8, 2, 2, 9, 1, 8, 3, 1, 1, 5, 10, 2, 1, 2, 4, 8, 9, 3, 2, 8, 7, 4, 4, 9, 9, 2, 8, 1, 1, 2, 4, 7, 1, 9, 1, 1, 1, 8, 4, 1, 3, 1, 2, 2, 9, 1, 8, 8, 2, 2, 9, 9, 1, 8, 8, 1, 9, 8, 8, 2, 2, 2, 2, 1, 1, 1, 7, 4, 1, 1, 4, 2, 3, 3, 2, 3, 9, 2, 8, 2, 1, 5, 1, 2, 2, 1, 3, 5, 2, 9, 1, 1, 9, 8, 1, 4, 8, 1, 8, 2, 4, 8, 4, 7, 9, 8, 1, 2, 2, 4, 4, 11, 3, 11, 1, 3, 8, 1, 9, 6, 8, 9, 3, 9, 8, 9, 2, 3, 3, 7, 1, 7, 2, 9, 9, 1, 8, 8, 1, 5, 5, 8, 8, 1, 2, 1, 3, 9, 9, 5, 9, 8, 1, 4, 3, 8, 1, 1, 2, 1, 8, 9, 8, 2, 2, 2, 1, 2, 4, 10, 8, 1, 9, 1, 8, 1, 1, 9, 9, 8, 11, 1, 8, 2, 1, 2, 8, 2, 8, 8, 2, 9, 6, 10, 1, 8, 6, 4, 5, 11, 2, 2, 8, 1, 8, 1, 8, 1, 4, 8, 1, 1, 1, 8, 3, 7, 3, 3, 7, 1, 1, 4, 8, 1, 6, 4, 2, 2, 1, 1, 1, 1, 6, 2, 2, 8, 1, 8, 5, 5, 2, 1, 1, 2, 3, 7, 1, 1, 6, 2, 9, 3, 9, 8, 9, 2, 1, 4, 2, 9, 13, 9, 2, 8, 12, 4, 1, 1, 9, 5, 1, 1, 1, 1, 8, 2, 1, 1, 2, 9, 0, 12, 1, 1, 8, 9, 8, 3, 2, 2, 12, 8, 2, 2, 2, 1, 10, 1, 9, 8, 9, 5, 2, 2, 9, 2, 8, 4, 8, 3, 7, 9, 2, 2, 7, 2, 2, 8, 1, 1, 9, 10, 9, 8, 2, 9, 0, 7, 1, 1, 1, 9, 8, 2, 8, 12, 8, 3, 2, 8, 8, 7, 7, 8, 12, 2, 1, 3, 9, 2, 2, 8, 2, 8, 8, 12, 8, 8, 1, 8, 9, 2, 4, 4, 7, 2, 1, 1, 9, 3, 7, 1, 3, 9, 8, 2, 2, 3, 1, 3, 10, 2, 3, 7, 1, 8, 1, 1, 10, 3, 10, 8, 4, 1, 2, 4, 3, 10, 9, 3, 9, 5, 8, 7, 2, 9, 3, 3, 2, 11, 8, 1, 1, 7, 2, 7, 2, 9, 4, 8, 1, 12, 8, 7, 9, 1, 0, 2, 6, 4, 9, 3, 2, 4, 12, 9, 8, 5, 9, 2, 8, 4, 6, 8, 9, 3, 1, 8, 7, 3, 1, 1, 1, 8, 9, 1, 8, 7, 9, 8, 2, 1, 2, 2, 3, 2, 2, 1, 1, 4, 9, 7, 3, 2, 8, 8, 9, 1, 9, 7, 4, 2, 2, 8, 5, 9, 1, 5, 7, 1, 4, 6, 9, 10, 1, 8, 2, 9, 1, 9, 2, 9, 8, 2, 9, 9, 11, 2, 12, 2, 2, 9, 4, 8, 1, 9, 9, 2, 8, 9, 1, 2, 9, 3, 8, 8, 1, 7, 8, 8, 2, 3, 2, 2, 2, 2, 9, 8, 10, 2, 2, 1, 9, 11, 1, 8, 8, 2, 4, 2, 1, 2, 8, 8, 9, 2, 8, 9, 2, 3, 1, 2, 1, 3, 10, 8, 1, 2, 4, 1, 9, 8, 9, 3, 3, 9, 8, 2, 11, 3, 7, 1, 8, 7, 1, 8, 8, 8, 1, 4, 8, 8, 1, 9, 3, 1, 1, 2, 8, 8, 8, 2, 1, 8, 10, 2, 12, 8, 8, 9, 1, 8, 1, 3, 2, 2, 10, 7, 2, 2, 1, 1, 8, 2, 9, 1, 2, 9, 3, 3, 10, 1, 4, 7, 10, 12, 2, 4, 10, 8, 6, 2, 9, 1, 8, 3, 1, 2, 8, 8, 2, 12, 10, 2, 10, 9, 1, 2, 5, 8, 12, 8, 8, 7, 8, 8, 1, 8, 2, 2, 9, 1, 8, 10, 5, 5, 5, 8, 1, 9, 1, 13, 1, 2, 2, 1, 2, 4, 9, 2, 1, 9, 13, 11, 1, 9, 9, 3, 10, 8, 7, 8, 8, 4, 2, 1, 9, 4, 3, 1, 1, 10, 9, 2, 8, 6, 2, 1, 1, 3, 2, 8, 1, 1, 1, 1, 2, 4, 1, 1, 10, 1, 8, 1, 1, 9, 1, 7, 1, 1, 9, 9, 2, 12, 9, 1, 8, 1, 12, 1, 8, 3, 8, 1, 8, 1, 2, 10, 1, 1, 2, 2, 9, 3, 9, 12, 1, 9, 1, 2, 8, 7, 2, 1, 1, 3, 2, 8, 4, 4, 5, 12, 7, 8, 9, 6, 1, 8, 9, 2, 1, 9, 1, 4, 1, 8, 2, 1, 1, 8, 7, 4, 9, 1, 8, 4, 2, 7, 5, 1, 3, 9, 2, 8, 2, 1, 2, 9, 1, 1, 2, 3, 4, 3, 1, 2, 2, 10, 2, 2, 8, 1, 1, 2, 4, 9, 2, 11, 9, 8, 9, 2, 1, 10, 4, 1, 1, 10, 7, 2, 10, 8, 1, 10, 8, 8, 8, 8, 8, 8, 2, 2, 2, 8, 3, 4, 1, 1, 1, 2, 1, 8, 8, 2, 8, 3, 8, 3, 1, 2, 3, 1, 1, 10, 1, 4, 4, 3, 3, 1, 9, 1, 1, 2, 1, 1, 6, 1, 1, 1, 9, 1, 4, 1, 1, 1, 1, 1, 1, 2, 12, 8, 8, 1, 9, 12, 10, 8, 2, 12, 1, 1, 2, 1, 7, 10, 7, 1, 2, 1, 10, 8, 2, 2, 8, 2, 2, 1, 9, 8, 8, 8, 8, 3, 1, 4, 2, 8, 3, 10, 10, 1, 9, 1, 9, 1, 9, 1, 8, 3, 1, 1, 8, 8, 8, 6, 3, 4, 1, 1, 1, 9, 9, 5, 2, 10, 2, 6, 2, 2, 7, 1, 8, 2, 11, 1, 1, 1, 2, 1, 9, 4, 4, 2, 8, 4, 6, 8, 8, 10, 10, 2, 1, 2, 9, 1, 8, 8, 3, 4, 8, 8, 2, 8, 8, 1, 2, 1, 2, 9, 4, 1, 3, 3, 3, 8, 8, 8, 2, 6, 4, 3, 3, 12, 3, 4, 9, 6, 8, 7, 7, 8, 6, 4, 1, 10, 6, 3, 3, 8, 1, 1, 8, 1, 11, 8, 1, 1, 2, 3, 11, 7, 2, 1, 1, 1, 9, 1, 2, 1, 1, 9, 8, 1, 1, 8, 0, 4, 1, 1, 2, 1, 1, 2, 2, 9, 1, 10, 1, 3, 8, 9, 3, 3, 1, 10, 1, 9, 1, 1, 7, 4, 1, 8, 10, 1, 2, 10, 1, 1, 2, 3, 3, 9, 1, 8, 10, 1, 7, 9, 1, 9, 6, 3, 9, 2, 8, 4, 12, 12, 3, 1, 1, 9, 1, 9, 2, 1, 1, 1, 1, 1, 9, 2, 1, 2, 10, 9, 8, 8, 10, 8, 2, 3, 2, 1, 12, 8, 12, 2, 9, 1, 3, 2, 5, 2, 2, 8, 2, 2, 4, 10, 9, 10, 9, 4, 2, 4, 12, 8, 2, 1, 8, 3, 9, 2, 9, 4, 1, 1, 1, 1, 1, 9, 6, 2, 9, 2, 1, 3, 2, 2, 5, 8, 9, 1, 6, 3, 1, 2, 2, 2, 6, 1, 8, 10, 8, 3, 3, 13, 2, 9, 9, 10, 6, 12, 8, 2, 9, 2, 3, 8, 8, 1, 2, 2, 3, 2, 10, 1, 8, 9, 1, 8, 9, 8, 8, 2, 10, 2, 1, 1, 1, 9, 9, 12, 1, 1, 4, 8, 3, 2, 2, 4, 4, 2, 2, 1, 1, 1, 9, 2, 2, 4, 1, 1, 8, 8, 8, 9, 2, 13, 9, 9, 4, 1, 9, 7, 10, 10, 8, 1, 9, 1, 1, 1, 8, 12, 4, 1, 2, 1, 1, 1, 7, 8, 3, 3, 1, 2, 2, 7, 2, 2, 10, 1, 8, 4, 0, 1, 9, 4, 1, 1, 2, 10, 10, 7, 9, 3, 12, 11, 2, 8, 10, 8, 9, 4, 3, 4, 10, 1, 1, 9, 3, 10, 1, 5, 3, 3, 2, 2, 1, 1, 6, 1, 7, 1, 1, 12, 1, 1, 1, 10, 1, 8, 8, 1, 3, 8, 3, 1, 2, 8, 3, 4, 2, 8, 8, 6, 1, 1, 4, 1, 2, 9, 5, 1, 7, 8, 9, 2, 4, 9, 8, 5, 9, 9, 9, 1, 2, 1, 3, 8, 9, 2, 9, 8, 9, 1, 8, 13, 9, 3, 8, 1, 4, 1, 3, 1, 6, 4, 10, 2, 2, 7, 8, 8, 12, 8, 9, 9, 9, 10, 3, 12, 12, 2, 9, 10, 9, 7, 2, 3, 4, 10, 10, 2, 7, 7, 1, 7, 3, 9, 1, 9, 8, 2, 9, 1, 8, 1, 10, 8, 8, 2, 7, 8, 1, 8, 9, 8, 1, 4, 1, 8, 8, 8, 1, 1, 10, 3, 2, 2, 6, 8, 9, 8, 2, 1, 1, 3, 8, 8, 1, 4, 4, 3, 9, 10, 4, 2, 4, 2, 9, 2, 2, 9, 1, 1, 10, 1, 1, 2, 1, 1, 1, 9, 1, 8, 8, 8, 2, 3, 8, 1, 6, 7, 3, 1, 9, 1, 2, 1, 6, 1, 2, 10, 1, 4, 2, 3, 2, 9, 9, 4, 9, 9, 1, 2, 8, 4, 7, 8, 7, 13, 9, 1, 2, 1, 9, 3, 3, 6, 8, 9, 10, 9, 2, 2, 3, 12, 1, 1, 1, 13, 2, 1, 7, 10, 8, 9, 1, 2, 9, 1, 1, 1, 2, 1, 12, 5, 6, 9, 10, 3, 1, 10, 1, 3, 2, 8, 9, 2, 10, 8, 8, 9, 2, 8, 9, 2, 2, 2, 8, 8, 2, 3, 1, 4, 8, 1, 9, 9, 2, 8, 10, 9, 1, 2, 12, 8, 8, 0, 2, 1, 1, 9, 10, 1, 6, 2, 2, 10, 2, 2, 4, 2, 2, 12, 1, 6, 7, 8, 9, 1, 3, 5, 7, 3, 1, 3, 1, 1, 3, 2, 6, 3, 2, 1, 8, 3, 5, 2, 1, 1, 8, 1, 1, 0, 2, 3, 5, 3, 1, 1, 9, 8, 8, 8, 8, 4, 7, 2, 9, 12, 5, 9, 3, 12, 3, 9, 1, 9, 1, 7, 3, 9, 3, 10, 1, 2, 1, 4, 9, 8, 2, 9, 11, 2, 8, 9, 4, 1, 1, 1, 1, 1, 1, 1, 9, 1, 9, 1, 1, 1, 12, 3, 10, 3, 6, 1, 7, 10, 8, 3, 7, 1, 1, 2, 6, 1, 3, 9, 2, 8, 1, 8, 8, 1, 8, 10, 12, 1, 10, 12, 10, 1, 8, 8, 1, 4, 7, 9, 2, 1, 9, 3, 8, 12, 10, 6, 1, 6, 8, 3, 1, 3, 1, 10, 10, 9, 8, 1, 2, 9, 8, 8, 1, 9, 8, 8, 3, 1, 3, 9, 12, 1, 8, 1, 5, 8, 11, 5, 5, 1, 2, 1, 3, 1, 1, 1, 9, 8, 8, 1, 9, 10, 8, 4, 1, 1, 8, 10, 8, 9, 1, 10, 1, 7, 2, 1, 1, 9, 6, 2, 9, 8, 1, 1, 1, 9, 8, 8, 1, 9, 9, 1, 1, 2, 7, 9, 2, 9, 9, 8, 7, 6, 8, 7, 8, 2, 9, 2, 1, 8, 8, 8, 2, 6, 3, 1, 8, 12, 12, 8, 7, 1, 2, 2, 7, 1, 9, 8, 1, 4, 1, 1, 8, 5, 8, 1, 8, 8, 8, 8, 1, 2, 11, 1, 1, 1, 2, 7, 1, 9, 2, 2, 2, 9, 8, 9, 2, 9, 1, 8, 1, 7, 11, 13, 1, 9, 8, 2, 2, 1, 2, 3, 10, 3, 10, 4, 3, 9, 1, 8, 1, 1, 13, 1, 1, 3, 8, 1, 2, 2, 2, 9, 4, 1, 8, 1, 9, 3, 6, 8, 5, 2, 8, 2, 8, 1, 9, 2, 2, 8, 1, 1, 4, 8, 9, 2, 2, 7, 1, 8, 12, 2, 12, 8, 2, 9, 9, 3, 8, 1, 1, 9, 9, 9, 2, 8, 1, 9, 1, 8, 9, 8, 2, 2, 4, 1, 9, 10, 10, 8, 8, 1, 1, 2, 1, 4, 1, 2, 1, 1, 3, 12, 8, 8, 8, 8, 10, 2, 8, 12, 1, 9, 9, 8, 9, 1, 2, 1, 8, 8, 8, 2, 8, 8, 3, 10, 8, 9, 1, 1, 1, 3, 4, 8, 10, 6, 3, 1, 3, 2, 8, 9, 3, 5, 4, 1, 5, 2, 9, 9, 9, 1, 1, 1, 9, 9, 6, 10, 9, 8, 12, 2, 9, 1, 2, 1, 1, 1, 8, 1, 12, 1, 12, 1, 9, 1, 8, 1, 2, 1, 2, 8, 8, 10, 1, 9, 1, 2, 2, 8, 8, 3, 12, 1, 11, 2, 10, 12, 11, 2, 1, 10, 1, 1, 9, 3, 10, 2, 7, 1, 8, 1, 9, 9, 2, 1, 3, 12, 5, 9, 9, 8, 1, 8, 8, 8, 1, 1, 3, 9, 8, 9, 8, 3, 10, 3, 7, 8, 9, 2, 3, 1, 9, 10, 9, 2, 8, 2, 6, 4, 1, 1, 3, 8, 2, 3, 9, 1, 2, 1, 8, 1, 2, 2, 2, 2, 9, 9, 4, 8, 9, 1, 1, 2, 9, 1, 5, 2, 9, 8, 10, 1, 2, 10, 8, 5, 6, 4, 8, 1, 1, 1, 8, 9, 2, 8, 8, 8, 12, 2, 2, 1, 8, 1, 2, 1, 9, 8, 8, 9, 1, 1, 8, 7, 1, 8, 0, 2, 3, 8, 1, 1, 8, 1, 1, 12, 3, 2, 10, 8, 10, 6, 1, 8, 8, 10, 8, 8, 1, 4, 8, 1, 2, 9, 8, 1, 1, 3, 3, 5, 1, 1, 2, 1, 2, 1, 9, 8, 3, 9, 8, 2, 10, 9, 1, 8, 1, 10, 9, 10, 1, 2, 3, 8, 1, 3, 1, 9, 9, 8, 1, 9, 8, 8, 9, 1, 9, 2, 8, 8, 2, 13, 8, 10, 8, 9, 3, 2, 1, 3, 1, 12, 10, 10, 1, 11, 1, 2, 4, 2, 10, 1, 8, 11, 1, 1, 1, 2, 2, 8, 2, 9, 8, 9, 9, 12, 8, 1, 9, 2, 4, 1, 8, 3, 9, 1, 6, 5, 8, 9, 3, 3, 2, 1, 1, 1, 8, 11, 1, 8, 7, 1, 11, 9, 1, 7, 9, 9, 8, 8, 8, 12, 8, 1, 2, 9, 8, 8, 2, 10, 9, 8, 8, 4, 10, 9, 8, 2, 10, 10, 2, 1, 2, 1, 2, 1, 4, 1, 7, 1, 1, 3, 12, 9, 8, 5, 9, 10, 1, 9, 9, 2, 7, 4, 1, 1, 8, 12, 8, 2, 2, 9, 4, 1, 1, 5, 9, 1, 8, 12, 8, 1, 1, 4, 9, 10, 2, 3, 1, 3, 3, 3, 8, 1, 2, 1, 2, 1, 2, 9, 1, 2, 8, 9, 4, 8, 8, 10, 2, 12, 5, 5, 1, 8, 1, 7, 8, 1, 1, 8, 9, 12, 4, 9, 3, 1, 2, 5, 9, 2, 1, 2, 2, 1, 2, 8, 1, 8, 8, 2, 2, 1, 8, 4, 1, 2, 10, 9, 10, 8, 1, 10, 4, 8, 8, 10, 2, 8, 1, 1, 3, 10, 1, 4, 2, 8, 3, 3, 2, 9, 8, 5, 5, 9, 3, 10, 8, 1, 2, 1, 2, 9, 1, 1, 2, 9, 9, 8, 8, 11, 9, 4, 1, 8, 2, 7, 1, 2, 8, 2, 9, 9, 8, 2, 9, 9, 8, 8, 1, 2, 8, 1, 1, 2, 9, 8, 1, 4, 9, 1, 8, 12, 1, 12, 2, 8, 2, 9, 1, 12, 1, 2, 9, 1, 1, 9, 3, 2, 9, 9, 2, 11, 8, 7, 9, 9, 9, 8, 8, 1, 2, 8, 1, 1, 4, 1, 2, 10, 1, 9, 2, 1, 1, 1, 9, 1, 13, 4, 3, 2, 1, 1, 2, 2, 7, 8, 7, 1, 1, 2, 8, 8, 3, 4, 8, 2, 10, 13, 8, 8, 9, 2, 2, 1, 1, 10, 4, 2, 7, 9, 8, 2, 1, 9, 8, 1, 1, 9, 8, 9, 8, 2, 8, 2, 2, 9, 2, 1, 9, 1, 2, 4, 8, 2, 1, 1, 8, 1, 4, 1, 9, 3, 9, 2, 7, 1, 9, 6, 1, 10, 2, 2, 2, 2, 2, 10, 10, 10, 9, 9, 9, 3, 12, 10, 1, 1, 10, 1, 1, 2, 2, 1, 2, 3, 12, 8, 8, 1, 2, 9, 9, 1, 1, 10, 8, 9, 8, 3, 1, 1, 3, 1, 10, 1, 1, 1, 4, 1, 1, 1, 7, 10, 2, 1, 8, 1, 9, 3, 1, 10, 8, 8, 1, 5, 9, 1, 2, 1, 8, 8, 1, 3, 1, 10, 2, 1, 1, 2, 8, 2, 5, 3, 5, 2, 1, 1, 9, 1, 7, 9, 9, 2, 8, 1, 12, 4, 1, 4, 9, 9, 4, 8, 1, 10, 10, 8, 8, 8, 9, 2, 3, 5, 1, 8, 1, 1, 1, 7, 10, 1, 4, 12, 3, 2, 2, 9, 1, 1, 1, 2, 8, 4, 1, 7, 3, 12, 8, 6, 2, 2, 7, 9, 11, 1, 10, 9, 1, 8, 12, 2, 11, 1, 2, 3, 1, 1, 1, 8, 9, 2, 2, 2, 2, 3, 3, 8, 10, 4, 1, 2, 9, 8, 2, 2, 9, 1, 8, 11, 4, 2, 8, 7, 1, 1, 7, 3, 9, 9, 4, 5, 8, 10, 2, 9, 9, 9, 8, 1, 9, 2, 2, 2, 1, 2, 9, 4, 3, 12, 4, 3, 2, 3, 8, 3, 10, 1, 10, 1, 1, 8, 10, 6, 8, 9, 9, 1, 2, 9, 2, 9, 3, 8, 1, 1, 12, 1, 5, 1, 10, 8, 10, 2, 7, 1, 1, 1, 1, 3, 2, 3, 5, 9, 1, 2, 1, 9, 8, 10, 9, 8, 1, 8, 1, 8, 2, 8, 1, 2, 8, 1, 2, 5, 8, 12, 2, 1, 1, 1, 1, 1, 8, 8, 2, 1, 4, 2, 8, 8, 8, 2, 9, 9, 11, 1, 2, 9, 3, 1, 1, 8, 9, 2, 4, 10, 1, 9, 8, 4, 9, 8, 10, 8, 8, 9, 2, 8, 9, 3, 3, 3, 4, 3, 2, 2, 10, 8, 2, 1, 5, 1, 9, 1, 1, 2, 1, 2, 3, 1, 1, 8, 8, 1, 10, 8, 8, 1, 6, 4, 8, 2, 5, 8, 1, 3, 8, 2, 8, 9, 1, 1, 8, 12, 10, 1, 5, 8, 2, 8, 10, 9, 9, 1, 6, 9, 1, 10, 8, 2, 9, 10, 1, 2, 1, 1, 8, 8, 3, 9, 8, 1, 10, 2, 8, 1, 10, 1, 5, 1, 1, 1, 5, 1, 1, 1, 4, 1, 1, 1, 8, 2, 8, 1, 8, 3, 8, 9, 1, 8, 1, 8, 1, 1, 2, 2, 1, 12, 9, 9, 1, 8, 2, 1, 2, 8, 1, 9, 1, 1, 2, 1, 2, 2, 2, 1, 9, 9, 8, 8, 1, 1, 9, 10, 8, 4, 3, 3, 4, 9, 1, 3, 3, 10, 2, 2, 1, 8, 4, 1, 9, 4, 1, 1, 9, 8, 10, 4, 9, 9, 8, 2, 1, 3, 4, 9, 3, 8, 9, 1, 1, 2, 1, 7, 8, 2, 9, 1, 9, 2, 6, 9, 10, 8, 1, 1, 5, 9, 5, 1, 9, 10, 9, 3, 3, 8, 8, 2, 9, 2, 8, 2, 1, 8, 5, 8, 3, 10, 1, 1, 2, 1, 8, 1, 4, 3, 2, 9, 4, 9, 8, 8, 8, 1, 3, 9, 1, 9, 9, 1, 2, 1, 9, 8, 9, 8, 1, 1, 1, 4, 2, 2, 9, 9, 1, 1, 1, 3, 6, 1, 2, 3, 1, 4, 2, 9, 1, 9, 9, 1, 8, 2, 1, 9, 1, 8, 1, 8, 8, 2, 1, 9, 9, 6, 8, 8, 9, 8, 10, 8, 9, 5, 1, 1, 1, 1, 8, 1, 8, 12, 8, 1, 12, 9, 2, 8, 1, 1, 2, 1, 8, 6, 9, 9, 8, 1, 8, 9, 7, 7, 8, 9, 9, 1, 8, 3, 8, 1, 3, 3, 8, 9, 8, 2, 8, 1, 2, 9, 8, 1, 1, 1, 1, 9, 1, 9, 8, 12, 3, 8, 8, 1, 10, 10, 10, 2, 2, 1, 10, 2, 2, 10, 8, 12, 8, 1, 1, 1, 2, 1, 1, 3, 8, 1, 2, 2, 2, 1, 1, 6, 2, 8, 8, 8, 1, 1, 1, 9, 9, 2, 8, 10, 2, 8, 2, 1, 2, 9, 9, 2, 1, 1, 8, 8, 1, 3, 1, 8, 9, 1, 10, 9, 1, 1, 1, 1, 7, 2, 2, 1, 2, 8, 8, 1, 2, 1, 3, 2, 1, 8, 3, 9, 2, 10, 2, 10, 1, 2, 1, 1, 13, 9, 10, 8, 2, 2, 1, 1, 8, 2, 2, 1, 9, 1, 1, 8, 9, 9, 2, 9, 2, 2, 1, 1, 1, 8, 9, 4, 9, 9, 1, 8, 2, 1, 1, 8, 2, 2, 2, 8, 1, 1, 8, 2, 10, 2, 9, 9, 7, 1, 1, 2, 2, 8, 3, 1, 2, 1, 1, 8, 1, 1, 1, 9, 1, 1, 8, 8, 1, 9, 6, 1, 9, 1, 8, 1, 8, 8, 8, 1, 3, 8, 8, 2, 6, 3, 2, 1, 10, 1, 8, 2, 1, 6, 1, 1, 1, 8, 1, 10, 1, 1, 8, 9, 2, 6, 9, 2, 9, 4, 1, 8, 1, 3, 7, 8, 8, 5, 8, 7, 1, 1, 1, 13, 8, 3, 1, 1, 1, 1, 2, 8, 2, 12, 8, 1, 2, 5, 1, 8, 2, 10, 8, 2, 10, 1, 5, 2, 1, 1, 5, 2, 2, 7, 8, 2, 9, 9, 1, 10, 1, 8, 2, 5, 8, 1, 5, 1, 10, 1, 1, 9, 8, 6, 1, 8, 9, 8, 1, 8, 2, 2, 8, 3, 9, 1, 9, 3, 8, 4, 4, 3, 3, 1, 1, 1, 8, 9, 1, 1, 8, 3, 1, 2, 8, 2, 1, 1, 10, 1, 2, 2, 1, 1, 8, 2, 8, 2, 10, 2, 2, 10, 8, 8, 8, 13, 2, 2, 9, 2, 5, 9, 2, 1, 8, 8, 8, 1, 12, 12, 2, 9, 2, 1, 8, 2, 1, 8, 1, 9, 9, 2, 7, 1, 1, 7, 1, 4, 3, 1, 10, 3, 10, 9, 4, 6, 7, 5, 2, 1, 8, 8, 1, 4, 9, 2, 1, 8, 1, 1, 1, 1, 1, 8, 9, 8, 8, 8, 8, 9, 8, 10, 1, 8, 2, 7, 8, 9, 1, 2, 5, 9, 10, 8, 9, 12, 1, 6, 1, 2, 10, 9, 4, 1, 8, 10, 10, 1, 1, 1, 1, 1, 2, 3, 8, 1, 2, 10, 2, 1, 2, 4, 2, 2, 9, 1, 4, 2, 1, 1, 12, 12, 9, 9, 7, 1, 8, 4, 9, 9, 8, 1, 7, 3, 2, 1, 1, 4, 8, 1, 5, 8, 2, 8, 1, 14, 9, 12, 1, 10, 2, 1, 1, 8, 8, 6, 6, 3, 1, 2, 8, 1, 3, 2, 1, 8, 8, 1, 10, 8, 2, 8, 2, 5, 9, 1, 8, 8, 1, 1, 8, 8, 13, 1, 3, 8, 4, 1, 9, 7, 8, 8, 8, 3, 8, 1, 4, 2, 8, 8, 8, 7, 1, 1, 2, 8, 8, 9, 8, 8, 2, 3, 9, 9, 2, 1, 2, 2, 1, 8, 2, 6, 2, 1, 1, 9, 10, 3, 8, 2, 3, 2, 8, 8, 1, 8, 8, 8, 9, 1, 4, 1, 9, 2, 1, 8, 0, 1, 8, 1, 1, 8, 9, 9, 1, 3, 1, 2, 8, 8, 7, 1, 1, 2, 9, 2, 10, 2, 8, 2, 2, 2, 7, 1, 9, 8, 1, 3, 9, 2, 1, 10, 8, 1, 4, 1, 8, 5, 9, 8, 8, 1, 2, 2, 1, 8, 8, 6, 8, 1, 1, 8, 3, 2, 2, 1, 8, 1, 7, 6, 8, 1, 1, 1, 9, 1, 1, 1, 2, 1, 11, 10, 10, 11, 9]\n",
            "8419\n",
            "Average Length 490.60577265708514\n",
            "Found 8419 texts.\n",
            "Found 15 labels.\n",
            "['8', '1', '8', '2', '8', '8', '8', '9', '7', '8', '1', '2', '1', '1', '8', '4', '8', '8', '12', '3', '3', '7', '3', '12', '1', '8', '8', '8', '8', '8', '8', '8', '1', '9', '5', '9', '9', '9', '11', '8', '8', '8', '4', '8', '8', '8', '8', '1', '3', '9', '3', '7', '1', '2', '9', '9', '7', '8', '8', '1', '10', '7', '8', '8', '9', '8', '7', '9', '9', '12', '7', '2', '8', '1', '11', '11', '1', '7', '7', '12', '1', '9', '8', '10', '12', '7', '8', '2', '8', '9', '9', '1', '8', '9', '1', '7', '12', '10', '10', '10', '8', '3', '7', '9', '8', '9', '1', '8', '8', '2', '7', '2', '9', '9', '11', '8', '8', '12', '12', '7', '8', '12', '4', '9', '3', '1', '12', '1', '1', '8', '8', '3', '8', '8', '8', '8', '9', '1', '8', '8', '10', '1', '8', '2', '8', '8', '7', '3', '8', '2', '4', '4', '9', '8', '10', '12', '12', '1', '1', '9', '1', '1', '1', '8', '2', '2', '8', '1', '1', '2', '2', '1', '2', '8', '1', '9', '9', '8', '8', '4', '2', '9', '9', '8', '3', '4', '3', '1', '8', '8', '2', '1', '9', '7', '8', '8', '1', '12', '3', '8', '2', '4', '2', '9', '12', '1', '4', '1', '8', '8', '8', '2', '2', '8', '9', '8', '8', '8', '10', '9', '8', '7', '9', '1', '1', '9', '4', '2', '4', '2', '2', '1', '7', '8', '11', '11', '3', '9', '2', '4', '8', '9', '1', '8', '1', '1', '4', '9', '1', '1', '8', '8', '2', '1', '8', '4', '2', '8', '9', '8', '8', '2', '8', '8', '8', '7', '1', '1', '1', '2', '1', '1', '8', '7', '8', '8', '12', '2', '12', '12', '8', '10', '12', '8', '3', '3', '12', '10', '1', '8', '12', '1', '8', '8', '2', '8', '4', '7', '8', '7', '10', '8', '10', '9', '8', '12', '12', '1', '8', '8', '3', '8', '8', '8', '8', '8', '1', '9', '8', '11', '1', '1', '1', '9', '8', '1', '9', '2', '3', '11', '8', '9', '9', '9', '2', '1', '8', '8', '9', '7', '1', '4', '9', '4', '8', '8', '4', '8', '12', '9', '4', '8', '2', '10', '10', '10', '8', '9', '9', '8', '8', '12', '7', '1', '8', '8', '8', '4', '1', '1', '1', '1', '1', '1', '8', '1', '9', '8', '9', '9', '4', '8', '12', '9', '8', '8', '2', '8', '8', '8', '6', '9', '8', '3', '7', '8', '8', '4', '12', '8', '8', '9', '12', '12', '9', '8', '2', '9', '2', '3', '1', '12', '8', '10', '9', '9', '9', '10', '10', '3', '8', '12', '1', '4', '2', '1', '10', '8', '2', '8', '4', '8', '9', '1', '9', '9', '10', '10', '1', '4', '9', '2', '4', '9', '1', '1', '3', '10', '3', '3', '8', '7', '3', '8', '9', '9', '12', '4', '8', '12', '2', '2', '4', '1', '9', '9', '4', '1', '4', '2', '8', '12', '2', '3', '10', '10', '9', '8', '9', '9', '1', '12', '8', '8', '8', '12', '4', '1', '8', '8', '1', '9', '8', '8', '2', '1', '8', '9', '8', '3', '3', '3', '1', '8', '8', '9', '1', '10', '9', '9', '9', '9', '5', '9', '9', '8', '8', '8', '8', '8', '8', '8', '8', '11', '12', '8', '8', '1', '8', '9', '11', '2', '2', '2', '2', '3', '1', '2', '2', '8', '2', '4', '9', '1', '2', '9', '8', '2', '8', '9', '9', '3', '10', '9', '9', '2', '8', '9', '8', '12', '12', '1', '3', '8', '8', '8', '2', '7', '7', '7', '7', '3', '9', '1', '9', '8', '9', '9', '1', '1', '1', '2', '9', '9', '9', '11', '1', '8', '8', '9', '1', '9', '8', '8', '8', '1', '1', '8', '7', '1', '1', '8', '8', '9', '4', '4', '8', '2', '2', '8', '8', '8', '8', '8', '8', '11', '8', '2', '9', '4', '9', '3', '9', '9', '1', '3', '9', '3', '1', '12', '8', '9', '12', '1', '8', '4', '2', '1', '4', '8', '3', '3', '8', '2', '8', '9', '7', '8', '8', '8', '5', '8', '3', '9', '8', '8', '13', '12', '1', '1', '2', '8', '4', '1', '9', '9', '12', '8', '9', '12', '9', '1', '9', '9', '9', '9', '3', '2', '9', '9', '4', '8', '12', '2', '4', '9', '3', '1', '9', '7', '8', '9', '9', '8', '4', '8', '8', '7', '9', '10', '3', '8', '8', '8', '1', '1', '1', '1', '8', '8', '4', '1', '10', '1', '5', '7', '7', '1', '8', '9', '3', '7', '2', '7', '7', '2', '4', '8', '12', '7', '4', '2', '9', '9', '12', '6', '10', '8', '2', '4', '12', '9', '9', '3', '8', '8', '1', '2', '10', '9', '9', '8', '4', '12', '2', '1', '8', '8', '8', '12', '10', '10', '9', '3', '8', '8', '9', '2', '8', '10', '1', '1', '1', '1', '2', '1', '1', '1', '1', '9', '8', '12', '9', '4', '8', '8', '9', '1', '9', '3', '9', '8', '8', '1', '7', '7', '10', '1', '8', '8', '1', '9', '8', '10', '3', '1', '7', '1', '8', '8', '12', '8', '8', '1', '8', '7', '1', '7', '7', '8', '2', '1', '8', '8', '2', '10', '8', '8', '8', '8', '8', '10', '1', '8', '8', '12', '8', '3', '3', '2', '2', '2', '10', '8', '8', '8', '2', '9', '1', '8', '9', '3', '2', '8', '10', '8', '6', '1', '1', '8', '4', '1', '9', '10', '8', '1', '7', '1', '2', '8', '1', '1', '1', '12', '1', '9', '12', '8', '12', '12', '12', '8', '8', '12', '4', '8', '8', '8', '8', '9', '9', '1', '3', '3', '3', '3', '1', '12', '12', '9', '10', '8', '8', '1', '9', '2', '2', '13', '9', '8', '9', '2', '1', '9', '1', '8', '8', '8', '4', '8', '1', '1', '1', '12', '12', '7', '2', '2', '2', '8', '3', '8', '9', '2', '10', '7', '8', '9', '2', '1', '2', '12', '12', '8', '8', '9', '2', '2', '9', '11', '1', '8', '1', '10', '9', '2', '1', '4', '7', '7', '7', '7', '7', '12', '8', '8', '8', '1', '1', '10', '1', '12', '1', '8', '2', '1', '1', '12', '8', '7', '9', '12', '8', '9', '3', '9', '8', '8', '8', '8', '3', '11', '2', '2', '9', '8', '8', '10', '8', '2', '7', '3', '1', '4', '7', '8', '8', '1', '8', '3', '7', '12', '8', '10', '9', '9', '8', '8', '2', '8', '9', '9', '1', '2', '8', '8', '9', '8', '3', '8', '1', '8', '10', '9', '8', '9', '9', '12', '4', '4', '8', '9', '9', '8', '2', '10', '1', '2', '8', '9', '1', '9', '9', '9', '7', '12', '12', '8', '1', '1', '1', '1', '8', '3', '1', '1', '8', '1', '8', '8', '7', '8', '8', '8', '8', '3', '2', '2', '10', '10', '10', '7', '8', '1', '2', '12', '7', '9', '8', '7', '8', '12', '2', '8', '9', '2', '6', '6', '7', '9', '8', '1', '8', '9', '8', '1', '12', '1', '2', '8', '7', '7', '7', '8', '2', '2', '8', '1', '2', '2', '9', '9', '1', '8', '8', '4', '3', '3', '1', '6', '3', '3', '12', '3', '8', '9', '1', '4', '3', '1', '8', '3', '9', '2', '8', '2', '8', '8', '8', '1', '1', '1', '9', '9', '8', '1', '9', '8', '1', '1', '3', '10', '8', '1', '1', '3', '9', '1', '4', '4', '1', '8', '9', '9', '2', '0', '0', '1', '8', '3', '1', '8', '8', '9', '8', '8', '1', '1', '8', '9', '8', '8', '8', '7', '9', '8', '8', '8', '10', '9', '8', '1', '2', '6', '1', '9', '9', '8', '12', '12', '12', '8', '8', '2', '8', '1', '2', '2', '2', '1', '9', '8', '2', '12', '2', '8', '12', '8', '9', '8', '8', '9', '7', '1', '1', '1', '1', '1', '8', '8', '1', '8', '8', '1', '1', '3', '2', '8', '8', '9', '10', '10', '2', '2', '1', '9', '2', '9', '9', '4', '12', '12', '12', '10', '7', '3', '3', '4', '2', '2', '9', '2', '8', '4', '2', '4', '1', '10', '9', '7', '8', '7', '1', '1', '3', '3', '1', '1', '3', '3', '3', '1', '1', '1', '1', '8', '2', '3', '1', '1', '2', '8', '8', '12', '8', '8', '8', '8', '11', '9', '1', '8', '9', '2', '8', '8', '8', '3', '9', '1', '9', '2', '7', '2', '8', '2', '8', '10', '8', '1', '10', '1', '1', '9', '9', '8', '8', '1', '8', '8', '8', '12', '8', '8', '8', '1', '8', '8', '8', '1', '9', '1', '1', '8', '1', '8', '9', '8', '2', '12', '9', '9', '0', '1', '8', '8', '1', '8', '12', '8', '8', '10', '8', '8', '8', '7', '8', '1', '8', '7', '3', '10', '1', '8', '9', '1', '8', '8', '8', '10', '1', '10', '3', '9', '1', '8', '9', '2', '8', '3', '3', '9', '9', '7', '9', '1', '1', '9', '2', '1', '1', '1', '7', '1', '1', '8', '8', '1', '1', '8', '1', '8', '3', '12', '9', '3', '3', '8', '8', '8', '8', '3', '1', '3', '3', '1', '11', '0', '8', '8', '7', '8', '12', '1', '8', '9', '8', '9', '8', '8', '3', '8', '8', '1', '1', '1', '9', '2', '2', '2', '8', '7', '12', '8', '8', '9', '10', '10', '7', '8', '1', '9', '8', '7', '3', '1', '3', '8', '2', '2', '3', '9', '8', '4', '4', '8', '9', '2', '1', '1', '7', '8', '9', '9', '7', '8', '7', '7', '8', '2', '2', '8', '4', '9', '7', '10', '0', '9', '8', '3', '7', '8', '1', '1', '8', '9', '9', '2', '2', '10', '1', '9', '10', '10', '10', '8', '3', '2', '12', '9', '9', '10', '12', '9', '12', '12', '9', '1', '2', '4', '12', '12', '7', '8', '9', '7', '7', '7', '3', '9', '8', '9', '1', '12', '8', '9', '4', '1', '3', '12', '12', '12', '12', '8', '8', '2', '1', '1', '2', '1', '1', '1', '12', '12', '8', '12', '2', '2', '12', '3', '3', '12', '8', '2', '8', '8', '12', '2', '1', '10', '3', '2', '8', '7', '1', '8', '1', '3', '7', '8', '9', '8', '3', '1', '1', '7', '8', '8', '9', '8', '2', '9', '2', '2', '9', '8', '1', '8', '8', '1', '3', '3', '1', '1', '10', '1', '2', '8', '1', '1', '1', '1', '9', '1', '4', '1', '7', '7', '7', '7', '2', '2', '8', '8', '12', '1', '9', '1', '7', '3', '3', '1', '8', '8', '10', '8', '9', '2', '9', '1', '3', '8', '8', '3', '12', '2', '8', '12', '2', '9', '1', '3', '3', '3', '3', '2', '8', '7', '9', '8', '3', '3', '1', '7', '8', '3', '1', '1', '12', '8', '9', '1', '2', '3', '8', '1', '1', '3', '3', '9', '1', '1', '1', '12', '1', '7', '3', '3', '1', '8', '8', '8', '1', '2', '4', '8', '1', '10', '2', '5', '3', '3', '12', '10', '9', '9', '12', '9', '0', '2', '8', '8', '9', '9', '9', '8', '1', '3', '1', '1', '4', '8', '1', '10', '8', '7', '2', '8', '2', '8', '4', '7', '8', '1', '9', '1', '9', '8', '2', '8', '2', '7', '9', '2', '2', '9', '1', '8', '12', '1', '8', '1', '4', '1', '9', '9', '1', '10', '12', '4', '8', '1', '7', '3', '9', '2', '12', '7', '8', '8', '2', '1', '12', '9', '8', '1', '2', '2', '8', '10', '2', '1', '7', '7', '7', '12', '3', '3', '8', '3', '8', '8', '3', '9', '8', '9', '1', '1', '8', '7', '9', '3', '3', '8', '1', '0', '9', '9', '9', '1', '8', '9', '9', '10', '1', '8', '7', '8', '8', '8', '9', '9', '8', '9', '10', '4', '9', '3', '7', '12', '1', '9', '9', '8', '9', '1', '9', '3', '1', '8', '4', '12', '10', '9', '8', '7', '10', '8', '12', '12', '3', '10', '8', '12', '2', '1', '2', '3', '9', '8', '8', '7', '1', '1', '2', '2', '1', '2', '2', '7', '1', '3', '9', '9', '3', '8', '8', '8', '8', '8', '7', '8', '8', '10', '8', '1', '8', '2', '8', '2', '2', '2', '2', '2', '1', '7', '12', '10', '1', '2', '8', '1', '4', '7', '8', '1', '12', '8', '7', '9', '2', '2', '2', '8', '1', '8', '1', '1', '0', '2', '2', '6', '1', '8', '2', '1', '8', '1', '1', '2', '2', '3', '2', '2', '10', '10', '9', '1', '7', '7', '8', '8', '1', '12', '10', '12', '3', '8', '8', '8', '3', '8', '3', '10', '2', '2', '2', '1', '2', '2', '1', '0', '1', '8', '9', '1', '1', '1', '2', '2', '2', '2', '2', '1', '1', '1', '1', '12', '9', '9', '1', '10', '11', '12', '9', '1', '1', '8', '8', '1', '2', '12', '8', '3', '7', '2', '10', '9', '7', '8', '1', '2', '2', '7', '9', '12', '2', '2', '1', '8', '9', '2', '3', '2', '2', '2', '9', '9', '8', '9', '2', '3', '8', '8', '9', '7', '3', '10', '8', '8', '9', '1', '1', '2', '8', '1', '10', '8', '8', '9', '7', '1', '7', '12', '8', '1', '7', '2', '1', '3', '9', '2', '8', '8', '1', '2', '3', '9', '3', '8', '9', '7', '7', '1', '10', '2', '8', '8', '8', '1', '8', '2', '8', '8', '1', '2', '8', '10', '2', '1', '0', '8', '3', '8', '10', '10', '12', '3', '8', '9', '3', '10', '8', '8', '8', '1', '8', '8', '2', '2', '2', '2', '2', '2', '1', '1', '10', '1', '10', '8', '2', '1', '2', '2', '8', '3', '3', '2', '2', '1', '8', '1', '3', '1', '9', '2', '2', '1', '3', '2', '2', '3', '2', '2', '3', '2', '1', '1', '2', '1', '2', '7', '8', '2', '1', '12', '12', '3', '1', '9', '9', '7', '8', '7', '2', '7', '9', '2', '2', '2', '8', '9', '7', '9', '2', '8', '9', '9', '2', '9', '1', '1', '9', '8', '3', '3', '8', '2', '7', '8', '11', '2', '8', '9', '1', '8', '3', '1', '2', '1', '2', '2', '2', '2', '8', '3', '9', '2', '10', '9', '9', '2', '7', '7', '7', '1', '3', '8', '8', '1', '1', '8', '7', '1', '8', '8', '9', '3', '3', '3', '2', '4', '8', '12', '8', '1', '12', '9', '2', '8', '2', '12', '2', '1', '3', '8', '12', '12', '11', '8', '10', '9', '2', '9', '4', '10', '1', '12', '12', '9', '3', '8', '9', '12', '9', '9', '2', '2', '2', '3', '5', '1', '1', '1', '7', '7', '8', '2', '2', '8', '2', '1', '7', '3', '2', '9', '8', '9', '1', '1', '9', '8', '9', '3', '3', '2', '9', '4', '9', '8', '8', '1', '8', '10', '2', '0', '3', '8', '8', '8', '9', '12', '9', '8', '2', '2', '8', '10', '9', '8', '2', '2', '4', '1', '9', '9', '8', '8', '10', '3', '1', '1', '2', '8', '7', '8', '2', '1', '1', '8', '12', '2', '9', '4', '8', '3', '3', '3', '8', '2', '12', '12', '8', '9', '12', '8', '2', '12', '7', '9', '2', '2', '1', '3', '1', '3', '11', '9', '8', '1', '10', '2', '12', '3', '8', '4', '1', '2', '8', '8', '3', '9', '3', '8', '7', '1', '1', '3', '1', '8', '2', '9', '8', '12', '1', '1', '1', '9', '9', '1', '8', '8', '8', '2', '2', '12', '3', '1', '1', '1', '9', '9', '3', '2', '1', '1', '9', '9', '1', '9', '9', '1', '9', '3', '9', '1', '8', '1', '9', '8', '3', '8', '8', '9', '9', '8', '2', '8', '1', '2', '2', '10', '1', '2', '1', '1', '9', '1', '9', '3', '7', '7', '2', '10', '3', '3', '1', '1', '9', '1', '2', '1', '3', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '8', '8', '7', '1', '1', '8', '8', '2', '1', '12', '1', '8', '1', '9', '8', '8', '2', '1', '9', '9', '2', '2', '8', '1', '7', '7', '9', '8', '1', '6', '8', '8', '2', '2', '8', '3', '8', '3', '2', '3', '8', '1', '2', '2', '2', '8', '9', '9', '9', '12', '1', '9', '2', '1', '9', '2', '9', '9', '10', '8', '1', '1', '9', '2', '1', '7', '1', '3', '7', '1', '1', '1', '3', '8', '8', '8', '9', '9', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '1', '0', '1', '1', '1', '2', '2', '3', '1', '1', '2', '3', '3', '3', '7', '3', '1', '9', '3', '9', '1', '4', '1', '1', '9', '10', '9', '8', '2', '3', '10', '9', '3', '10', '12', '8', '9', '8', '2', '1', '9', '8', '1', '7', '8', '1', '9', '1', '2', '10', '7', '7', '8', '1', '3', '3', '9', '3', '3', '1', '1', '1', '9', '1', '3', '8', '8', '8', '1', '8', '1', '9', '7', '8', '8', '2', '1', '3', '8', '2', '1', '6', '1', '8', '8', '2', '8', '2', '2', '9', '8', '1', '1', '6', '8', '6', '10', '2', '1', '1', '8', '9', '3', '3', '3', '1', '3', '9', '6', '8', '1', '8', '3', '1', '2', '2', '12', '7', '1', '1', '1', '1', '12', '1', '8', '8', '3', '2', '1', '9', '2', '3', '3', '2', '2', '7', '2', '2', '2', '3', '1', '9', '8', '7', '1', '1', '3', '1', '9', '4', '3', '9', '2', '1', '1', '9', '8', '8', '7', '2', '1', '3', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '10', '1', '1', '8', '2', '8', '1', '8', '1', '3', '1', '2', '1', '1', '3', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '8', '1', '9', '8', '8', '1', '10', '8', '8', '1', '3', '9', '8', '9', '8', '2', '1', '3', '4', '1', '12', '1', '9', '8', '2', '7', '2', '1', '2', '9', '2', '1', '3', '8', '1', '2', '3', '8', '2', '10', '10', '10', '9', '9', '9', '3', '8', '3', '1', '1', '1', '1', '1', '1', '2', '1', '9', '2', '7', '9', '8', '7', '9', '1', '1', '1', '1', '8', '2', '2', '3', '3', '2', '12', '8', '3', '1', '1', '12', '9', '8', '2', '2', '9', '1', '2', '2', '9', '1', '1', '2', '4', '8', '1', '8', '10', '2', '9', '9', '9', '1', '2', '1', '1', '2', '2', '2', '12', '1', '2', '8', '3', '9', '9', '3', '2', '9', '9', '7', '2', '8', '8', '9', '2', '9', '1', '1', '1', '1', '1', '2', '8', '2', '1', '2', '2', '8', '3', '1', '1', '9', '1', '3', '10', '7', '9', '8', '8', '2', '2', '9', '2', '2', '2', '2', '2', '2', '9', '1', '3', '6', '4', '2', '2', '9', '1', '9', '8', '1', '1', '1', '7', '3', '2', '9', '9', '1', '9', '7', '2', '8', '9', '9', '12', '10', '8', '10', '2', '3', '1', '2', '2', '12', '12', '3', '12', '1', '2', '1', '2', '1', '2', '8', '2', '3', '12', '12', '8', '2', '2', '9', '2', '9', '2', '3', '3', '1', '1', '1', '12', '3', '7', '1', '3', '1', '2', '9', '2', '7', '2', '1', '8', '3', '7', '8', '1', '1', '3', '8', '3', '2', '9', '3', '1', '1', '1', '1', '11', '1', '2', '6', '1', '2', '3', '8', '9', '9', '2', '9', '2', '1', '1', '3', '1', '12', '9', '1', '1', '9', '1', '9', '9', '8', '9', '8', '1', '2', '7', '1', '0', '9', '8', '2', '3', '2', '4', '1', '1', '1', '8', '1', '12', '1', '2', '3', '3', '9', '9', '9', '9', '9', '7', '9', '3', '9', '1', '7', '3', '3', '3', '3', '7', '8', '2', '2', '2', '8', '2', '3', '9', '9', '3', '1', '8', '9', '12', '8', '8', '3', '2', '1', '6', '1', '9', '1', '1', '1', '1', '1', '1', '2', '2', '1', '2', '2', '2', '2', '9', '2', '5', '3', '2', '2', '8', '2', '1', '8', '3', '3', '8', '3', '1', '3', '9', '2', '8', '9', '4', '4', '9', '8', '8', '7', '7', '3', '1', '8', '8', '3', '2', '2', '10', '3', '3', '2', '2', '2', '2', '12', '3', '1', '2', '7', '7', '12', '2', '1', '2', '1', '1', '2', '1', '3', '3', '3', '1', '3', '9', '4', '8', '8', '4', '2', '4', '2', '8', '9', '1', '1', '2', '2', '2', '8', '7', '2', '8', '2', '9', '1', '8', '1', '1', '2', '1', '1', '1', '2', '9', '9', '8', '1', '8', '1', '4', '8', '1', '2', '7', '9', '2', '1', '8', '9', '8', '9', '1', '1', '2', '3', '2', '12', '7', '1', '2', '4', '4', '4', '2', '2', '2', '9', '8', '8', '1', '12', '3', '3', '2', '2', '3', '12', '1', '5', '1', '1', '3', '2', '8', '8', '2', '2', '2', '3', '9', '8', '8', '9', '8', '8', '11', '8', '2', '9', '2', '3', '1', '7', '1', '8', '2', '8', '1', '1', '1', '8', '1', '1', '1', '7', '8', '8', '2', '3', '2', '1', '8', '8', '1', '8', '4', '8', '9', '8', '9', '8', '1', '2', '3', '2', '1', '2', '2', '3', '1', '9', '4', '8', '1', '1', '9', '1', '1', '8', '2', '2', '2', '1', '7', '3', '3', '1', '3', '3', '12', '3', '1', '1', '3', '1', '1', '4', '8', '4', '4', '3', '3', '3', '4', '8', '1', '9', '9', '9', '4', '1', '7', '4', '8', '4', '9', '8', '1', '1', '3', '8', '9', '1', '9', '7', '1', '1', '9', '1', '8', '8', '8', '1', '1', '8', '2', '2', '2', '9', '4', '4', '1', '2', '1', '2', '9', '1', '1', '8', '5', '5', '5', '9', '12', '4', '1', '2', '1', '8', '8', '1', '9', '9', '2', '12', '1', '1', '7', '8', '8', '4', '1', '2', '8', '11', '2', '3', '2', '2', '1', '11', '2', '2', '2', '2', '9', '9', '2', '2', '9', '3', '1', '9', '1', '1', '1', '7', '8', '1', '8', '9', '1', '2', '9', '8', '1', '2', '9', '8', '12', '2', '2', '10', '8', '2', '2', '8', '8', '1', '2', '6', '1', '1', '7', '7', '2', '3', '2', '1', '1', '8', '1', '10', '8', '12', '6', '4', '1', '4', '1', '2', '9', '8', '9', '4', '8', '8', '10', '8', '8', '8', '8', '8', '2', '2', '8', '4', '9', '3', '3', '3', '3', '3', '9', '2', '1', '1', '2', '3', '2', '1', '2', '3', '3', '3', '2', '2', '3', '3', '2', '1', '2', '3', '3', '3', '3', '12', '9', '3', '2', '2', '3', '1', '5', '1', '1', '3', '2', '2', '1', '2', '9', '3', '9', '8', '1', '8', '7', '7', '9', '1', '1', '7', '9', '10', '1', '7', '1', '4', '3', '8', '9', '4', '9', '9', '2', '9', '2', '8', '4', '2', '2', '9', '5', '2', '1', '10', '9', '3', '1', '1', '1', '2', '1', '2', '9', '1', '7', '9', '9', '8', '2', '2', '8', '9', '1', '9', '8', '2', '3', '2', '2', '1', '2', '2', '2', '1', '1', '8', '1', '9', '4', '12', '8', '2', '7', '2', '2', '1', '9', '3', '1', '8', '12', '1', '1', '2', '1', '10', '2', '6', '12', '12', '4', '9', '1', '9', '10', '1', '2', '8', '2', '1', '8', '6', '12', '9', '9', '2', '1', '7', '8', '9', '5', '8', '1', '8', '8', '3', '1', '8', '2', '8', '2', '2', '1', '2', '9', '2', '8', '1', '12', '8', '2', '7', '3', '3', '12', '2', '3', '3', '9', '9', '3', '3', '3', '3', '3', '2', '1', '4', '1', '4', '8', '8', '2', '1', '2', '9', '12', '1', '10', '12', '1', '2', '9', '4', '8', '10', '3', '2', '8', '7', '4', '8', '9', '2', '7', '1', '10', '2', '2', '2', '8', '4', '2', '2', '1', '1', '8', '7', '9', '2', '1', '9', '8', '9', '12', '4', '8', '2', '8', '7', '7', '1', '9', '2', '1', '1', '9', '1', '8', '2', '3', '9', '9', '1', '3', '2', '9', '2', '2', '8', '1', '1', '2', '1', '2', '1', '9', '8', '2', '2', '4', '8', '8', '9', '5', '5', '9', '8', '9', '6', '2', '1', '12', '2', '3', '8', '8', '9', '2', '2', '1', '3', '2', '10', '9', '10', '7', '2', '8', '4', '2', '8', '9', '8', '1', '3', '8', '8', '1', '8', '3', '8', '8', '1', '10', '3', '1', '5', '8', '8', '9', '2', '2', '9', '2', '1', '9', '1', '4', '1', '12', '8', '8', '2', '1', '1', '1', '1', '1', '9', '2', '9', '8', '9', '5', '9', '1', '8', '2', '4', '1', '1', '1', '9', '12', '4', '1', '1', '9', '8', '4', '1', '8', '9', '8', '8', '9', '9', '9', '9', '9', '9', '1', '3', '4', '2', '2', '8', '2', '9', '2', '3', '8', '3', '1', '7', '2', '1', '1', '4', '2', '9', '2', '1', '3', '2', '9', '2', '9', '3', '8', '1', '9', '1', '1', '2', '8', '8', '8', '2', '3', '9', '9', '8', '2', '4', '1', '5', '1', '1', '9', '9', '2', '1', '1', '1', '9', '9', '1', '3', '9', '2', '2', '9', '9', '8', '3', '9', '9', '8', '2', '2', '8', '9', '2', '2', '8', '9', '10', '10', '2', '8', '7', '9', '9', '4', '2', '4', '11', '2', '1', '7', '8', '8', '8', '9', '4', '9', '8', '8', '2', '1', '1', '9', '8', '3', '3', '8', '8', '7', '9', '1', '3', '4', '8', '10', '2', '4', '4', '8', '2', '8', '2', '8', '9', '2', '1', '2', '2', '3', '1', '9', '4', '5', '9', '9', '1', '1', '1', '1', '1', '1', '7', '1', '1', '1', '8', '1', '1', '1', '1', '1', '9', '1', '2', '1', '12', '9', '3', '9', '9', '4', '1', '9', '1', '1', '2', '11', '9', '3', '2', '2', '2', '4', '2', '3', '2', '7', '7', '8', '1', '10', '9', '5', '7', '1', '10', '8', '1', '2', '7', '1', '12', '5', '8', '4', '2', '9', '9', '8', '2', '9', '8', '8', '10', '2', '3', '2', '7', '2', '8', '10', '3', '2', '9', '9', '9', '1', '1', '1', '1', '8', '2', '10', '9', '8', '1', '2', '2', '2', '1', '2', '1', '3', '9', '12', '2', '2', '4', '8', '1', '3', '9', '4', '9', '1', '9', '9', '2', '1', '1', '9', '7', '10', '3', '10', '2', '9', '2', '9', '2', '8', '2', '1', '2', '3', '1', '1', '1', '8', '5', '8', '3', '1', '1', '4', '2', '2', '1', '3', '8', '2', '1', '1', '1', '2', '9', '4', '1', '8', '1', '2', '8', '2', '9', '2', '2', '5', '5', '2', '5', '2', '1', '8', '8', '1', '3', '12', '2', '4', '3', '2', '2', '2', '6', '2', '3', '3', '1', '8', '2', '2', '1', '1', '8', '8', '10', '1', '9', '2', '9', '12', '0', '2', '1', '3', '2', '2', '1', '2', '1', '9', '9', '2', '9', '8', '8', '1', '7', '8', '1', '2', '6', '9', '8', '10', '1', '12', '2', '2', '1', '8', '2', '1', '12', '7', '4', '2', '10', '2', '2', '1', '2', '1', '2', '1', '1', '2', '1', '9', '8', '10', '2', '10', '9', '9', '12', '5', '3', '2', '8', '2', '8', '3', '3', '1', '4', '9', '10', '2', '4', '8', '1', '2', '10', '12', '12', '3', '1', '1', '2', '9', '6', '6', '1', '9', '1', '8', '1', '8', '8', '8', '8', '2', '2', '2', '8', '8', '2', '1', '1', '1', '1', '1', '8', '8', '5', '8', '8', '1', '8', '9', '9', '1', '7', '12', '9', '9', '7', '2', '2', '7', '8', '9', '8', '2', '9', '6', '3', '4', '8', '4', '1', '2', '9', '8', '8', '8', '2', '1', '1', '8', '8', '3', '1', '9', '9', '7', '1', '2', '2', '2', '9', '4', '1', '2', '12', '1', '8', '2', '1', '9', '1', '8', '9', '9', '2', '5', '4', '2', '1', '2', '8', '12', '8', '10', '3', '8', '8', '8', '2', '2', '8', '2', '8', '2', '4', '8', '10', '2', '7', '2', '1', '8', '8', '9', '5', '8', '1', '12', '7', '10', '2', '2', '2', '1', '4', '8', '12', '1', '8', '2', '2', '9', '1', '8', '3', '1', '1', '5', '10', '2', '1', '2', '4', '8', '9', '3', '2', '8', '7', '4', '4', '9', '9', '2', '8', '1', '1', '2', '4', '7', '1', '9', '1', '1', '1', '8', '4', '1', '3', '1', '2', '2', '9', '1', '8', '8', '2', '2', '9', '9', '1', '8', '8', '1', '9', '8', '8', '2', '2', '2', '2', '1', '1', '1', '7', '4', '1', '1', '4', '2', '3', '3', '2', '3', '9', '2', '8', '2', '1', '5', '1', '2', '2', '1', '3', '5', '2', '9', '1', '1', '9', '8', '1', '4', '8', '1', '8', '2', '4', '8', '4', '7', '9', '8', '1', '2', '2', '4', '4', '11', '3', '11', '1', '3', '8', '1', '9', '6', '8', '9', '3', '9', '8', '9', '2', '3', '3', '7', '1', '7', '2', '9', '9', '1', '8', '8', '1', '5', '5', '8', '8', '1', '2', '1', '3', '9', '9', '5', '9', '8', '1', '4', '3', '8', '1', '1', '2', '1', '8', '9', '8', '2', '2', '2', '1', '2', '4', '10', '8', '1', '9', '1', '8', '1', '1', '9', '9', '8', '11', '1', '8', '2', '1', '2', '8', '2', '8', '8', '2', '9', '6', '10', '1', '8', '6', '4', '5', '11', '2', '2', '8', '1', '8', '1', '8', '1', '4', '8', '1', '1', '1', '8', '3', '7', '3', '3', '7', '1', '1', '4', '8', '1', '6', '4', '2', '2', '1', '1', '1', '1', '6', '2', '2', '8', '1', '8', '5', '5', '2', '1', '1', '2', '3', '7', '1', '1', '6', '2', '9', '3', '9', '8', '9', '2', '1', '4', '2', '9', '13', '9', '2', '8', '12', '4', '1', '1', '9', '5', '1', '1', '1', '1', '8', '2', '1', '1', '2', '9', '0', '12', '1', '1', '8', '9', '8', '3', '2', '2', '12', '8', '2', '2', '2', '1', '10', '1', '9', '8', '9', '5', '2', '2', '9', '2', '8', '4', '8', '3', '7', '9', '2', '2', '7', '2', '2', '8', '1', '1', '9', '10', '9', '8', '2', '9', '0', '7', '1', '1', '1', '9', '8', '2', '8', '12', '8', '3', '2', '8', '8', '7', '7', '8', '12', '2', '1', '3', '9', '2', '2', '8', '2', '8', '8', '12', '8', '8', '1', '8', '9', '2', '4', '4', '7', '2', '1', '1', '9', '3', '7', '1', '3', '9', '8', '2', '2', '3', '1', '3', '10', '2', '3', '7', '1', '8', '1', '1', '10', '3', '10', '8', '4', '1', '2', '4', '3', '10', '9', '3', '9', '5', '8', '7', '2', '9', '3', '3', '2', '11', '8', '1', '1', '7', '2', '7', '2', '9', '4', '8', '1', '12', '8', '7', '9', '1', '0', '2', '6', '4', '9', '3', '2', '4', '12', '9', '8', '5', '9', '2', '8', '4', '6', '8', '9', '3', '1', '8', '7', '3', '1', '1', '1', '8', '9', '1', '8', '7', '9', '8', '2', '1', '2', '2', '3', '2', '2', '1', '1', '4', '9', '7', '3', '2', '8', '8', '9', '1', '9', '7', '4', '2', '2', '8', '5', '9', '1', '5', '7', '1', '4', '6', '9', '10', '1', '8', '2', '9', '1', '9', '2', '9', '8', '2', '9', '9', '11', '2', '12', '2', '2', '9', '4', '8', '1', '9', '9', '2', '8', '9', '1', '2', '9', '3', '8', '8', '1', '7', '8', '8', '2', '3', '2', '2', '2', '2', '9', '8', '10', '2', '2', '1', '9', '11', '1', '8', '8', '2', '4', '2', '1', '2', '8', '8', '9', '2', '8', '9', '2', '3', '1', '2', '1', '3', '10', '8', '1', '2', '4', '1', '9', '8', '9', '3', '3', '9', '8', '2', '11', '3', '7', '1', '8', '7', '1', '8', '8', '8', '1', '4', '8', '8', '1', '9', '3', '1', '1', '2', '8', '8', '8', '2', '1', '8', '10', '2', '12', '8', '8', '9', '1', '8', '1', '3', '2', '2', '10', '7', '2', '2', '1', '1', '8', '2', '9', '1', '2', '9', '3', '3', '10', '1', '4', '7', '10', '12', '2', '4', '10', '8', '6', '2', '9', '1', '8', '3', '1', '2', '8', '8', '2', '12', '10', '2', '10', '9', '1', '2', '5', '8', '12', '8', '8', '7', '8', '8', '1', '8', '2', '2', '9', '1', '8', '10', '5', '5', '5', '8', '1', '9', '1', '13', '1', '2', '2', '1', '2', '4', '9', '2', '1', '9', '13', '11', '1', '9', '9', '3', '10', '8', '7', '8', '8', '4', '2', '1', '9', '4', '3', '1', '1', '10', '9', '2', '8', '6', '2', '1', '1', '3', '2', '8', '1', '1', '1', '1', '2', '4', '1', '1', '10', '1', '8', '1', '1', '9', '1', '7', '1', '1', '9', '9', '2', '12', '9', '1', '8', '1', '12', '1', '8', '3', '8', '1', '8', '1', '2', '10', '1', '1', '2', '2', '9', '3', '9', '12', '1', '9', '1', '2', '8', '7', '2', '1', '1', '3', '2', '8', '4', '4', '5', '12', '7', '8', '9', '6', '1', '8', '9', '2', '1', '9', '1', '4', '1', '8', '2', '1', '1', '8', '7', '4', '9', '1', '8', '4', '2', '7', '5', '1', '3', '9', '2', '8', '2', '1', '2', '9', '1', '1', '2', '3', '4', '3', '1', '2', '2', '10', '2', '2', '8', '1', '1', '2', '4', '9', '2', '11', '9', '8', '9', '2', '1', '10', '4', '1', '1', '10', '7', '2', '10', '8', '1', '10', '8', '8', '8', '8', '8', '8', '2', '2', '2', '8', '3', '4', '1', '1', '1', '2', '1', '8', '8', '2', '8', '3', '8', '3', '1', '2', '3', '1', '1', '10', '1', '4', '4', '3', '3', '1', '9', '1', '1', '2', '1', '1', '6', '1', '1', '1', '9', '1', '4', '1', '1', '1', '1', '1', '1', '2', '12', '8', '8', '1', '9', '12', '10', '8', '2', '12', '1', '1', '2', '1', '7', '10', '7', '1', '2', '1', '10', '8', '2', '2', '8', '2', '2', '1', '9', '8', '8', '8', '8', '3', '1', '4', '2', '8', '3', '10', '10', '1', '9', '1', '9', '1', '9', '1', '8', '3', '1', '1', '8', '8', '8', '6', '3', '4', '1', '1', '1', '9', '9', '5', '2', '10', '2', '6', '2', '2', '7', '1', '8', '2', '11', '1', '1', '1', '2', '1', '9', '4', '4', '2', '8', '4', '6', '8', '8', '10', '10', '2', '1', '2', '9', '1', '8', '8', '3', '4', '8', '8', '2', '8', '8', '1', '2', '1', '2', '9', '4', '1', '3', '3', '3', '8', '8', '8', '2', '6', '4', '3', '3', '12', '3', '4', '9', '6', '8', '7', '7', '8', '6', '4', '1', '10', '6', '3', '3', '8', '1', '1', '8', '1', '11', '8', '1', '1', '2', '3', '11', '7', '2', '1', '1', '1', '9', '1', '2', '1', '1', '9', '8', '1', '1', '8', '0', '4', '1', '1', '2', '1', '1', '2', '2', '9', '1', '10', '1', '3', '8', '9', '3', '3', '1', '10', '1', '9', '1', '1', '7', '4', '1', '8', '10', '1', '2', '10', '1', '1', '2', '3', '3', '9', '1', '8', '10', '1', '7', '9', '1', '9', '6', '3', '9', '2', '8', '4', '12', '12', '3', '1', '1', '9', '1', '9', '2', '1', '1', '1', '1', '1', '9', '2', '1', '2', '10', '9', '8', '8', '10', '8', '2', '3', '2', '1', '12', '8', '12', '2', '9', '1', '3', '2', '5', '2', '2', '8', '2', '2', '4', '10', '9', '10', '9', '4', '2', '4', '12', '8', '2', '1', '8', '3', '9', '2', '9', '4', '1', '1', '1', '1', '1', '9', '6', '2', '9', '2', '1', '3', '2', '2', '5', '8', '9', '1', '6', '3', '1', '2', '2', '2', '6', '1', '8', '10', '8', '3', '3', '13', '2', '9', '9', '10', '6', '12', '8', '2', '9', '2', '3', '8', '8', '1', '2', '2', '3', '2', '10', '1', '8', '9', '1', '8', '9', '8', '8', '2', '10', '2', '1', '1', '1', '9', '9', '12', '1', '1', '4', '8', '3', '2', '2', '4', '4', '2', '2', '1', '1', '1', '9', '2', '2', '4', '1', '1', '8', '8', '8', '9', '2', '13', '9', '9', '4', '1', '9', '7', '10', '10', '8', '1', '9', '1', '1', '1', '8', '12', '4', '1', '2', '1', '1', '1', '7', '8', '3', '3', '1', '2', '2', '7', '2', '2', '10', '1', '8', '4', '0', '1', '9', '4', '1', '1', '2', '10', '10', '7', '9', '3', '12', '11', '2', '8', '10', '8', '9', '4', '3', '4', '10', '1', '1', '9', '3', '10', '1', '5', '3', '3', '2', '2', '1', '1', '6', '1', '7', '1', '1', '12', '1', '1', '1', '10', '1', '8', '8', '1', '3', '8', '3', '1', '2', '8', '3', '4', '2', '8', '8', '6', '1', '1', '4', '1', '2', '9', '5', '1', '7', '8', '9', '2', '4', '9', '8', '5', '9', '9', '9', '1', '2', '1', '3', '8', '9', '2', '9', '8', '9', '1', '8', '13', '9', '3', '8', '1', '4', '1', '3', '1', '6', '4', '10', '2', '2', '7', '8', '8', '12', '8', '9', '9', '9', '10', '3', '12', '12', '2', '9', '10', '9', '7', '2', '3', '4', '10', '10', '2', '7', '7', '1', '7', '3', '9', '1', '9', '8', '2', '9', '1', '8', '1', '10', '8', '8', '2', '7', '8', '1', '8', '9', '8', '1', '4', '1', '8', '8', '8', '1', '1', '10', '3', '2', '2', '6', '8', '9', '8', '2', '1', '1', '3', '8', '8', '1', '4', '4', '3', '9', '10', '4', '2', '4', '2', '9', '2', '2', '9', '1', '1', '10', '1', '1', '2', '1', '1', '1', '9', '1', '8', '8', '8', '2', '3', '8', '1', '6', '7', '3', '1', '9', '1', '2', '1', '6', '1', '2', '10', '1', '4', '2', '3', '2', '9', '9', '4', '9', '9', '1', '2', '8', '4', '7', '8', '7', '13', '9', '1', '2', '1', '9', '3', '3', '6', '8', '9', '10', '9', '2', '2', '3', '12', '1', '1', '1', '13', '2', '1', '7', '10', '8', '9', '1', '2', '9', '1', '1', '1', '2', '1', '12', '5', '6', '9', '10', '3', '1', '10', '1', '3', '2', '8', '9', '2', '10', '8', '8', '9', '2', '8', '9', '2', '2', '2', '8', '8', '2', '3', '1', '4', '8', '1', '9', '9', '2', '8', '10', '9', '1', '2', '12', '8', '8', '0', '2', '1', '1', '9', '10', '1', '6', '2', '2', '10', '2', '2', '4', '2', '2', '12', '1', '6', '7', '8', '9', '1', '3', '5', '7', '3', '1', '3', '1', '1', '3', '2', '6', '3', '2', '1', '8', '3', '5', '2', '1', '1', '8', '1', '1', '0', '2', '3', '5', '3', '1', '1', '9', '8', '8', '8', '8', '4', '7', '2', '9', '12', '5', '9', '3', '12', '3', '9', '1', '9', '1', '7', '3', '9', '3', '10', '1', '2', '1', '4', '9', '8', '2', '9', '11', '2', '8', '9', '4', '1', '1', '1', '1', '1', '1', '1', '9', '1', '9', '1', '1', '1', '12', '3', '10', '3', '6', '1', '7', '10', '8', '3', '7', '1', '1', '2', '6', '1', '3', '9', '2', '8', '1', '8', '8', '1', '8', '10', '12', '1', '10', '12', '10', '1', '8', '8', '1', '4', '7', '9', '2', '1', '9', '3', '8', '12', '10', '6', '1', '6', '8', '3', '1', '3', '1', '10', '10', '9', '8', '1', '2', '9', '8', '8', '1', '9', '8', '8', '3', '1', '3', '9', '12', '1', '8', '1', '5', '8', '11', '5', '5', '1', '2', '1', '3', '1', '1', '1', '9', '8', '8', '1', '9', '10', '8', '4', '1', '1', '8', '10', '8', '9', '1', '10', '1', '7', '2', '1', '1', '9', '6', '2', '9', '8', '1', '1', '1', '9', '8', '8', '1', '9', '9', '1', '1', '2', '7', '9', '2', '9', '9', '8', '7', '6', '8', '7', '8', '2', '9', '2', '1', '8', '8', '8', '2', '6', '3', '1', '8', '12', '12', '8', '7', '1', '2', '2', '7', '1', '9', '8', '1', '4', '1', '1', '8', '5', '8', '1', '8', '8', '8', '8', '1', '2', '11', '1', '1', '1', '2', '7', '1', '9', '2', '2', '2', '9', '8', '9', '2', '9', '1', '8', '1', '7', '11', '13', '1', '9', '8', '2', '2', '1', '2', '3', '10', '3', '10', '4', '3', '9', '1', '8', '1', '1', '13', '1', '1', '3', '8', '1', '2', '2', '2', '9', '4', '1', '8', '1', '9', '3', '6', '8', '5', '2', '8', '2', '8', '1', '9', '2', '2', '8', '1', '1', '4', '8', '9', '2', '2', '7', '1', '8', '12', '2', '12', '8', '2', '9', '9', '3', '8', '1', '1', '9', '9', '9', '2', '8', '1', '9', '1', '8', '9', '8', '2', '2', '4', '1', '9', '10', '10', '8', '8', '1', '1', '2', '1', '4', '1', '2', '1', '1', '3', '12', '8', '8', '8', '8', '10', '2', '8', '12', '1', '9', '9', '8', '9', '1', '2', '1', '8', '8', '8', '2', '8', '8', '3', '10', '8', '9', '1', '1', '1', '3', '4', '8', '10', '6', '3', '1', '3', '2', '8', '9', '3', '5', '4', '1', '5', '2', '9', '9', '9', '1', '1', '1', '9', '9', '6', '10', '9', '8', '12', '2', '9', '1', '2', '1', '1', '1', '8', '1', '12', '1', '12', '1', '9', '1', '8', '1', '2', '1', '2', '8', '8', '10', '1', '9', '1', '2', '2', '8', '8', '3', '12', '1', '11', '2', '10', '12', '11', '2', '1', '10', '1', '1', '9', '3', '10', '2', '7', '1', '8', '1', '9', '9', '2', '1', '3', '12', '5', '9', '9', '8', '1', '8', '8', '8', '1', '1', '3', '9', '8', '9', '8', '3', '10', '3', '7', '8', '9', '2', '3', '1', '9', '10', '9', '2', '8', '2', '6', '4', '1', '1', '3', '8', '2', '3', '9', '1', '2', '1', '8', '1', '2', '2', '2', '2', '9', '9', '4', '8', '9', '1', '1', '2', '9', '1', '5', '2', '9', '8', '10', '1', '2', '10', '8', '5', '6', '4', '8', '1', '1', '1', '8', '9', '2', '8', '8', '8', '12', '2', '2', '1', '8', '1', '2', '1', '9', '8', '8', '9', '1', '1', '8', '7', '1', '8', '0', '2', '3', '8', '1', '1', '8', '1', '1', '12', '3', '2', '10', '8', '10', '6', '1', '8', '8', '10', '8', '8', '1', '4', '8', '1', '2', '9', '8', '1', '1', '3', '3', '5', '1', '1', '2', '1', '2', '1', '9', '8', '3', '9', '8', '2', '10', '9', '1', '8', '1', '10', '9', '10', '1', '2', '3', '8', '1', '3', '1', '9', '9', '8', '1', '9', '8', '8', '9', '1', '9', '2', '8', '8', '2', '13', '8', '10', '8', '9', '3', '2', '1', '3', '1', '12', '10', '10', '1', '11', '1', '2', '4', '2', '10', '1', '8', '11', '1', '1', '1', '2', '2', '8', '2', '9', '8', '9', '9', '12', '8', '1', '9', '2', '4', '1', '8', '3', '9', '1', '6', '5', '8', '9', '3', '3', '2', '1', '1', '1', '8', '11', '1', '8', '7', '1', '11', '9', '1', '7', '9', '9', '8', '8', '8', '12', '8', '1', '2', '9', '8', '8', '2', '10', '9', '8', '8', '4', '10', '9', '8', '2', '10', '10', '2', '1', '2', '1', '2', '1', '4', '1', '7', '1', '1', '3', '12', '9', '8', '5', '9', '10', '1', '9', '9', '2', '7', '4', '1', '1', '8', '12', '8', '2', '2', '9', '4', '1', '1', '5', '9', '1', '8', '12', '8', '1', '1', '4', '9', '10', '2', '3', '1', '3', '3', '3', '8', '1', '2', '1', '2', '1', '2', '9', '1', '2', '8', '9', '4', '8', '8', '10', '2', '12', '5', '5', '1', '8', '1', '7', '8', '1', '1', '8', '9', '12', '4', '9', '3', '1', '2', '5', '9', '2', '1', '2', '2', '1', '2', '8', '1', '8', '8', '2', '2', '1', '8', '4', '1', '2', '10', '9', '10', '8', '1', '10', '4', '8', '8', '10', '2', '8', '1', '1', '3', '10', '1', '4', '2', '8', '3', '3', '2', '9', '8', '5', '5', '9', '3', '10', '8', '1', '2', '1', '2', '9', '1', '1', '2', '9', '9', '8', '8', '11', '9', '4', '1', '8', '2', '7', '1', '2', '8', '2', '9', '9', '8', '2', '9', '9', '8', '8', '1', '2', '8', '1', '1', '2', '9', '8', '1', '4', '9', '1', '8', '12', '1', '12', '2', '8', '2', '9', '1', '12', '1', '2', '9', '1', '1', '9', '3', '2', '9', '9', '2', '11', '8', '7', '9', '9', '9', '8', '8', '1', '2', '8', '1', '1', '4', '1', '2', '10', '1', '9', '2', '1', '1', '1', '9', '1', '13', '4', '3', '2', '1', '1', '2', '2', '7', '8', '7', '1', '1', '2', '8', '8', '3', '4', '8', '2', '10', '13', '8', '8', '9', '2', '2', '1', '1', '10', '4', '2', '7', '9', '8', '2', '1', '9', '8', '1', '1', '9', '8', '9', '8', '2', '8', '2', '2', '9', '2', '1', '9', '1', '2', '4', '8', '2', '1', '1', '8', '1', '4', '1', '9', '3', '9', '2', '7', '1', '9', '6', '1', '10', '2', '2', '2', '2', '2', '10', '10', '10', '9', '9', '9', '3', '12', '10', '1', '1', '10', '1', '1', '2', '2', '1', '2', '3', '12', '8', '8', '1', '2', '9', '9', '1', '1', '10', '8', '9', '8', '3', '1', '1', '3', '1', '10', '1', '1', '1', '4', '1', '1', '1', '7', '10', '2', '1', '8', '1', '9', '3', '1', '10', '8', '8', '1', '5', '9', '1', '2', '1', '8', '8', '1', '3', '1', '10', '2', '1', '1', '2', '8', '2', '5', '3', '5', '2', '1', '1', '9', '1', '7', '9', '9', '2', '8', '1', '12', '4', '1', '4', '9', '9', '4', '8', '1', '10', '10', '8', '8', '8', '9', '2', '3', '5', '1', '8', '1', '1', '1', '7', '10', '1', '4', '12', '3', '2', '2', '9', '1', '1', '1', '2', '8', '4', '1', '7', '3', '12', '8', '6', '2', '2', '7', '9', '11', '1', '10', '9', '1', '8', '12', '2', '11', '1', '2', '3', '1', '1', '1', '8', '9', '2', '2', '2', '2', '3', '3', '8', '10', '4', '1', '2', '9', '8', '2', '2', '9', '1', '8', '11', '4', '2', '8', '7', '1', '1', '7', '3', '9', '9', '4', '5', '8', '10', '2', '9', '9', '9', '8', '1', '9', '2', '2', '2', '1', '2', '9', '4', '3', '12', '4', '3', '2', '3', '8', '3', '10', '1', '10', '1', '1', '8', '10', '6', '8', '9', '9', '1', '2', '9', '2', '9', '3', '8', '1', '1', '12', '1', '5', '1', '10', '8', '10', '2', '7', '1', '1', '1', '1', '3', '2', '3', '5', '9', '1', '2', '1', '9', '8', '10', '9', '8', '1', '8', '1', '8', '2', '8', '1', '2', '8', '1', '2', '5', '8', '12', '2', '1', '1', '1', '1', '1', '8', '8', '2', '1', '4', '2', '8', '8', '8', '2', '9', '9', '11', '1', '2', '9', '3', '1', '1', '8', '9', '2', '4', '10', '1', '9', '8', '4', '9', '8', '10', '8', '8', '9', '2', '8', '9', '3', '3', '3', '4', '3', '2', '2', '10', '8', '2', '1', '5', '1', '9', '1', '1', '2', '1', '2', '3', '1', '1', '8', '8', '1', '10', '8', '8', '1', '6', '4', '8', '2', '5', '8', '1', '3', '8', '2', '8', '9', '1', '1', '8', '12', '10', '1', '5', '8', '2', '8', '10', '9', '9', '1', '6', '9', '1', '10', '8', '2', '9', '10', '1', '2', '1', '1', '8', '8', '3', '9', '8', '1', '10', '2', '8', '1', '10', '1', '5', '1', '1', '1', '5', '1', '1', '1', '4', '1', '1', '1', '8', '2', '8', '1', '8', '3', '8', '9', '1', '8', '1', '8', '1', '1', '2', '2', '1', '12', '9', '9', '1', '8', '2', '1', '2', '8', '1', '9', '1', '1', '2', '1', '2', '2', '2', '1', '9', '9', '8', '8', '1', '1', '9', '10', '8', '4', '3', '3', '4', '9', '1', '3', '3', '10', '2', '2', '1', '8', '4', '1', '9', '4', '1', '1', '9', '8', '10', '4', '9', '9', '8', '2', '1', '3', '4', '9', '3', '8', '9', '1', '1', '2', '1', '7', '8', '2', '9', '1', '9', '2', '6', '9', '10', '8', '1', '1', '5', '9', '5', '1', '9', '10', '9', '3', '3', '8', '8', '2', '9', '2', '8', '2', '1', '8', '5', '8', '3', '10', '1', '1', '2', '1', '8', '1', '4', '3', '2', '9', '4', '9', '8', '8', '8', '1', '3', '9', '1', '9', '9', '1', '2', '1', '9', '8', '9', '8', '1', '1', '1', '4', '2', '2', '9', '9', '1', '1', '1', '3', '6', '1', '2', '3', '1', '4', '2', '9', '1', '9', '9', '1', '8', '2', '1', '9', '1', '8', '1', '8', '8', '2', '1', '9', '9', '6', '8', '8', '9', '8', '10', '8', '9', '5', '1', '1', '1', '1', '8', '1', '8', '12', '8', '1', '12', '9', '2', '8', '1', '1', '2', '1', '8', '6', '9', '9', '8', '1', '8', '9', '7', '7', '8', '9', '9', '1', '8', '3', '8', '1', '3', '3', '8', '9', '8', '2', '8', '1', '2', '9', '8', '1', '1', '1', '1', '9', '1', '9', '8', '12', '3', '8', '8', '1', '10', '10', '10', '2', '2', '1', '10', '2', '2', '10', '8', '12', '8', '1', '1', '1', '2', '1', '1', '3', '8', '1', '2', '2', '2', '1', '1', '6', '2', '8', '8', '8', '1', '1', '1', '9', '9', '2', '8', '10', '2', '8', '2', '1', '2', '9', '9', '2', '1', '1', '8', '8', '1', '3', '1', '8', '9', '1', '10', '9', '1', '1', '1', '1', '7', '2', '2', '1', '2', '8', '8', '1', '2', '1', '3', '2', '1', '8', '3', '9', '2', '10', '2', '10', '1', '2', '1', '1', '13', '9', '10', '8', '2', '2', '1', '1', '8', '2', '2', '1', '9', '1', '1', '8', '9', '9', '2', '9', '2', '2', '1', '1', '1', '8', '9', '4', '9', '9', '1', '8', '2', '1', '1', '8', '2', '2', '2', '8', '1', '1', '8', '2', '10', '2', '9', '9', '7', '1', '1', '2', '2', '8', '3', '1', '2', '1', '1', '8', '1', '1', '1', '9', '1', '1', '8', '8', '1', '9', '6', '1', '9', '1', '8', '1', '8', '8', '8', '1', '3', '8', '8', '2', '6', '3', '2', '1', '10', '1', '8', '2', '1', '6', '1', '1', '1', '8', '1', '10', '1', '1', '8', '9', '2', '6', '9', '2', '9', '4', '1', '8', '1', '3', '7', '8', '8', '5', '8', '7', '1', '1', '1', '13', '8', '3', '1', '1', '1', '1', '2', '8', '2', '12', '8', '1', '2', '5', '1', '8', '2', '10', '8', '2', '10', '1', '5', '2', '1', '1', '5', '2', '2', '7', '8', '2', '9', '9', '1', '10', '1', '8', '2', '5', '8', '1', '5', '1', '10', '1', '1', '9', '8', '6', '1', '8', '9', '8', '1', '8', '2', '2', '8', '3', '9', '1', '9', '3', '8', '4', '4', '3', '3', '1', '1', '1', '8', '9', '1', '1', '8', '3', '1', '2', '8', '2', '1', '1', '10', '1', '2', '2', '1', '1', '8', '2', '8', '2', '10', '2', '2', '10', '8', '8', '8', '13', '2', '2', '9', '2', '5', '9', '2', '1', '8', '8', '8', '1', '12', '12', '2', '9', '2', '1', '8', '2', '1', '8', '1', '9', '9', '2', '7', '1', '1', '7', '1', '4', '3', '1', '10', '3', '10', '9', '4', '6', '7', '5', '2', '1', '8', '8', '1', '4', '9', '2', '1', '8', '1', '1', '1', '1', '1', '8', '9', '8', '8', '8', '8', '9', '8', '10', '1', '8', '2', '7', '8', '9', '1', '2', '5', '9', '10', '8', '9', '12', '1', '6', '1', '2', '10', '9', '4', '1', '8', '10', '10', '1', '1', '1', '1', '1', '2', '3', '8', '1', '2', '10', '2', '1', '2', '4', '2', '2', '9', '1', '4', '2', '1', '1', '12', '12', '9', '9', '7', '1', '8', '4', '9', '9', '8', '1', '7', '3', '2', '1', '1', '4', '8', '1', '5', '8', '2', '8', '1', '14', '9', '12', '1', '10', '2', '1', '1', '8', '8', '6', '6', '3', '1', '2', '8', '1', '3', '2', '1', '8', '8', '1', '10', '8', '2', '8', '2', '5', '9', '1', '8', '8', '1', '1', '8', '8', '13', '1', '3', '8', '4', '1', '9', '7', '8', '8', '8', '3', '8', '1', '4', '2', '8', '8', '8', '7', '1', '1', '2', '8', '8', '9', '8', '8', '2', '3', '9', '9', '2', '1', '2', '2', '1', '8', '2', '6', '2', '1', '1', '9', '10', '3', '8', '2', '3', '2', '8', '8', '1', '8', '8', '8', '9', '1', '4', '1', '9', '2', '1', '8', '0', '1', '8', '1', '1', '8', '9', '9', '1', '3', '1', '2', '8', '8', '7', '1', '1', '2', '9', '2', '10', '2', '8', '2', '2', '2', '7', '1', '9', '8', '1', '3', '9', '2', '1', '10', '8', '1', '4', '1', '8', '5', '9', '8', '8', '1', '2', '2', '1', '8', '8', '6', '8', '1', '1', '8', '3', '2', '2', '1', '8', '1', '7', '6', '8', '1', '1', '1', '9', '1', '1', '1', '2', '1', '11', '10', '10', '11', '9', '']\n",
            "['8', '1', '8', '2', '8', '8', '8', '9', '7', '8', '1', '2', '1', '1', '8', '4', '8', '8', '12', '3', '3', '7', '3', '12', '1', '8', '8', '8', '8', '8', '8', '8', '1', '9', '5', '9', '9', '9', '11', '8', '8', '8', '4', '8', '8', '8', '8', '1', '3', '9', '3', '7', '1', '2', '9', '9', '7', '8', '8', '1', '10', '7', '8', '8', '9', '8', '7', '9', '9', '12', '7', '2', '8', '1', '11', '11', '1', '7', '7', '12', '1', '9', '8', '10', '12', '7', '8', '2', '8', '9', '9', '1', '8', '9', '1', '7', '12', '10', '10', '10', '8', '3', '7', '9', '8', '9', '1', '8', '8', '2', '7', '2', '9', '9', '11', '8', '8', '12', '12', '7', '8', '12', '4', '9', '3', '1', '12', '1', '1', '8', '8', '3', '8', '8', '8', '8', '9', '1', '8', '8', '10', '1', '8', '2', '8', '8', '7', '3', '8', '2', '4', '4', '9', '8', '10', '12', '12', '1', '1', '9', '1', '1', '1', '8', '2', '2', '8', '1', '1', '2', '2', '1', '2', '8', '1', '9', '9', '8', '8', '4', '2', '9', '9', '8', '3', '4', '3', '1', '8', '8', '2', '1', '9', '7', '8', '8', '1', '12', '3', '8', '2', '4', '2', '9', '12', '1', '4', '1', '8', '8', '8', '2', '2', '8', '9', '8', '8', '8', '10', '9', '8', '7', '9', '1', '1', '9', '4', '2', '4', '2', '2', '1', '7', '8', '11', '11', '3', '9', '2', '4', '8', '9', '1', '8', '1', '1', '4', '9', '1', '1', '8', '8', '2', '1', '8', '4', '2', '8', '9', '8', '8', '2', '8', '8', '8', '7', '1', '1', '1', '2', '1', '1', '8', '7', '8', '8', '12', '2', '12', '12', '8', '10', '12', '8', '3', '3', '12', '10', '1', '8', '12', '1', '8', '8', '2', '8', '4', '7', '8', '7', '10', '8', '10', '9', '8', '12', '12', '1', '8', '8', '3', '8', '8', '8', '8', '8', '1', '9', '8', '11', '1', '1', '1', '9', '8', '1', '9', '2', '3', '11', '8', '9', '9', '9', '2', '1', '8', '8', '9', '7', '1', '4', '9', '4', '8', '8', '4', '8', '12', '9', '4', '8', '2', '10', '10', '10', '8', '9', '9', '8', '8', '12', '7', '1', '8', '8', '8', '4', '1', '1', '1', '1', '1', '1', '8', '1', '9', '8', '9', '9', '4', '8', '12', '9', '8', '8', '2', '8', '8', '8', '6', '9', '8', '3', '7', '8', '8', '4', '12', '8', '8', '9', '12', '12', '9', '8', '2', '9', '2', '3', '1', '12', '8', '10', '9', '9', '9', '10', '10', '3', '8', '12', '1', '4', '2', '1', '10', '8', '2', '8', '4', '8', '9', '1', '9', '9', '10', '10', '1', '4', '9', '2', '4', '9', '1', '1', '3', '10', '3', '3', '8', '7', '3', '8', '9', '9', '12', '4', '8', '12', '2', '2', '4', '1', '9', '9', '4', '1', '4', '2', '8', '12', '2', '3', '10', '10', '9', '8', '9', '9', '1', '12', '8', '8', '8', '12', '4', '1', '8', '8', '1', '9', '8', '8', '2', '1', '8', '9', '8', '3', '3', '3', '1', '8', '8', '9', '1', '10', '9', '9', '9', '9', '5', '9', '9', '8', '8', '8', '8', '8', '8', '8', '8', '11', '12', '8', '8', '1', '8', '9', '11', '2', '2', '2', '2', '3', '1', '2', '2', '8', '2', '4', '9', '1', '2', '9', '8', '2', '8', '9', '9', '3', '10', '9', '9', '2', '8', '9', '8', '12', '12', '1', '3', '8', '8', '8', '2', '7', '7', '7', '7', '3', '9', '1', '9', '8', '9', '9', '1', '1', '1', '2', '9', '9', '9', '11', '1', '8', '8', '9', '1', '9', '8', '8', '8', '1', '1', '8', '7', '1', '1', '8', '8', '9', '4', '4', '8', '2', '2', '8', '8', '8', '8', '8', '8', '11', '8', '2', '9', '4', '9', '3', '9', '9', '1', '3', '9', '3', '1', '12', '8', '9', '12', '1', '8', '4', '2', '1', '4', '8', '3', '3', '8', '2', '8', '9', '7', '8', '8', '8', '5', '8', '3', '9', '8', '8', '13', '12', '1', '1', '2', '8', '4', '1', '9', '9', '12', '8', '9', '12', '9', '1', '9', '9', '9', '9', '3', '2', '9', '9', '4', '8', '12', '2', '4', '9', '3', '1', '9', '7', '8', '9', '9', '8', '4', '8', '8', '7', '9', '10', '3', '8', '8', '8', '1', '1', '1', '1', '8', '8', '4', '1', '10', '1', '5', '7', '7', '1', '8', '9', '3', '7', '2', '7', '7', '2', '4', '8', '12', '7', '4', '2', '9', '9', '12', '6', '10', '8', '2', '4', '12', '9', '9', '3', '8', '8', '1', '2', '10', '9', '9', '8', '4', '12', '2', '1', '8', '8', '8', '12', '10', '10', '9', '3', '8', '8', '9', '2', '8', '10', '1', '1', '1', '1', '2', '1', '1', '1', '1', '9', '8', '12', '9', '4', '8', '8', '9', '1', '9', '3', '9', '8', '8', '1', '7', '7', '10', '1', '8', '8', '1', '9', '8', '10', '3', '1', '7', '1', '8', '8', '12', '8', '8', '1', '8', '7', '1', '7', '7', '8', '2', '1', '8', '8', '2', '10', '8', '8', '8', '8', '8', '10', '1', '8', '8', '12', '8', '3', '3', '2', '2', '2', '10', '8', '8', '8', '2', '9', '1', '8', '9', '3', '2', '8', '10', '8', '6', '1', '1', '8', '4', '1', '9', '10', '8', '1', '7', '1', '2', '8', '1', '1', '1', '12', '1', '9', '12', '8', '12', '12', '12', '8', '8', '12', '4', '8', '8', '8', '8', '9', '9', '1', '3', '3', '3', '3', '1', '12', '12', '9', '10', '8', '8', '1', '9', '2', '2', '13', '9', '8', '9', '2', '1', '9', '1', '8', '8', '8', '4', '8', '1', '1', '1', '12', '12', '7', '2', '2', '2', '8', '3', '8', '9', '2', '10', '7', '8', '9', '2', '1', '2', '12', '12', '8', '8', '9', '2', '2', '9', '11', '1', '8', '1', '10', '9', '2', '1', '4', '7', '7', '7', '7', '7', '12', '8', '8', '8', '1', '1', '10', '1', '12', '1', '8', '2', '1', '1', '12', '8', '7', '9', '12', '8', '9', '3', '9', '8', '8', '8', '8', '3', '11', '2', '2', '9', '8', '8', '10', '8', '2', '7', '3', '1', '4', '7', '8', '8', '1', '8', '3', '7', '12', '8', '10', '9', '9', '8', '8', '2', '8', '9', '9', '1', '2', '8', '8', '9', '8', '3', '8', '1', '8', '10', '9', '8', '9', '9', '12', '4', '4', '8', '9', '9', '8', '2', '10', '1', '2', '8', '9', '1', '9', '9', '9', '7', '12', '12', '8', '1', '1', '1', '1', '8', '3', '1', '1', '8', '1', '8', '8', '7', '8', '8', '8', '8', '3', '2', '2', '10', '10', '10', '7', '8', '1', '2', '12', '7', '9', '8', '7', '8', '12', '2', '8', '9', '2', '6', '6', '7', '9', '8', '1', '8', '9', '8', '1', '12', '1', '2', '8', '7', '7', '7', '8', '2', '2', '8', '1', '2', '2', '9', '9', '1', '8', '8', '4', '3', '3', '1', '6', '3', '3', '12', '3', '8', '9', '1', '4', '3', '1', '8', '3', '9', '2', '8', '2', '8', '8', '8', '1', '1', '1', '9', '9', '8', '1', '9', '8', '1', '1', '3', '10', '8', '1', '1', '3', '9', '1', '4', '4', '1', '8', '9', '9', '2', '0', '0', '1', '8', '3', '1', '8', '8', '9', '8', '8', '1', '1', '8', '9', '8', '8', '8', '7', '9', '8', '8', '8', '10', '9', '8', '1', '2', '6', '1', '9', '9', '8', '12', '12', '12', '8', '8', '2', '8', '1', '2', '2', '2', '1', '9', '8', '2', '12', '2', '8', '12', '8', '9', '8', '8', '9', '7', '1', '1', '1', '1', '1', '8', '8', '1', '8', '8', '1', '1', '3', '2', '8', '8', '9', '10', '10', '2', '2', '1', '9', '2', '9', '9', '4', '12', '12', '12', '10', '7', '3', '3', '4', '2', '2', '9', '2', '8', '4', '2', '4', '1', '10', '9', '7', '8', '7', '1', '1', '3', '3', '1', '1', '3', '3', '3', '1', '1', '1', '1', '8', '2', '3', '1', '1', '2', '8', '8', '12', '8', '8', '8', '8', '11', '9', '1', '8', '9', '2', '8', '8', '8', '3', '9', '1', '9', '2', '7', '2', '8', '2', '8', '10', '8', '1', '10', '1', '1', '9', '9', '8', '8', '1', '8', '8', '8', '12', '8', '8', '8', '1', '8', '8', '8', '1', '9', '1', '1', '8', '1', '8', '9', '8', '2', '12', '9', '9', '0', '1', '8', '8', '1', '8', '12', '8', '8', '10', '8', '8', '8', '7', '8', '1', '8', '7', '3', '10', '1', '8', '9', '1', '8', '8', '8', '10', '1', '10', '3', '9', '1', '8', '9', '2', '8', '3', '3', '9', '9', '7', '9', '1', '1', '9', '2', '1', '1', '1', '7', '1', '1', '8', '8', '1', '1', '8', '1', '8', '3', '12', '9', '3', '3', '8', '8', '8', '8', '3', '1', '3', '3', '1', '11', '0', '8', '8', '7', '8', '12', '1', '8', '9', '8', '9', '8', '8', '3', '8', '8', '1', '1', '1', '9', '2', '2', '2', '8', '7', '12', '8', '8', '9', '10', '10', '7', '8', '1', '9', '8', '7', '3', '1', '3', '8', '2', '2', '3', '9', '8', '4', '4', '8', '9', '2', '1', '1', '7', '8', '9', '9', '7', '8', '7', '7', '8', '2', '2', '8', '4', '9', '7', '10', '0', '9', '8', '3', '7', '8', '1', '1', '8', '9', '9', '2', '2', '10', '1', '9', '10', '10', '10', '8', '3', '2', '12', '9', '9', '10', '12', '9', '12', '12', '9', '1', '2', '4', '12', '12', '7', '8', '9', '7', '7', '7', '3', '9', '8', '9', '1', '12', '8', '9', '4', '1', '3', '12', '12', '12', '12', '8', '8', '2', '1', '1', '2', '1', '1', '1', '12', '12', '8', '12', '2', '2', '12', '3', '3', '12', '8', '2', '8', '8', '12', '2', '1', '10', '3', '2', '8', '7', '1', '8', '1', '3', '7', '8', '9', '8', '3', '1', '1', '7', '8', '8', '9', '8', '2', '9', '2', '2', '9', '8', '1', '8', '8', '1', '3', '3', '1', '1', '10', '1', '2', '8', '1', '1', '1', '1', '9', '1', '4', '1', '7', '7', '7', '7', '2', '2', '8', '8', '12', '1', '9', '1', '7', '3', '3', '1', '8', '8', '10', '8', '9', '2', '9', '1', '3', '8', '8', '3', '12', '2', '8', '12', '2', '9', '1', '3', '3', '3', '3', '2', '8', '7', '9', '8', '3', '3', '1', '7', '8', '3', '1', '1', '12', '8', '9', '1', '2', '3', '8', '1', '1', '3', '3', '9', '1', '1', '1', '12', '1', '7', '3', '3', '1', '8', '8', '8', '1', '2', '4', '8', '1', '10', '2', '5', '3', '3', '12', '10', '9', '9', '12', '9', '0', '2', '8', '8', '9', '9', '9', '8', '1', '3', '1', '1', '4', '8', '1', '10', '8', '7', '2', '8', '2', '8', '4', '7', '8', '1', '9', '1', '9', '8', '2', '8', '2', '7', '9', '2', '2', '9', '1', '8', '12', '1', '8', '1', '4', '1', '9', '9', '1', '10', '12', '4', '8', '1', '7', '3', '9', '2', '12', '7', '8', '8', '2', '1', '12', '9', '8', '1', '2', '2', '8', '10', '2', '1', '7', '7', '7', '12', '3', '3', '8', '3', '8', '8', '3', '9', '8', '9', '1', '1', '8', '7', '9', '3', '3', '8', '1', '0', '9', '9', '9', '1', '8', '9', '9', '10', '1', '8', '7', '8', '8', '8', '9', '9', '8', '9', '10', '4', '9', '3', '7', '12', '1', '9', '9', '8', '9', '1', '9', '3', '1', '8', '4', '12', '10', '9', '8', '7', '10', '8', '12', '12', '3', '10', '8', '12', '2', '1', '2', '3', '9', '8', '8', '7', '1', '1', '2', '2', '1', '2', '2', '7', '1', '3', '9', '9', '3', '8', '8', '8', '8', '8', '7', '8', '8', '10', '8', '1', '8', '2', '8', '2', '2', '2', '2', '2', '1', '7', '12', '10', '1', '2', '8', '1', '4', '7', '8', '1', '12', '8', '7', '9', '2', '2', '2', '8', '1', '8', '1', '1', '0', '2', '2', '6', '1', '8', '2', '1', '8', '1', '1', '2', '2', '3', '2', '2', '10', '10', '9', '1', '7', '7', '8', '8', '1', '12', '10', '12', '3', '8', '8', '8', '3', '8', '3', '10', '2', '2', '2', '1', '2', '2', '1', '0', '1', '8', '9', '1', '1', '1', '2', '2', '2', '2', '2', '1', '1', '1', '1', '12', '9', '9', '1', '10', '11', '12', '9', '1', '1', '8', '8', '1', '2', '12', '8', '3', '7', '2', '10', '9', '7', '8', '1', '2', '2', '7', '9', '12', '2', '2', '1', '8', '9', '2', '3', '2', '2', '2', '9', '9', '8', '9', '2', '3', '8', '8', '9', '7', '3', '10', '8', '8', '9', '1', '1', '2', '8', '1', '10', '8', '8', '9', '7', '1', '7', '12', '8', '1', '7', '2', '1', '3', '9', '2', '8', '8', '1', '2', '3', '9', '3', '8', '9', '7', '7', '1', '10', '2', '8', '8', '8', '1', '8', '2', '8', '8', '1', '2', '8', '10', '2', '1', '0', '8', '3', '8', '10', '10', '12', '3', '8', '9', '3', '10', '8', '8', '8', '1', '8', '8', '2', '2', '2', '2', '2', '2', '1', '1', '10', '1', '10', '8', '2', '1', '2', '2', '8', '3', '3', '2', '2', '1', '8', '1', '3', '1', '9', '2', '2', '1', '3', '2', '2', '3', '2', '2', '3', '2', '1', '1', '2', '1', '2', '7', '8', '2', '1', '12', '12', '3', '1', '9', '9', '7', '8', '7', '2', '7', '9', '2', '2', '2', '8', '9', '7', '9', '2', '8', '9', '9', '2', '9', '1', '1', '9', '8', '3', '3', '8', '2', '7', '8', '11', '2', '8', '9', '1', '8', '3', '1', '2', '1', '2', '2', '2', '2', '8', '3', '9', '2', '10', '9', '9', '2', '7', '7', '7', '1', '3', '8', '8', '1', '1', '8', '7', '1', '8', '8', '9', '3', '3', '3', '2', '4', '8', '12', '8', '1', '12', '9', '2', '8', '2', '12', '2', '1', '3', '8', '12', '12', '11', '8', '10', '9', '2', '9', '4', '10', '1', '12', '12', '9', '3', '8', '9', '12', '9', '9', '2', '2', '2', '3', '5', '1', '1', '1', '7', '7', '8', '2', '2', '8', '2', '1', '7', '3', '2', '9', '8', '9', '1', '1', '9', '8', '9', '3', '3', '2', '9', '4', '9', '8', '8', '1', '8', '10', '2', '0', '3', '8', '8', '8', '9', '12', '9', '8', '2', '2', '8', '10', '9', '8', '2', '2', '4', '1', '9', '9', '8', '8', '10', '3', '1', '1', '2', '8', '7', '8', '2', '1', '1', '8', '12', '2', '9', '4', '8', '3', '3', '3', '8', '2', '12', '12', '8', '9', '12', '8', '2', '12', '7', '9', '2', '2', '1', '3', '1', '3', '11', '9', '8', '1', '10', '2', '12', '3', '8', '4', '1', '2', '8', '8', '3', '9', '3', '8', '7', '1', '1', '3', '1', '8', '2', '9', '8', '12', '1', '1', '1', '9', '9', '1', '8', '8', '8', '2', '2', '12', '3', '1', '1', '1', '9', '9', '3', '2', '1', '1', '9', '9', '1', '9', '9', '1', '9', '3', '9', '1', '8', '1', '9', '8', '3', '8', '8', '9', '9', '8', '2', '8', '1', '2', '2', '10', '1', '2', '1', '1', '9', '1', '9', '3', '7', '7', '2', '10', '3', '3', '1', '1', '9', '1', '2', '1', '3', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '8', '8', '7', '1', '1', '8', '8', '2', '1', '12', '1', '8', '1', '9', '8', '8', '2', '1', '9', '9', '2', '2', '8', '1', '7', '7', '9', '8', '1', '6', '8', '8', '2', '2', '8', '3', '8', '3', '2', '3', '8', '1', '2', '2', '2', '8', '9', '9', '9', '12', '1', '9', '2', '1', '9', '2', '9', '9', '10', '8', '1', '1', '9', '2', '1', '7', '1', '3', '7', '1', '1', '1', '3', '8', '8', '8', '9', '9', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '1', '0', '1', '1', '1', '2', '2', '3', '1', '1', '2', '3', '3', '3', '7', '3', '1', '9', '3', '9', '1', '4', '1', '1', '9', '10', '9', '8', '2', '3', '10', '9', '3', '10', '12', '8', '9', '8', '2', '1', '9', '8', '1', '7', '8', '1', '9', '1', '2', '10', '7', '7', '8', '1', '3', '3', '9', '3', '3', '1', '1', '1', '9', '1', '3', '8', '8', '8', '1', '8', '1', '9', '7', '8', '8', '2', '1', '3', '8', '2', '1', '6', '1', '8', '8', '2', '8', '2', '2', '9', '8', '1', '1', '6', '8', '6', '10', '2', '1', '1', '8', '9', '3', '3', '3', '1', '3', '9', '6', '8', '1', '8', '3', '1', '2', '2', '12', '7', '1', '1', '1', '1', '12', '1', '8', '8', '3', '2', '1', '9', '2', '3', '3', '2', '2', '7', '2', '2', '2', '3', '1', '9', '8', '7', '1', '1', '3', '1', '9', '4', '3', '9', '2', '1', '1', '9', '8', '8', '7', '2', '1', '3', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '10', '1', '1', '8', '2', '8', '1', '8', '1', '3', '1', '2', '1', '1', '3', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '8', '1', '9', '8', '8', '1', '10', '8', '8', '1', '3', '9', '8', '9', '8', '2', '1', '3', '4', '1', '12', '1', '9', '8', '2', '7', '2', '1', '2', '9', '2', '1', '3', '8', '1', '2', '3', '8', '2', '10', '10', '10', '9', '9', '9', '3', '8', '3', '1', '1', '1', '1', '1', '1', '2', '1', '9', '2', '7', '9', '8', '7', '9', '1', '1', '1', '1', '8', '2', '2', '3', '3', '2', '12', '8', '3', '1', '1', '12', '9', '8', '2', '2', '9', '1', '2', '2', '9', '1', '1', '2', '4', '8', '1', '8', '10', '2', '9', '9', '9', '1', '2', '1', '1', '2', '2', '2', '12', '1', '2', '8', '3', '9', '9', '3', '2', '9', '9', '7', '2', '8', '8', '9', '2', '9', '1', '1', '1', '1', '1', '2', '8', '2', '1', '2', '2', '8', '3', '1', '1', '9', '1', '3', '10', '7', '9', '8', '8', '2', '2', '9', '2', '2', '2', '2', '2', '2', '9', '1', '3', '6', '4', '2', '2', '9', '1', '9', '8', '1', '1', '1', '7', '3', '2', '9', '9', '1', '9', '7', '2', '8', '9', '9', '12', '10', '8', '10', '2', '3', '1', '2', '2', '12', '12', '3', '12', '1', '2', '1', '2', '1', '2', '8', '2', '3', '12', '12', '8', '2', '2', '9', '2', '9', '2', '3', '3', '1', '1', '1', '12', '3', '7', '1', '3', '1', '2', '9', '2', '7', '2', '1', '8', '3', '7', '8', '1', '1', '3', '8', '3', '2', '9', '3', '1', '1', '1', '1', '11', '1', '2', '6', '1', '2', '3', '8', '9', '9', '2', '9', '2', '1', '1', '3', '1', '12', '9', '1', '1', '9', '1', '9', '9', '8', '9', '8', '1', '2', '7', '1', '0', '9', '8', '2', '3', '2', '4', '1', '1', '1', '8', '1', '12', '1', '2', '3', '3', '9', '9', '9', '9', '9', '7', '9', '3', '9', '1', '7', '3', '3', '3', '3', '7', '8', '2', '2', '2', '8', '2', '3', '9', '9', '3', '1', '8', '9', '12', '8', '8', '3', '2', '1', '6', '1', '9', '1', '1', '1', '1', '1', '1', '2', '2', '1', '2', '2', '2', '2', '9', '2', '5', '3', '2', '2', '8', '2', '1', '8', '3', '3', '8', '3', '1', '3', '9', '2', '8', '9', '4', '4', '9', '8', '8', '7', '7', '3', '1', '8', '8', '3', '2', '2', '10', '3', '3', '2', '2', '2', '2', '12', '3', '1', '2', '7', '7', '12', '2', '1', '2', '1', '1', '2', '1', '3', '3', '3', '1', '3', '9', '4', '8', '8', '4', '2', '4', '2', '8', '9', '1', '1', '2', '2', '2', '8', '7', '2', '8', '2', '9', '1', '8', '1', '1', '2', '1', '1', '1', '2', '9', '9', '8', '1', '8', '1', '4', '8', '1', '2', '7', '9', '2', '1', '8', '9', '8', '9', '1', '1', '2', '3', '2', '12', '7', '1', '2', '4', '4', '4', '2', '2', '2', '9', '8', '8', '1', '12', '3', '3', '2', '2', '3', '12', '1', '5', '1', '1', '3', '2', '8', '8', '2', '2', '2', '3', '9', '8', '8', '9', '8', '8', '11', '8', '2', '9', '2', '3', '1', '7', '1', '8', '2', '8', '1', '1', '1', '8', '1', '1', '1', '7', '8', '8', '2', '3', '2', '1', '8', '8', '1', '8', '4', '8', '9', '8', '9', '8', '1', '2', '3', '2', '1', '2', '2', '3', '1', '9', '4', '8', '1', '1', '9', '1', '1', '8', '2', '2', '2', '1', '7', '3', '3', '1', '3', '3', '12', '3', '1', '1', '3', '1', '1', '4', '8', '4', '4', '3', '3', '3', '4', '8', '1', '9', '9', '9', '4', '1', '7', '4', '8', '4', '9', '8', '1', '1', '3', '8', '9', '1', '9', '7', '1', '1', '9', '1', '8', '8', '8', '1', '1', '8', '2', '2', '2', '9', '4', '4', '1', '2', '1', '2', '9', '1', '1', '8', '5', '5', '5', '9', '12', '4', '1', '2', '1', '8', '8', '1', '9', '9', '2', '12', '1', '1', '7', '8', '8', '4', '1', '2', '8', '11', '2', '3', '2', '2', '1', '11', '2', '2', '2', '2', '9', '9', '2', '2', '9', '3', '1', '9', '1', '1', '1', '7', '8', '1', '8', '9', '1', '2', '9', '8', '1', '2', '9', '8', '12', '2', '2', '10', '8', '2', '2', '8', '8', '1', '2', '6', '1', '1', '7', '7', '2', '3', '2', '1', '1', '8', '1', '10', '8', '12', '6', '4', '1', '4', '1', '2', '9', '8', '9', '4', '8', '8', '10', '8', '8', '8', '8', '8', '2', '2', '8', '4', '9', '3', '3', '3', '3', '3', '9', '2', '1', '1', '2', '3', '2', '1', '2', '3', '3', '3', '2', '2', '3', '3', '2', '1', '2', '3', '3', '3', '3', '12', '9', '3', '2', '2', '3', '1', '5', '1', '1', '3', '2', '2', '1', '2', '9', '3', '9', '8', '1', '8', '7', '7', '9', '1', '1', '7', '9', '10', '1', '7', '1', '4', '3', '8', '9', '4', '9', '9', '2', '9', '2', '8', '4', '2', '2', '9', '5', '2', '1', '10', '9', '3', '1', '1', '1', '2', '1', '2', '9', '1', '7', '9', '9', '8', '2', '2', '8', '9', '1', '9', '8', '2', '3', '2', '2', '1', '2', '2', '2', '1', '1', '8', '1', '9', '4', '12', '8', '2', '7', '2', '2', '1', '9', '3', '1', '8', '12', '1', '1', '2', '1', '10', '2', '6', '12', '12', '4', '9', '1', '9', '10', '1', '2', '8', '2', '1', '8', '6', '12', '9', '9', '2', '1', '7', '8', '9', '5', '8', '1', '8', '8', '3', '1', '8', '2', '8', '2', '2', '1', '2', '9', '2', '8', '1', '12', '8', '2', '7', '3', '3', '12', '2', '3', '3', '9', '9', '3', '3', '3', '3', '3', '2', '1', '4', '1', '4', '8', '8', '2', '1', '2', '9', '12', '1', '10', '12', '1', '2', '9', '4', '8', '10', '3', '2', '8', '7', '4', '8', '9', '2', '7', '1', '10', '2', '2', '2', '8', '4', '2', '2', '1', '1', '8', '7', '9', '2', '1', '9', '8', '9', '12', '4', '8', '2', '8', '7', '7', '1', '9', '2', '1', '1', '9', '1', '8', '2', '3', '9', '9', '1', '3', '2', '9', '2', '2', '8', '1', '1', '2', '1', '2', '1', '9', '8', '2', '2', '4', '8', '8', '9', '5', '5', '9', '8', '9', '6', '2', '1', '12', '2', '3', '8', '8', '9', '2', '2', '1', '3', '2', '10', '9', '10', '7', '2', '8', '4', '2', '8', '9', '8', '1', '3', '8', '8', '1', '8', '3', '8', '8', '1', '10', '3', '1', '5', '8', '8', '9', '2', '2', '9', '2', '1', '9', '1', '4', '1', '12', '8', '8', '2', '1', '1', '1', '1', '1', '9', '2', '9', '8', '9', '5', '9', '1', '8', '2', '4', '1', '1', '1', '9', '12', '4', '1', '1', '9', '8', '4', '1', '8', '9', '8', '8', '9', '9', '9', '9', '9', '9', '1', '3', '4', '2', '2', '8', '2', '9', '2', '3', '8', '3', '1', '7', '2', '1', '1', '4', '2', '9', '2', '1', '3', '2', '9', '2', '9', '3', '8', '1', '9', '1', '1', '2', '8', '8', '8', '2', '3', '9', '9', '8', '2', '4', '1', '5', '1', '1', '9', '9', '2', '1', '1', '1', '9', '9', '1', '3', '9', '2', '2', '9', '9', '8', '3', '9', '9', '8', '2', '2', '8', '9', '2', '2', '8', '9', '10', '10', '2', '8', '7', '9', '9', '4', '2', '4', '11', '2', '1', '7', '8', '8', '8', '9', '4', '9', '8', '8', '2', '1', '1', '9', '8', '3', '3', '8', '8', '7', '9', '1', '3', '4', '8', '10', '2', '4', '4', '8', '2', '8', '2', '8', '9', '2', '1', '2', '2', '3', '1', '9', '4', '5', '9', '9', '1', '1', '1', '1', '1', '1', '7', '1', '1', '1', '8', '1', '1', '1', '1', '1', '9', '1', '2', '1', '12', '9', '3', '9', '9', '4', '1', '9', '1', '1', '2', '11', '9', '3', '2', '2', '2', '4', '2', '3', '2', '7', '7', '8', '1', '10', '9', '5', '7', '1', '10', '8', '1', '2', '7', '1', '12', '5', '8', '4', '2', '9', '9', '8', '2', '9', '8', '8', '10', '2', '3', '2', '7', '2', '8', '10', '3', '2', '9', '9', '9', '1', '1', '1', '1', '8', '2', '10', '9', '8', '1', '2', '2', '2', '1', '2', '1', '3', '9', '12', '2', '2', '4', '8', '1', '3', '9', '4', '9', '1', '9', '9', '2', '1', '1', '9', '7', '10', '3', '10', '2', '9', '2', '9', '2', '8', '2', '1', '2', '3', '1', '1', '1', '8', '5', '8', '3', '1', '1', '4', '2', '2', '1', '3', '8', '2', '1', '1', '1', '2', '9', '4', '1', '8', '1', '2', '8', '2', '9', '2', '2', '5', '5', '2', '5', '2', '1', '8', '8', '1', '3', '12', '2', '4', '3', '2', '2', '2', '6', '2', '3', '3', '1', '8', '2', '2', '1', '1', '8', '8', '10', '1', '9', '2', '9', '12', '0', '2', '1', '3', '2', '2', '1', '2', '1', '9', '9', '2', '9', '8', '8', '1', '7', '8', '1', '2', '6', '9', '8', '10', '1', '12', '2', '2', '1', '8', '2', '1', '12', '7', '4', '2', '10', '2', '2', '1', '2', '1', '2', '1', '1', '2', '1', '9', '8', '10', '2', '10', '9', '9', '12', '5', '3', '2', '8', '2', '8', '3', '3', '1', '4', '9', '10', '2', '4', '8', '1', '2', '10', '12', '12', '3', '1', '1', '2', '9', '6', '6', '1', '9', '1', '8', '1', '8', '8', '8', '8', '2', '2', '2', '8', '8', '2', '1', '1', '1', '1', '1', '8', '8', '5', '8', '8', '1', '8', '9', '9', '1', '7', '12', '9', '9', '7', '2', '2', '7', '8', '9', '8', '2', '9', '6', '3', '4', '8', '4', '1', '2', '9', '8', '8', '8', '2', '1', '1', '8', '8', '3', '1', '9', '9', '7', '1', '2', '2', '2', '9', '4', '1', '2', '12', '1', '8', '2', '1', '9', '1', '8', '9', '9', '2', '5', '4', '2', '1', '2', '8', '12', '8', '10', '3', '8', '8', '8', '2', '2', '8', '2', '8', '2', '4', '8', '10', '2', '7', '2', '1', '8', '8', '9', '5', '8', '1', '12', '7', '10', '2', '2', '2', '1', '4', '8', '12', '1', '8', '2', '2', '9', '1', '8', '3', '1', '1', '5', '10', '2', '1', '2', '4', '8', '9', '3', '2', '8', '7', '4', '4', '9', '9', '2', '8', '1', '1', '2', '4', '7', '1', '9', '1', '1', '1', '8', '4', '1', '3', '1', '2', '2', '9', '1', '8', '8', '2', '2', '9', '9', '1', '8', '8', '1', '9', '8', '8', '2', '2', '2', '2', '1', '1', '1', '7', '4', '1', '1', '4', '2', '3', '3', '2', '3', '9', '2', '8', '2', '1', '5', '1', '2', '2', '1', '3', '5', '2', '9', '1', '1', '9', '8', '1', '4', '8', '1', '8', '2', '4', '8', '4', '7', '9', '8', '1', '2', '2', '4', '4', '11', '3', '11', '1', '3', '8', '1', '9', '6', '8', '9', '3', '9', '8', '9', '2', '3', '3', '7', '1', '7', '2', '9', '9', '1', '8', '8', '1', '5', '5', '8', '8', '1', '2', '1', '3', '9', '9', '5', '9', '8', '1', '4', '3', '8', '1', '1', '2', '1', '8', '9', '8', '2', '2', '2', '1', '2', '4', '10', '8', '1', '9', '1', '8', '1', '1', '9', '9', '8', '11', '1', '8', '2', '1', '2', '8', '2', '8', '8', '2', '9', '6', '10', '1', '8', '6', '4', '5', '11', '2', '2', '8', '1', '8', '1', '8', '1', '4', '8', '1', '1', '1', '8', '3', '7', '3', '3', '7', '1', '1', '4', '8', '1', '6', '4', '2', '2', '1', '1', '1', '1', '6', '2', '2', '8', '1', '8', '5', '5', '2', '1', '1', '2', '3', '7', '1', '1', '6', '2', '9', '3', '9', '8', '9', '2', '1', '4', '2', '9', '13', '9', '2', '8', '12', '4', '1', '1', '9', '5', '1', '1', '1', '1', '8', '2', '1', '1', '2', '9', '0', '12', '1', '1', '8', '9', '8', '3', '2', '2', '12', '8', '2', '2', '2', '1', '10', '1', '9', '8', '9', '5', '2', '2', '9', '2', '8', '4', '8', '3', '7', '9', '2', '2', '7', '2', '2', '8', '1', '1', '9', '10', '9', '8', '2', '9', '0', '7', '1', '1', '1', '9', '8', '2', '8', '12', '8', '3', '2', '8', '8', '7', '7', '8', '12', '2', '1', '3', '9', '2', '2', '8', '2', '8', '8', '12', '8', '8', '1', '8', '9', '2', '4', '4', '7', '2', '1', '1', '9', '3', '7', '1', '3', '9', '8', '2', '2', '3', '1', '3', '10', '2', '3', '7', '1', '8', '1', '1', '10', '3', '10', '8', '4', '1', '2', '4', '3', '10', '9', '3', '9', '5', '8', '7', '2', '9', '3', '3', '2', '11', '8', '1', '1', '7', '2', '7', '2', '9', '4', '8', '1', '12', '8', '7', '9', '1', '0', '2', '6', '4', '9', '3', '2', '4', '12', '9', '8', '5', '9', '2', '8', '4', '6', '8', '9', '3', '1', '8', '7', '3', '1', '1', '1', '8', '9', '1', '8', '7', '9', '8', '2', '1', '2', '2', '3', '2', '2', '1', '1', '4', '9', '7', '3', '2', '8', '8', '9', '1', '9', '7', '4', '2', '2', '8', '5', '9', '1', '5', '7', '1', '4', '6', '9', '10', '1', '8', '2', '9', '1', '9', '2', '9', '8', '2', '9', '9', '11', '2', '12', '2', '2', '9', '4', '8', '1', '9', '9', '2', '8', '9', '1', '2', '9', '3', '8', '8', '1', '7', '8', '8', '2', '3', '2', '2', '2', '2', '9', '8', '10', '2', '2', '1', '9', '11', '1', '8', '8', '2', '4', '2', '1', '2', '8', '8', '9', '2', '8', '9', '2', '3', '1', '2', '1', '3', '10', '8', '1', '2', '4', '1', '9', '8', '9', '3', '3', '9', '8', '2', '11', '3', '7', '1', '8', '7', '1', '8', '8', '8', '1', '4', '8', '8', '1', '9', '3', '1', '1', '2', '8', '8', '8', '2', '1', '8', '10', '2', '12', '8', '8', '9', '1', '8', '1', '3', '2', '2', '10', '7', '2', '2', '1', '1', '8', '2', '9', '1', '2', '9', '3', '3', '10', '1', '4', '7', '10', '12', '2', '4', '10', '8', '6', '2', '9', '1', '8', '3', '1', '2', '8', '8', '2', '12', '10', '2', '10', '9', '1', '2', '5', '8', '12', '8', '8', '7', '8', '8', '1', '8', '2', '2', '9', '1', '8', '10', '5', '5', '5', '8', '1', '9', '1', '13', '1', '2', '2', '1', '2', '4', '9', '2', '1', '9', '13', '11', '1', '9', '9', '3', '10', '8', '7', '8', '8', '4', '2', '1', '9', '4', '3', '1', '1', '10', '9', '2', '8', '6', '2', '1', '1', '3', '2', '8', '1', '1', '1', '1', '2', '4', '1', '1', '10', '1', '8', '1', '1', '9', '1', '7', '1', '1', '9', '9', '2', '12', '9', '1', '8', '1', '12', '1', '8', '3', '8', '1', '8', '1', '2', '10', '1', '1', '2', '2', '9', '3', '9', '12', '1', '9', '1', '2', '8', '7', '2', '1', '1', '3', '2', '8', '4', '4', '5', '12', '7', '8', '9', '6', '1', '8', '9', '2', '1', '9', '1', '4', '1', '8', '2', '1', '1', '8', '7', '4', '9', '1', '8', '4', '2', '7', '5', '1', '3', '9', '2', '8', '2', '1', '2', '9', '1', '1', '2', '3', '4', '3', '1', '2', '2', '10', '2', '2', '8', '1', '1', '2', '4', '9', '2', '11', '9', '8', '9', '2', '1', '10', '4', '1', '1', '10', '7', '2', '10', '8', '1', '10', '8', '8', '8', '8', '8', '8', '2', '2', '2', '8', '3', '4', '1', '1', '1', '2', '1', '8', '8', '2', '8', '3', '8', '3', '1', '2', '3', '1', '1', '10', '1', '4', '4', '3', '3', '1', '9', '1', '1', '2', '1', '1', '6', '1', '1', '1', '9', '1', '4', '1', '1', '1', '1', '1', '1', '2', '12', '8', '8', '1', '9', '12', '10', '8', '2', '12', '1', '1', '2', '1', '7', '10', '7', '1', '2', '1', '10', '8', '2', '2', '8', '2', '2', '1', '9', '8', '8', '8', '8', '3', '1', '4', '2', '8', '3', '10', '10', '1', '9', '1', '9', '1', '9', '1', '8', '3', '1', '1', '8', '8', '8', '6', '3', '4', '1', '1', '1', '9', '9', '5', '2', '10', '2', '6', '2', '2', '7', '1', '8', '2', '11', '1', '1', '1', '2', '1', '9', '4', '4', '2', '8', '4', '6', '8', '8', '10', '10', '2', '1', '2', '9', '1', '8', '8', '3', '4', '8', '8', '2', '8', '8', '1', '2', '1', '2', '9', '4', '1', '3', '3', '3', '8', '8', '8', '2', '6', '4', '3', '3', '12', '3', '4', '9', '6', '8', '7', '7', '8', '6', '4', '1', '10', '6', '3', '3', '8', '1', '1', '8', '1', '11', '8', '1', '1', '2', '3', '11', '7', '2', '1', '1', '1', '9', '1', '2', '1', '1', '9', '8', '1', '1', '8', '0', '4', '1', '1', '2', '1', '1', '2', '2', '9', '1', '10', '1', '3', '8', '9', '3', '3', '1', '10', '1', '9', '1', '1', '7', '4', '1', '8', '10', '1', '2', '10', '1', '1', '2', '3', '3', '9', '1', '8', '10', '1', '7', '9', '1', '9', '6', '3', '9', '2', '8', '4', '12', '12', '3', '1', '1', '9', '1', '9', '2', '1', '1', '1', '1', '1', '9', '2', '1', '2', '10', '9', '8', '8', '10', '8', '2', '3', '2', '1', '12', '8', '12', '2', '9', '1', '3', '2', '5', '2', '2', '8', '2', '2', '4', '10', '9', '10', '9', '4', '2', '4', '12', '8', '2', '1', '8', '3', '9', '2', '9', '4', '1', '1', '1', '1', '1', '9', '6', '2', '9', '2', '1', '3', '2', '2', '5', '8', '9', '1', '6', '3', '1', '2', '2', '2', '6', '1', '8', '10', '8', '3', '3', '13', '2', '9', '9', '10', '6', '12', '8', '2', '9', '2', '3', '8', '8', '1', '2', '2', '3', '2', '10', '1', '8', '9', '1', '8', '9', '8', '8', '2', '10', '2', '1', '1', '1', '9', '9', '12', '1', '1', '4', '8', '3', '2', '2', '4', '4', '2', '2', '1', '1', '1', '9', '2', '2', '4', '1', '1', '8', '8', '8', '9', '2', '13', '9', '9', '4', '1', '9', '7', '10', '10', '8', '1', '9', '1', '1', '1', '8', '12', '4', '1', '2', '1', '1', '1', '7', '8', '3', '3', '1', '2', '2', '7', '2', '2', '10', '1', '8', '4', '0', '1', '9', '4', '1', '1', '2', '10', '10', '7', '9', '3', '12', '11', '2', '8', '10', '8', '9', '4', '3', '4', '10', '1', '1', '9', '3', '10', '1', '5', '3', '3', '2', '2', '1', '1', '6', '1', '7', '1', '1', '12', '1', '1', '1', '10', '1', '8', '8', '1', '3', '8', '3', '1', '2', '8', '3', '4', '2', '8', '8', '6', '1', '1', '4', '1', '2', '9', '5', '1', '7', '8', '9', '2', '4', '9', '8', '5', '9', '9', '9', '1', '2', '1', '3', '8', '9', '2', '9', '8', '9', '1', '8', '13', '9', '3', '8', '1', '4', '1', '3', '1', '6', '4', '10', '2', '2', '7', '8', '8', '12', '8', '9', '9', '9', '10', '3', '12', '12', '2', '9', '10', '9', '7', '2', '3', '4', '10', '10', '2', '7', '7', '1', '7', '3', '9', '1', '9', '8', '2', '9', '1', '8', '1', '10', '8', '8', '2', '7', '8', '1', '8', '9', '8', '1', '4', '1', '8', '8', '8', '1', '1', '10', '3', '2', '2', '6', '8', '9', '8', '2', '1', '1', '3', '8', '8', '1', '4', '4', '3', '9', '10', '4', '2', '4', '2', '9', '2', '2', '9', '1', '1', '10', '1', '1', '2', '1', '1', '1', '9', '1', '8', '8', '8', '2', '3', '8', '1', '6', '7', '3', '1', '9', '1', '2', '1', '6', '1', '2', '10', '1', '4', '2', '3', '2', '9', '9', '4', '9', '9', '1', '2', '8', '4', '7', '8', '7', '13', '9', '1', '2', '1', '9', '3', '3', '6', '8', '9', '10', '9', '2', '2', '3', '12', '1', '1', '1', '13', '2', '1', '7', '10', '8', '9', '1', '2', '9', '1', '1', '1', '2', '1', '12', '5', '6', '9', '10', '3', '1', '10', '1', '3', '2', '8', '9', '2', '10', '8', '8', '9', '2', '8', '9', '2', '2', '2', '8', '8', '2', '3', '1', '4', '8', '1', '9', '9', '2', '8', '10', '9', '1', '2', '12', '8', '8', '0', '2', '1', '1', '9', '10', '1', '6', '2', '2', '10', '2', '2', '4', '2', '2', '12', '1', '6', '7', '8', '9', '1', '3', '5', '7', '3', '1', '3', '1', '1', '3', '2', '6', '3', '2', '1', '8', '3', '5', '2', '1', '1', '8', '1', '1', '0', '2', '3', '5', '3', '1', '1', '9', '8', '8', '8', '8', '4', '7', '2', '9', '12', '5', '9', '3', '12', '3', '9', '1', '9', '1', '7', '3', '9', '3', '10', '1', '2', '1', '4', '9', '8', '2', '9', '11', '2', '8', '9', '4', '1', '1', '1', '1', '1', '1', '1', '9', '1', '9', '1', '1', '1', '12', '3', '10', '3', '6', '1', '7', '10', '8', '3', '7', '1', '1', '2', '6', '1', '3', '9', '2', '8', '1', '8', '8', '1', '8', '10', '12', '1', '10', '12', '10', '1', '8', '8', '1', '4', '7', '9', '2', '1', '9', '3', '8', '12', '10', '6', '1', '6', '8', '3', '1', '3', '1', '10', '10', '9', '8', '1', '2', '9', '8', '8', '1', '9', '8', '8', '3', '1', '3', '9', '12', '1', '8', '1', '5', '8', '11', '5', '5', '1', '2', '1', '3', '1', '1', '1', '9', '8', '8', '1', '9', '10', '8', '4', '1', '1', '8', '10', '8', '9', '1', '10', '1', '7', '2', '1', '1', '9', '6', '2', '9', '8', '1', '1', '1', '9', '8', '8', '1', '9', '9', '1', '1', '2', '7', '9', '2', '9', '9', '8', '7', '6', '8', '7', '8', '2', '9', '2', '1', '8', '8', '8', '2', '6', '3', '1', '8', '12', '12', '8', '7', '1', '2', '2', '7', '1', '9', '8', '1', '4', '1', '1', '8', '5', '8', '1', '8', '8', '8', '8', '1', '2', '11', '1', '1', '1', '2', '7', '1', '9', '2', '2', '2', '9', '8', '9', '2', '9', '1', '8', '1', '7', '11', '13', '1', '9', '8', '2', '2', '1', '2', '3', '10', '3', '10', '4', '3', '9', '1', '8', '1', '1', '13', '1', '1', '3', '8', '1', '2', '2', '2', '9', '4', '1', '8', '1', '9', '3', '6', '8', '5', '2', '8', '2', '8', '1', '9', '2', '2', '8', '1', '1', '4', '8', '9', '2', '2', '7', '1', '8', '12', '2', '12', '8', '2', '9', '9', '3', '8', '1', '1', '9', '9', '9', '2', '8', '1', '9', '1', '8', '9', '8', '2', '2', '4', '1', '9', '10', '10', '8', '8', '1', '1', '2', '1', '4', '1', '2', '1', '1', '3', '12', '8', '8', '8', '8', '10', '2', '8', '12', '1', '9', '9', '8', '9', '1', '2', '1', '8', '8', '8', '2', '8', '8', '3', '10', '8', '9', '1', '1', '1', '3', '4', '8', '10', '6', '3', '1', '3', '2', '8', '9', '3', '5', '4', '1', '5', '2', '9', '9', '9', '1', '1', '1', '9', '9', '6', '10', '9', '8', '12', '2', '9', '1', '2', '1', '1', '1', '8', '1', '12', '1', '12', '1', '9', '1', '8', '1', '2', '1', '2', '8', '8', '10', '1', '9', '1', '2', '2', '8', '8', '3', '12', '1', '11', '2', '10', '12', '11', '2', '1', '10', '1', '1', '9', '3', '10', '2', '7', '1', '8', '1', '9', '9', '2', '1', '3', '12', '5', '9', '9', '8', '1', '8', '8', '8', '1', '1', '3', '9', '8', '9', '8', '3', '10', '3', '7', '8', '9', '2', '3', '1', '9', '10', '9', '2', '8', '2', '6', '4', '1', '1', '3', '8', '2', '3', '9', '1', '2', '1', '8', '1', '2', '2', '2', '2', '9', '9', '4', '8', '9', '1', '1', '2', '9', '1', '5', '2', '9', '8', '10', '1', '2', '10', '8', '5', '6', '4', '8', '1', '1', '1', '8', '9', '2', '8', '8', '8', '12', '2', '2', '1', '8', '1', '2', '1', '9', '8', '8', '9', '1', '1', '8', '7', '1', '8', '0', '2', '3', '8', '1', '1', '8', '1', '1', '12', '3', '2', '10', '8', '10', '6', '1', '8', '8', '10', '8', '8', '1', '4', '8', '1', '2', '9', '8', '1', '1', '3', '3', '5', '1', '1', '2', '1', '2', '1', '9', '8', '3', '9', '8', '2', '10', '9', '1', '8', '1', '10', '9', '10', '1', '2', '3', '8', '1', '3', '1', '9', '9', '8', '1', '9', '8', '8', '9', '1', '9', '2', '8', '8', '2', '13', '8', '10', '8', '9', '3', '2', '1', '3', '1', '12', '10', '10', '1', '11', '1', '2', '4', '2', '10', '1', '8', '11', '1', '1', '1', '2', '2', '8', '2', '9', '8', '9', '9', '12', '8', '1', '9', '2', '4', '1', '8', '3', '9', '1', '6', '5', '8', '9', '3', '3', '2', '1', '1', '1', '8', '11', '1', '8', '7', '1', '11', '9', '1', '7', '9', '9', '8', '8', '8', '12', '8', '1', '2', '9', '8', '8', '2', '10', '9', '8', '8', '4', '10', '9', '8', '2', '10', '10', '2', '1', '2', '1', '2', '1', '4', '1', '7', '1', '1', '3', '12', '9', '8', '5', '9', '10', '1', '9', '9', '2', '7', '4', '1', '1', '8', '12', '8', '2', '2', '9', '4', '1', '1', '5', '9', '1', '8', '12', '8', '1', '1', '4', '9', '10', '2', '3', '1', '3', '3', '3', '8', '1', '2', '1', '2', '1', '2', '9', '1', '2', '8', '9', '4', '8', '8', '10', '2', '12', '5', '5', '1', '8', '1', '7', '8', '1', '1', '8', '9', '12', '4', '9', '3', '1', '2', '5', '9', '2', '1', '2', '2', '1', '2', '8', '1', '8', '8', '2', '2', '1', '8', '4', '1', '2', '10', '9', '10', '8', '1', '10', '4', '8', '8', '10', '2', '8', '1', '1', '3', '10', '1', '4', '2', '8', '3', '3', '2', '9', '8', '5', '5', '9', '3', '10', '8', '1', '2', '1', '2', '9', '1', '1', '2', '9', '9', '8', '8', '11', '9', '4', '1', '8', '2', '7', '1', '2', '8', '2', '9', '9', '8', '2', '9', '9', '8', '8', '1', '2', '8', '1', '1', '2', '9', '8', '1', '4', '9', '1', '8', '12', '1', '12', '2', '8', '2', '9', '1', '12', '1', '2', '9', '1', '1', '9', '3', '2', '9', '9', '2', '11', '8', '7', '9', '9', '9', '8', '8', '1', '2', '8', '1', '1', '4', '1', '2', '10', '1', '9', '2', '1', '1', '1', '9', '1', '13', '4', '3', '2', '1', '1', '2', '2', '7', '8', '7', '1', '1', '2', '8', '8', '3', '4', '8', '2', '10', '13', '8', '8', '9', '2', '2', '1', '1', '10', '4', '2', '7', '9', '8', '2', '1', '9', '8', '1', '1', '9', '8', '9', '8', '2', '8', '2', '2', '9', '2', '1', '9', '1', '2', '4', '8', '2', '1', '1', '8', '1', '4', '1', '9', '3', '9', '2', '7', '1', '9', '6', '1', '10', '2', '2', '2', '2', '2', '10', '10', '10', '9', '9', '9', '3', '12', '10', '1', '1', '10', '1', '1', '2', '2', '1', '2', '3', '12', '8', '8', '1', '2', '9', '9', '1', '1', '10', '8', '9', '8', '3', '1', '1', '3', '1', '10', '1', '1', '1', '4', '1', '1', '1', '7', '10', '2', '1', '8', '1', '9', '3', '1', '10', '8', '8', '1', '5', '9', '1', '2', '1', '8', '8', '1', '3', '1', '10', '2', '1', '1', '2', '8', '2', '5', '3', '5', '2', '1', '1', '9', '1', '7', '9', '9', '2', '8', '1', '12', '4', '1', '4', '9', '9', '4', '8', '1', '10', '10', '8', '8', '8', '9', '2', '3', '5', '1', '8', '1', '1', '1', '7', '10', '1', '4', '12', '3', '2', '2', '9', '1', '1', '1', '2', '8', '4', '1', '7', '3', '12', '8', '6', '2', '2', '7', '9', '11', '1', '10', '9', '1', '8', '12', '2', '11', '1', '2', '3', '1', '1', '1', '8', '9', '2', '2', '2', '2', '3', '3', '8', '10', '4', '1', '2', '9', '8', '2', '2', '9', '1', '8', '11', '4', '2', '8', '7', '1', '1', '7', '3', '9', '9', '4', '5', '8', '10', '2', '9', '9', '9', '8', '1', '9', '2', '2', '2', '1', '2', '9', '4', '3', '12', '4', '3', '2', '3', '8', '3', '10', '1', '10', '1', '1', '8', '10', '6', '8', '9', '9', '1', '2', '9', '2', '9', '3', '8', '1', '1', '12', '1', '5', '1', '10', '8', '10', '2', '7', '1', '1', '1', '1', '3', '2', '3', '5', '9', '1', '2', '1', '9', '8', '10', '9', '8', '1', '8', '1', '8', '2', '8', '1', '2', '8', '1', '2', '5', '8', '12', '2', '1', '1', '1', '1', '1', '8', '8', '2', '1', '4', '2', '8', '8', '8', '2', '9', '9', '11', '1', '2', '9', '3', '1', '1', '8', '9', '2', '4', '10', '1', '9', '8', '4', '9', '8', '10', '8', '8', '9', '2', '8', '9', '3', '3', '3', '4', '3', '2', '2', '10', '8', '2', '1', '5', '1', '9', '1', '1', '2', '1', '2', '3', '1', '1', '8', '8', '1', '10', '8', '8', '1', '6', '4', '8', '2', '5', '8', '1', '3', '8', '2', '8', '9', '1', '1', '8', '12', '10', '1', '5', '8', '2', '8', '10', '9', '9', '1', '6', '9', '1', '10', '8', '2', '9', '10', '1', '2', '1', '1', '8', '8', '3', '9', '8', '1', '10', '2', '8', '1', '10', '1', '5', '1', '1', '1', '5', '1', '1', '1', '4', '1', '1', '1', '8', '2', '8', '1', '8', '3', '8', '9', '1', '8', '1', '8', '1', '1', '2', '2', '1', '12', '9', '9', '1', '8', '2', '1', '2', '8', '1', '9', '1', '1', '2', '1', '2', '2', '2', '1', '9', '9', '8', '8', '1', '1', '9', '10', '8', '4', '3', '3', '4', '9', '1', '3', '3', '10', '2', '2', '1', '8', '4', '1', '9', '4', '1', '1', '9', '8', '10', '4', '9', '9', '8', '2', '1', '3', '4', '9', '3', '8', '9', '1', '1', '2', '1', '7', '8', '2', '9', '1', '9', '2', '6', '9', '10', '8', '1', '1', '5', '9', '5', '1', '9', '10', '9', '3', '3', '8', '8', '2', '9', '2', '8', '2', '1', '8', '5', '8', '3', '10', '1', '1', '2', '1', '8', '1', '4', '3', '2', '9', '4', '9', '8', '8', '8', '1', '3', '9', '1', '9', '9', '1', '2', '1', '9', '8', '9', '8', '1', '1', '1', '4', '2', '2', '9', '9', '1', '1', '1', '3', '6', '1', '2', '3', '1', '4', '2', '9', '1', '9', '9', '1', '8', '2', '1', '9', '1', '8', '1', '8', '8', '2', '1', '9', '9', '6', '8', '8', '9', '8', '10', '8', '9', '5', '1', '1', '1', '1', '8', '1', '8', '12', '8', '1', '12', '9', '2', '8', '1', '1', '2', '1', '8', '6', '9', '9', '8', '1', '8', '9', '7', '7', '8', '9', '9', '1', '8', '3', '8', '1', '3', '3', '8', '9', '8', '2', '8', '1', '2', '9', '8', '1', '1', '1', '1', '9', '1', '9', '8', '12', '3', '8', '8', '1', '10', '10', '10', '2', '2', '1', '10', '2', '2', '10', '8', '12', '8', '1', '1', '1', '2', '1', '1', '3', '8', '1', '2', '2', '2', '1', '1', '6', '2', '8', '8', '8', '1', '1', '1', '9', '9', '2', '8', '10', '2', '8', '2', '1', '2', '9', '9', '2', '1', '1', '8', '8', '1', '3', '1', '8', '9', '1', '10', '9', '1', '1', '1', '1', '7', '2', '2', '1', '2', '8', '8', '1', '2', '1', '3', '2', '1', '8', '3', '9', '2', '10', '2', '10', '1', '2', '1', '1', '13', '9', '10', '8', '2', '2', '1', '1', '8', '2', '2', '1', '9', '1', '1', '8', '9', '9', '2', '9', '2', '2', '1', '1', '1', '8', '9', '4', '9', '9', '1', '8', '2', '1', '1', '8', '2', '2', '2', '8', '1', '1', '8', '2', '10', '2', '9', '9', '7', '1', '1', '2', '2', '8', '3', '1', '2', '1', '1', '8', '1', '1', '1', '9', '1', '1', '8', '8', '1', '9', '6', '1', '9', '1', '8', '1', '8', '8', '8', '1', '3', '8', '8', '2', '6', '3', '2', '1', '10', '1', '8', '2', '1', '6', '1', '1', '1', '8', '1', '10', '1', '1', '8', '9', '2', '6', '9', '2', '9', '4', '1', '8', '1', '3', '7', '8', '8', '5', '8', '7', '1', '1', '1', '13', '8', '3', '1', '1', '1', '1', '2', '8', '2', '12', '8', '1', '2', '5', '1', '8', '2', '10', '8', '2', '10', '1', '5', '2', '1', '1', '5', '2', '2', '7', '8', '2', '9', '9', '1', '10', '1', '8', '2', '5', '8', '1', '5', '1', '10', '1', '1', '9', '8', '6', '1', '8', '9', '8', '1', '8', '2', '2', '8', '3', '9', '1', '9', '3', '8', '4', '4', '3', '3', '1', '1', '1', '8', '9', '1', '1', '8', '3', '1', '2', '8', '2', '1', '1', '10', '1', '2', '2', '1', '1', '8', '2', '8', '2', '10', '2', '2', '10', '8', '8', '8', '13', '2', '2', '9', '2', '5', '9', '2', '1', '8', '8', '8', '1', '12', '12', '2', '9', '2', '1', '8', '2', '1', '8', '1', '9', '9', '2', '7', '1', '1', '7', '1', '4', '3', '1', '10', '3', '10', '9', '4', '6', '7', '5', '2', '1', '8', '8', '1', '4', '9', '2', '1', '8', '1', '1', '1', '1', '1', '8', '9', '8', '8', '8', '8', '9', '8', '10', '1', '8', '2', '7', '8', '9', '1', '2', '5', '9', '10', '8', '9', '12', '1', '6', '1', '2', '10', '9', '4', '1', '8', '10', '10', '1', '1', '1', '1', '1', '2', '3', '8', '1', '2', '10', '2', '1', '2', '4', '2', '2', '9', '1', '4', '2', '1', '1', '12', '12', '9', '9', '7', '1', '8', '4', '9', '9', '8', '1', '7', '3', '2', '1', '1', '4', '8', '1', '5', '8', '2', '8', '1', '14', '9', '12', '1', '10', '2', '1', '1', '8', '8', '6', '6', '3', '1', '2', '8', '1', '3', '2', '1', '8', '8', '1', '10', '8', '2', '8', '2', '5', '9', '1', '8', '8', '1', '1', '8', '8', '13', '1', '3', '8', '4', '1', '9', '7', '8', '8', '8', '3', '8', '1', '4', '2', '8', '8', '8', '7', '1', '1', '2', '8', '8', '9', '8', '8', '2', '3', '9', '9', '2', '1', '2', '2', '1', '8', '2', '6', '2', '1', '1', '9', '10', '3', '8', '2', '3', '2', '8', '8', '1', '8', '8', '8', '9', '1', '4', '1', '9', '2', '1', '8', '0', '1', '8', '1', '1', '8', '9', '9', '1', '3', '1', '2', '8', '8', '7', '1', '1', '2', '9', '2', '10', '2', '8', '2', '2', '2', '7', '1', '9', '8', '1', '3', '9', '2', '1', '10', '8', '1', '4', '1', '8', '5', '9', '8', '8', '1', '2', '2', '1', '8', '8', '6', '8', '1', '1', '8', '3', '2', '2', '1', '8', '1', '7', '6', '8', '1', '1', '1', '9', '1', '1', '1', '2', '1', '11', '10', '10', '11', '9']\n"
          ]
        }
      ],
      "source": [
        "sc = SupremeCourt()\n",
        "print(sc.info)\n",
        "sc.download()\n",
        "\n",
        "texts = []  # list of text samples\n",
        "labels_index = {}  # dictionary mapping label name to numeric id\n",
        "labels = []  # list of label ids\n",
        "\n",
        "issue_codes = list(sc.issue_area_codes.keys()) # 15 labels\n",
        "print(issue_codes)\n",
        "issue_codes.sort()\n",
        "issue_codes = [str(ic) for ic in issue_codes]\n",
        "\n",
        "labels_index = dict(zip(issue_codes, np.arange(len(issue_codes))))\n",
        "print(labels_index)\n",
        "count=0\n",
        "\n",
        "for record in sc.records():\n",
        "\n",
        "        count=count+1\n",
        "        if record[1]['issue'] == None: # some cases have None as an issue\n",
        "            labels.append(labels_index['-1'])\n",
        "        else:\n",
        "            labels.append(labels_index[record[1]['issue'][:-4]])\n",
        "        \n",
        "        new_sen=record[0].split(\"Footnotes\")[0]\n",
        "        new_new_sen=new_sen.split()\n",
        "        if len(new_new_sen) >= 2048:\n",
        "          new_new_sen=new_new_sen[1536:2048]\n",
        "        \n",
        "        elif len(new_new_sen) < 512:\n",
        "          new_new_sen=new_new_sen[0:len(new_new_sen)]\n",
        "        \n",
        "        else:\n",
        "          new_new_sen=new_new_sen[-512:]\n",
        "          \n",
        "        new_new_sen=' '.join(new_new_sen)\n",
        "\n",
        "        texts.append(new_new_sen)\n",
        "   \n",
        "len_list = [len(ele.split()) for ele in texts]\n",
        "\n",
        "print(labels)\n",
        "print(len(labels))\n",
        "\n",
        "res = 0 if len(len_list) == 0 else (float(sum(len_list)) / len(len_list))\n",
        "print(\"Average Length %s\" % res) \n",
        "print('Found %s texts.' % len(texts))\n",
        "print('Found %s labels.' % len(labels_index))\n",
        "\n",
        "temp_file = open(\"labels_sc.txt\", \"r\")\n",
        "\n",
        "data = temp_file.read()\n",
        "label_list = data.split(\"\\n\")\n",
        "print(label_list)\n",
        "label_list = label_list[0:-1]\n",
        "print(label_list)\n",
        "label_list = [int(i) for i in label_list]\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LprCHRM2aWb8",
        "outputId": "4ebac6d3-54cd-4ee8-fd71-25f635475d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text  label\n",
            "0     held valid run afoul of Rev.Stat. 4888 because...      8\n",
            "1     Mann Act's coverage beyond the congressional i...      1\n",
            "2     within its scope all pipe lines that would car...      8\n",
            "3     ignore the plain import of traditional methods...      2\n",
            "4     the runway sections as they were intermittentl...      8\n",
            "...                                                 ...    ...\n",
            "8414  Opinion reported: Ante, p. 88. DECREE 1. It is...     11\n",
            "8415  325,000. For the purpose of giving effect to t...     10\n",
            "8416  v. California was controlling and emphasizing ...     10\n",
            "8417  passage more recently known as \"middle pass,\" ...     11\n",
            "8418  original jurisdiction. It is similarly clear t...      9\n",
            "\n",
            "[8419 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "summarized_data = pd.DataFrame(texts,\n",
        "               columns =['text'])\n",
        "summarized_data['label'] = label_list\n",
        "print(summarized_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VoY1gHZoaZmG"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    inps = Input(shape = (max_len,), dtype='int64')\n",
        "    masks= Input(shape = (max_len,), dtype='int64')\n",
        "    dbert_layer = dbert_model(inps, attention_mask=masks)[0][:,0,:]\n",
        "    dense_0 = Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))(dbert_layer)\n",
        "    dropout_0= Dropout(0.5)(dense_0)\n",
        "    pred = Dense(15, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout_0)\n",
        "    model = tf.keras.Model(inputs=[inps,masks], outputs=pred)\n",
        "    print(model.summary())\n",
        "    return model   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f0279bcea67f48f5aacb3e949ad232cb",
            "be7f4ca79fe047f4a316266b02761226",
            "5d5ac4ef9f3d4eca8b927714ab4c9d27",
            "77747db1d00646b68c9b86821c07dd6a",
            "61bcd901b2a84f7e98a406b0a3aee3cf",
            "a4997f49e7d747de8d87a1a2792d368f",
            "252efc18da524d27aef5085efae568f9",
            "c518a201d9f84a3eb71b1b825997d1c9",
            "d1a8bfa06f8c44daa0cfb79c08313bd2",
            "4c41439c5bd042e5aace47cf1874c32f",
            "f34bcb2aca164962946d6c4ad660b88b",
            "afb21bd1532e456e897f0d13b2564c54",
            "39ca359ca662458f85d825d36cc4e0f5",
            "a1e1729b3abb4907b9a4372398004370",
            "4588da212dc7446880702a5268800a07",
            "6fd19ba203a54823b6e3713aed3d1070",
            "0bee467370c243d1ab0be0a1f6b6bab4",
            "ef74f2682fd548b88b30e586c11b0ffa",
            "cff85f7aab9f43bc8487863a486599ed",
            "3e4f54436cac422abcd1d3e81fda6ca2",
            "fd68dc88a39f4612a7e7e425f8ce5485",
            "3faf046fe0ca4abeb591300f88a3c955",
            "23058d9e407f4c199374bddace31a5c1",
            "74eff27a7b6b4b2d834ac42841d83f7e",
            "0930f5194617418586cd0d016fd0c234",
            "769133477520492c92979b005158a3ba",
            "efb3212434d442df9a5d3a4fe323451d",
            "11ec92f7df8848129c04a6e0ad531b75",
            "047210907aa6472aa7000c02cd43128f",
            "24ff0e484f8a4213a032f2065e2c2ec6",
            "d10377b6036945628afc004f6670329d",
            "7b46cff03c384d5eac29a6a0586befa8",
            "35e3e7d371324b2e88cfdf1505ea6523",
            "97f5ac6937be48a68e4dd0443cff8cb1",
            "c81edd8aed5d44ee939a56a107ee2a1f",
            "de627a1b72c94d45bb03384911c10799",
            "89da48b91a0642419893ed023977cb33",
            "649a9ea501124b56a20bce6f3c94131b",
            "be4839681fcf4b9f87ae10e144f684c4",
            "0fe6ed72724148649fefcbbee0c20906",
            "28823b5030d94ce08737e5834ad912f1",
            "2d34cc4e64aa494d9c7d7cefd587e96f",
            "288b2d881dde4dd99ac53340c2d2a2e7",
            "1cc2e62aeac649409b562fbdba1ec748"
          ]
        },
        "id": "x9kO4eVwCHKg",
        "outputId": "05d740cc-7052-4b13-9951-9682759a803f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0279bcea67f48f5aacb3e949ad232cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afb21bd1532e456e897f0d13b2564c54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23058d9e407f4c199374bddace31a5c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97f5ac6937be48a68e4dd0443cff8cb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 28 16:39:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    40W / 300W |   1683MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 335s 337ms/step - loss: 7.1571 - accuracy: 0.5687 - val_loss: 6.2451 - val_accuracy: 0.6425\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 320s 338ms/step - loss: 5.5870 - accuracy: 0.7083 - val_loss: 5.1603 - val_accuracy: 0.6900\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 316s 334ms/step - loss: 4.4765 - accuracy: 0.7874 - val_loss: 4.4529 - val_accuracy: 0.6651\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 317s 334ms/step - loss: 3.5466 - accuracy: 0.8581 - val_loss: 3.9005 - val_accuracy: 0.6829\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 316s 334ms/step - loss: 2.7924 - accuracy: 0.9083 - val_loss: 3.4962 - val_accuracy: 0.6793\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.6900237529691211\n",
            "Weighted F1: 0.6815032469045896\n",
            "Micro F1: 0.6900237529691211\n",
            "Weighted Precision: 0.6880278776807328\n",
            "Micro Precision: 0.6900237529691211\n",
            "Weighted Recall: 0.6900237529691211\n",
            "Micro Recall: 0.6900237529691211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 28 17:09:27 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    40W / 300W |  15237MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 335s 338ms/step - loss: 7.0989 - accuracy: 0.5811 - val_loss: 6.1722 - val_accuracy: 0.6425\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 320s 337ms/step - loss: 5.5210 - accuracy: 0.7234 - val_loss: 5.1323 - val_accuracy: 0.6793\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 319s 337ms/step - loss: 4.4164 - accuracy: 0.7944 - val_loss: 4.4162 - val_accuracy: 0.7090\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 316s 333ms/step - loss: 3.5194 - accuracy: 0.8554 - val_loss: 3.8630 - val_accuracy: 0.7067\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 316s 333ms/step - loss: 2.7671 - accuracy: 0.9051 - val_loss: 3.5517 - val_accuracy: 0.6805\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.7090261282660333\n",
            "Weighted F1: 0.7059665439351648\n",
            "Micro F1: 0.7090261282660333\n",
            "Weighted Precision: 0.7097532558363102\n",
            "Micro Precision: 0.7090261282660333\n",
            "Weighted Recall: 0.7090261282660333\n",
            "Micro Recall: 0.7090261282660333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 28 17:39:11 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    40W / 300W |  15237MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 335s 337ms/step - loss: 7.1416 - accuracy: 0.5630 - val_loss: 6.1942 - val_accuracy: 0.6390\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 320s 337ms/step - loss: 5.5518 - accuracy: 0.7111 - val_loss: 5.1381 - val_accuracy: 0.6805\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 316s 333ms/step - loss: 4.4449 - accuracy: 0.7841 - val_loss: 4.4578 - val_accuracy: 0.6793\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 319s 337ms/step - loss: 3.5495 - accuracy: 0.8513 - val_loss: 3.8788 - val_accuracy: 0.7102\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 316s 333ms/step - loss: 2.8043 - accuracy: 0.9043 - val_loss: 3.5204 - val_accuracy: 0.6758\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.7102137767220903\n",
            "Weighted F1: 0.7012445046257646\n",
            "Micro F1: 0.7102137767220903\n",
            "Weighted Precision: 0.7067611235115892\n",
            "Micro Precision: 0.7102137767220903\n",
            "Weighted Recall: 0.7102137767220903\n",
            "Micro Recall: 0.7102137767220903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 28 18:08:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    40W / 300W |  15237MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 335s 337ms/step - loss: 7.1580 - accuracy: 0.5709 - val_loss: 6.2949 - val_accuracy: 0.6532\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 319s 337ms/step - loss: 5.6657 - accuracy: 0.7147 - val_loss: 5.2533 - val_accuracy: 0.6781\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 319s 337ms/step - loss: 4.5739 - accuracy: 0.7861 - val_loss: 4.5187 - val_accuracy: 0.6900\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 319s 337ms/step - loss: 3.6488 - accuracy: 0.8547 - val_loss: 3.9744 - val_accuracy: 0.7162\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 316s 333ms/step - loss: 2.8962 - accuracy: 0.9004 - val_loss: 3.6371 - val_accuracy: 0.6532\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.7161520190023754\n",
            "Weighted F1: 0.7059789154791624\n",
            "Micro F1: 0.7161520190023754\n",
            "Weighted Precision: 0.7136326865793133\n",
            "Micro Precision: 0.7161520190023754\n",
            "Weighted Recall: 0.7161520190023754\n",
            "Micro Recall: 0.7161520190023754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 28 18:38:44 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    40W / 300W |  15237MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 336s 338ms/step - loss: 7.1408 - accuracy: 0.5711 - val_loss: 6.2268 - val_accuracy: 0.6449\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 320s 338ms/step - loss: 5.5925 - accuracy: 0.7139 - val_loss: 5.1868 - val_accuracy: 0.6758\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 320s 338ms/step - loss: 4.4834 - accuracy: 0.7896 - val_loss: 4.4690 - val_accuracy: 0.6876\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 320s 338ms/step - loss: 3.5747 - accuracy: 0.8536 - val_loss: 3.9792 - val_accuracy: 0.6960\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 317s 334ms/step - loss: 2.8167 - accuracy: 0.9062 - val_loss: 3.4804 - val_accuracy: 0.6793\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.6959619952494062\n",
            "Weighted F1: 0.6878808224744642\n",
            "Micro F1: 0.6959619952494062\n",
            "Weighted Precision: 0.6953062476857206\n",
            "Micro Precision: 0.6959619952494062\n",
            "Weighted Recall: 0.6959619952494062\n",
            "Micro Recall: 0.6959619952494062\n",
            "Average Accuracy: 0.7042755344418052\n",
            "Average Weighted F1: 0.6965148066838291\n",
            "Average Micro F1: 0.7042755344418052\n",
            "Average Weighted Precision: 0.7026962382587332\n",
            "Average Micro Precision: 0.7042755344418052\n",
            "Average Weighted Recall: 0.7042755344418052\n",
            "Average Micro Recall: 0.7042755344418052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "total_accuracy=0\n",
        "total_weighted_f1=0\n",
        "total_micro_f1=0\n",
        "total_weighted_precision=0\n",
        "total_micro_precision=0\n",
        "total_weighted_recall=0\n",
        "total_micro_recall=0\n",
        "\n",
        "for i in range(5):\n",
        "  gc.collect()\n",
        "  tf.keras.backend.clear_session()\n",
        "  dbert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "  dbert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "  max_len=512\n",
        "  sentences=summarized_data['text']\n",
        "  labels=summarized_data['label']\n",
        "  len(sentences),len(labels)\n",
        "  model_0=create_model()\n",
        "  input_ids=[]\n",
        "  attention_masks=[]\n",
        "\n",
        "  for sent in sentences:\n",
        "    dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
        "    input_ids.append(dbert_inps['input_ids'])\n",
        "    attention_masks.append(dbert_inps['attention_mask'])\n",
        "  input_ids=np.asarray(input_ids)\n",
        "\n",
        "  attention_masks=np.array(attention_masks)\n",
        "  labels=np.array(labels)\n",
        "  train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.1,random_state=42)\n",
        "  log_dir='dbert_model'\n",
        "\n",
        "  model_save_path='./drive/MyDrive/Best-512/best-512-1536-2048-'+str(i)+'-15labels.h5'\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "  callbacks= [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,monitor='val_accuracy',mode='max',save_best_only=True,save_weights_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
        "  model_0.compile(loss=loss,optimizer=optimizer, metrics=[accuracy])\n",
        "  gpu_info = !nvidia-smi\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "  else:\n",
        "    print(gpu_info)\n",
        "  history=model_0.fit([train_inp,train_mask],train_label,batch_size=8,epochs=5,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)\n",
        "  pred_labels=[]\n",
        "\n",
        "  model_saved= create_model()\n",
        "  model_saved.compile(loss=loss,optimizer=optimizer, metrics=[accuracy])\n",
        "  model_saved.load_weights('./drive/MyDrive/Best-512/best-512-1536-2048-'+str(i)+'-15labels.h5')\n",
        "\n",
        "  for i in range(0,len(val_inp)):\n",
        "    pred=model_saved.predict([val_inp[i].reshape(1,512),val_mask[i].reshape(1,512)])\n",
        "    pred_label = pred.argmax(axis=1)\n",
        "    pred_labels.append(pred_label)\n",
        "  accuracy=accuracy_score(val_label, pred_labels)\n",
        "  print(\"Accuracy: \"+str(accuracy))\n",
        "  total_accuracy=total_accuracy+accuracy\n",
        "  \n",
        "  weighted_f1=f1_score(val_label,pred_labels, average='weighted')\n",
        "  print(\"Weighted F1: \"+ str(weighted_f1))\n",
        "  total_weighted_f1=total_weighted_f1+weighted_f1\n",
        "  micro_f1=f1_score(val_label,pred_labels, average='micro')\n",
        "  print(\"Micro F1: \"+ str(micro_f1))\n",
        "  total_micro_f1=total_micro_f1+micro_f1\n",
        "\n",
        "  weighted_precision=precision_score(val_label, pred_labels, average='weighted')\n",
        "  print(\"Weighted Precision: \" + str(weighted_precision))\n",
        "  total_weighted_precision=total_weighted_precision+weighted_precision\n",
        "  micro_precision=precision_score(val_label, pred_labels, average='micro')\n",
        "  print(\"Micro Precision: \" + str(micro_precision))\n",
        "  total_micro_precision=total_micro_precision+micro_precision\n",
        "\n",
        "  weighted_recall=recall_score(val_label, pred_labels, average='weighted')\n",
        "  print(\"Weighted Recall: \" + str(weighted_recall))\n",
        "  total_weighted_recall=total_weighted_recall+weighted_recall\n",
        "  micro_recall=recall_score(val_label, pred_labels, average='micro')\n",
        "  print(\"Micro Recall: \" + str(micro_recall))\n",
        "  total_micro_recall=total_micro_recall+micro_recall\n",
        "\n",
        "\n",
        "print(\"Average Accuracy: \"+str(total_accuracy/5))\n",
        "print(\"Average Weighted F1: \"+str(total_weighted_f1/5))\n",
        "print(\"Average Micro F1: \"+str(total_micro_f1/5))\n",
        "print(\"Average Weighted Precision: \"+str(total_weighted_precision/5))\n",
        "print(\"Average Micro Precision: \"+str(total_micro_precision/5))\n",
        "print(\"Average Weighted Recall: \"+str(total_weighted_recall/5))\n",
        "print(\"Average Micro Recall: \"+str(total_micro_recall/5))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Best-512_1536:2048_15labels.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f0279bcea67f48f5aacb3e949ad232cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be7f4ca79fe047f4a316266b02761226",
              "IPY_MODEL_5d5ac4ef9f3d4eca8b927714ab4c9d27",
              "IPY_MODEL_77747db1d00646b68c9b86821c07dd6a"
            ],
            "layout": "IPY_MODEL_61bcd901b2a84f7e98a406b0a3aee3cf"
          }
        },
        "be7f4ca79fe047f4a316266b02761226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4997f49e7d747de8d87a1a2792d368f",
            "placeholder": "​",
            "style": "IPY_MODEL_252efc18da524d27aef5085efae568f9",
            "value": "Downloading: 100%"
          }
        },
        "5d5ac4ef9f3d4eca8b927714ab4c9d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c518a201d9f84a3eb71b1b825997d1c9",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1a8bfa06f8c44daa0cfb79c08313bd2",
            "value": 231508
          }
        },
        "77747db1d00646b68c9b86821c07dd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c41439c5bd042e5aace47cf1874c32f",
            "placeholder": "​",
            "style": "IPY_MODEL_f34bcb2aca164962946d6c4ad660b88b",
            "value": " 226k/226k [00:00&lt;00:00, 598kB/s]"
          }
        },
        "61bcd901b2a84f7e98a406b0a3aee3cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4997f49e7d747de8d87a1a2792d368f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "252efc18da524d27aef5085efae568f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c518a201d9f84a3eb71b1b825997d1c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a8bfa06f8c44daa0cfb79c08313bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c41439c5bd042e5aace47cf1874c32f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f34bcb2aca164962946d6c4ad660b88b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afb21bd1532e456e897f0d13b2564c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39ca359ca662458f85d825d36cc4e0f5",
              "IPY_MODEL_a1e1729b3abb4907b9a4372398004370",
              "IPY_MODEL_4588da212dc7446880702a5268800a07"
            ],
            "layout": "IPY_MODEL_6fd19ba203a54823b6e3713aed3d1070"
          }
        },
        "39ca359ca662458f85d825d36cc4e0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bee467370c243d1ab0be0a1f6b6bab4",
            "placeholder": "​",
            "style": "IPY_MODEL_ef74f2682fd548b88b30e586c11b0ffa",
            "value": "Downloading: 100%"
          }
        },
        "a1e1729b3abb4907b9a4372398004370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cff85f7aab9f43bc8487863a486599ed",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e4f54436cac422abcd1d3e81fda6ca2",
            "value": 28
          }
        },
        "4588da212dc7446880702a5268800a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd68dc88a39f4612a7e7e425f8ce5485",
            "placeholder": "​",
            "style": "IPY_MODEL_3faf046fe0ca4abeb591300f88a3c955",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.13kB/s]"
          }
        },
        "6fd19ba203a54823b6e3713aed3d1070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bee467370c243d1ab0be0a1f6b6bab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef74f2682fd548b88b30e586c11b0ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cff85f7aab9f43bc8487863a486599ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e4f54436cac422abcd1d3e81fda6ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd68dc88a39f4612a7e7e425f8ce5485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3faf046fe0ca4abeb591300f88a3c955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23058d9e407f4c199374bddace31a5c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74eff27a7b6b4b2d834ac42841d83f7e",
              "IPY_MODEL_0930f5194617418586cd0d016fd0c234",
              "IPY_MODEL_769133477520492c92979b005158a3ba"
            ],
            "layout": "IPY_MODEL_efb3212434d442df9a5d3a4fe323451d"
          }
        },
        "74eff27a7b6b4b2d834ac42841d83f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11ec92f7df8848129c04a6e0ad531b75",
            "placeholder": "​",
            "style": "IPY_MODEL_047210907aa6472aa7000c02cd43128f",
            "value": "Downloading: 100%"
          }
        },
        "0930f5194617418586cd0d016fd0c234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24ff0e484f8a4213a032f2065e2c2ec6",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d10377b6036945628afc004f6670329d",
            "value": 570
          }
        },
        "769133477520492c92979b005158a3ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b46cff03c384d5eac29a6a0586befa8",
            "placeholder": "​",
            "style": "IPY_MODEL_35e3e7d371324b2e88cfdf1505ea6523",
            "value": " 570/570 [00:00&lt;00:00, 19.9kB/s]"
          }
        },
        "efb3212434d442df9a5d3a4fe323451d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11ec92f7df8848129c04a6e0ad531b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "047210907aa6472aa7000c02cd43128f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24ff0e484f8a4213a032f2065e2c2ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d10377b6036945628afc004f6670329d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b46cff03c384d5eac29a6a0586befa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35e3e7d371324b2e88cfdf1505ea6523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97f5ac6937be48a68e4dd0443cff8cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c81edd8aed5d44ee939a56a107ee2a1f",
              "IPY_MODEL_de627a1b72c94d45bb03384911c10799",
              "IPY_MODEL_89da48b91a0642419893ed023977cb33"
            ],
            "layout": "IPY_MODEL_649a9ea501124b56a20bce6f3c94131b"
          }
        },
        "c81edd8aed5d44ee939a56a107ee2a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be4839681fcf4b9f87ae10e144f684c4",
            "placeholder": "​",
            "style": "IPY_MODEL_0fe6ed72724148649fefcbbee0c20906",
            "value": "Downloading: 100%"
          }
        },
        "de627a1b72c94d45bb03384911c10799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28823b5030d94ce08737e5834ad912f1",
            "max": 536063208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d34cc4e64aa494d9c7d7cefd587e96f",
            "value": 536063208
          }
        },
        "89da48b91a0642419893ed023977cb33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_288b2d881dde4dd99ac53340c2d2a2e7",
            "placeholder": "​",
            "style": "IPY_MODEL_1cc2e62aeac649409b562fbdba1ec748",
            "value": " 511M/511M [00:08&lt;00:00, 66.1MB/s]"
          }
        },
        "649a9ea501124b56a20bce6f3c94131b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be4839681fcf4b9f87ae10e144f684c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fe6ed72724148649fefcbbee0c20906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28823b5030d94ce08737e5834ad912f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d34cc4e64aa494d9c7d7cefd587e96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "288b2d881dde4dd99ac53340c2d2a2e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cc2e62aeac649409b562fbdba1ec748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}