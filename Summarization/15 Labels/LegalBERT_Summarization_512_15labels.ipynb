{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCIR7rd5h9fv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "#drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')\n",
        "#drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k8FHrSIiqDo",
        "outputId": "001e9530-1339-498b-e042-b8c4a19289dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 14.7 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 84.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 85.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 14.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 489.6 MB 19 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.14.1)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 87.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.21.6)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 94.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (14.0.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Collecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.37.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (4.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.25.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.46.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "Successfully installed gast-0.4.0 keras-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.4.0-py3-none-any.whl (574 kB)\n",
            "\u001b[K     |████████████████████████████████| 574 kB 15.4 MB/s \n",
            "\u001b[?25hCollecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 85.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.64.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from stanza) (4.19.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.11.0+cu113)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (4.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (3.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (0.6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (4.11.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->stanza) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->stanza) (3.8.0)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=953f7cee26e402031aa678e2edfbe3aedbf2695e6f90037ec55d7cf0828c6880\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-1.7.0 stanza-1.4.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Collecting textacy\n",
            "  Downloading textacy-0.11.0-py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 13.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.4.1)\n",
            "Collecting pyphen>=0.10.0\n",
            "  Downloading pyphen-0.12.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 88.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.23.0)\n",
            "Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.2.4)\n",
            "Collecting jellyfish>=0.8.0\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 79.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.21.6)\n",
            "Collecting cytoolz>=0.10.1\n",
            "  Downloading cytoolz-0.11.2.tar.gz (481 kB)\n",
            "\u001b[K     |████████████████████████████████| 481 kB 66.0 MB/s \n",
            "\u001b[?25hCollecting spacy>=3.0.0\n",
            "  Downloading spacy-3.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 61.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.6.3)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.64.0)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz>=0.10.1->textacy) (0.11.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.0->textacy) (3.1.0)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 62.9 MB/s \n",
            "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 75.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (57.4.0)\n",
            "Collecting thinc<8.1.0,>=8.0.14\n",
            "  Downloading thinc-8.0.16-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n",
            "\u001b[K     |████████████████████████████████| 660 kB 72.6 MB/s \n",
            "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.9\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (21.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.9.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.0.6)\n",
            "Collecting typing-extensions<4.0.0.0,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3\n",
            "  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
            "\u001b[K     |████████████████████████████████| 457 kB 91.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.0.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.0->textacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0.0->textacy) (3.0.9)\n",
            "Collecting smart-open<6.0.0,>=5.0.0\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.0.0->textacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.0.0->textacy) (2.0.1)\n",
            "Building wheels for collected packages: cytoolz, jellyfish\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.11.2-cp37-cp37m-linux_x86_64.whl size=1236693 sha256=3295112e94ac8f8f94dc4d57c4692559e29901317b22805a788ea9429ccddfbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/70/71/ca13ea3d36ccd0b3d0ec7d7a4ca67522048d695b556bba4f59\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=73974 sha256=66356ff04eb998397847341d83048ce8f29d0fb3baab165594c882fe6b8e2e07\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "Successfully built cytoolz jellyfish\n",
            "Installing collected packages: typing-extensions, catalogue, typer, srsly, smart-open, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy, pyphen, jellyfish, cytoolz, textacy\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 6.0.0\n",
            "    Uninstalling smart-open-6.0.0:\n",
            "      Successfully uninstalled smart-open-6.0.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.7 cytoolz-0.11.2 jellyfish-0.9.0 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 pyphen-0.12.0 smart-open-5.2.1 spacy-3.3.0 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 textacy-0.11.0 thinc-8.0.16 typer-0.4.1 typing-extensions-3.10.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install tensorflow==2.7.0\n",
        "!pip install stanza\n",
        "!pip install transformers\n",
        "!pip install tensorflow-addons\n",
        "!pip install nltk\n",
        "!pip install textacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0rs0NoritMk",
        "outputId": "b4aba292-cd74-48f3-a4f2-5aaf3a524ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wYwcFK5gixXz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from textacy.datasets.supreme_court import SupremeCourt\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "import nltk\n",
        "#from transformers import pipeline\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense,Dropout, Input, BatchNormalization\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras import regularizers\n",
        "#from transformers import *\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "import numpy as np\n",
        "import gc\n",
        "import math\n",
        "import json\n",
        "import stanza\n",
        "from tensorflow.keras import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import *\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import TFRobertaModel,RobertaTokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.initializers import RandomUniform\n",
        "\n",
        "from numpy.random import seed\n",
        "import random as python_random\n",
        "import os\n",
        "import sys\n",
        "\n",
        "np.random.seed(1)\n",
        "python_random.seed(1)\n",
        "tf.random.set_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jrwKSatri3Lh"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/Summarization/summarized_usdb.txt\" \"./summarized_usdb.txt\"\n",
        "!cp \"/content/drive/My Drive/labels_sc.txt\" \"./labels_sc.txt\"\n",
        "!cp \"/content/drive/My Drive/labels_sc_279.txt\" \"./labels_sc_279.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZinwFiui-A3",
        "outputId": "c985ee24-34cf-4e04-87f6-cb6488e6bf44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Length 389.2275804727402\n",
            "['8', '1', '8', '2', '8', '8', '8', '9', '7', '8', '1', '2', '1', '1', '8', '4', '8', '8', '12', '3', '3', '7', '3', '12', '1', '8', '8', '8', '8', '8', '8', '8', '1', '9', '5', '9', '9', '9', '11', '8', '8', '8', '4', '8', '8', '8', '8', '1', '3', '9', '3', '7', '1', '2', '9', '9', '7', '8', '8', '1', '10', '7', '8', '8', '9', '8', '7', '9', '9', '12', '7', '2', '8', '1', '11', '11', '1', '7', '7', '12', '1', '9', '8', '10', '12', '7', '8', '2', '8', '9', '9', '1', '8', '9', '1', '7', '12', '10', '10', '10', '8', '3', '7', '9', '8', '9', '1', '8', '8', '2', '7', '2', '9', '9', '11', '8', '8', '12', '12', '7', '8', '12', '4', '9', '3', '1', '12', '1', '1', '8', '8', '3', '8', '8', '8', '8', '9', '1', '8', '8', '10', '1', '8', '2', '8', '8', '7', '3', '8', '2', '4', '4', '9', '8', '10', '12', '12', '1', '1', '9', '1', '1', '1', '8', '2', '2', '8', '1', '1', '2', '2', '1', '2', '8', '1', '9', '9', '8', '8', '4', '2', '9', '9', '8', '3', '4', '3', '1', '8', '8', '2', '1', '9', '7', '8', '8', '1', '12', '3', '8', '2', '4', '2', '9', '12', '1', '4', '1', '8', '8', '8', '2', '2', '8', '9', '8', '8', '8', '10', '9', '8', '7', '9', '1', '1', '9', '4', '2', '4', '2', '2', '1', '7', '8', '11', '11', '3', '9', '2', '4', '8', '9', '1', '8', '1', '1', '4', '9', '1', '1', '8', '8', '2', '1', '8', '4', '2', '8', '9', '8', '8', '2', '8', '8', '8', '7', '1', '1', '1', '2', '1', '1', '8', '7', '8', '8', '12', '2', '12', '12', '8', '10', '12', '8', '3', '3', '12', '10', '1', '8', '12', '1', '8', '8', '2', '8', '4', '7', '8', '7', '10', '8', '10', '9', '8', '12', '12', '1', '8', '8', '3', '8', '8', '8', '8', '8', '1', '9', '8', '11', '1', '1', '1', '9', '8', '1', '9', '2', '3', '11', '8', '9', '9', '9', '2', '1', '8', '8', '9', '7', '1', '4', '9', '4', '8', '8', '4', '8', '12', '9', '4', '8', '2', '10', '10', '10', '8', '9', '9', '8', '8', '12', '7', '1', '8', '8', '8', '4', '1', '1', '1', '1', '1', '1', '8', '1', '9', '8', '9', '9', '4', '8', '12', '9', '8', '8', '2', '8', '8', '8', '6', '9', '8', '3', '7', '8', '8', '4', '12', '8', '8', '9', '12', '12', '9', '8', '2', '9', '2', '3', '1', '12', '8', '10', '9', '9', '9', '10', '10', '3', '8', '12', '1', '4', '2', '1', '10', '8', '2', '8', '4', '8', '9', '1', '9', '9', '10', '10', '1', '4', '9', '2', '4', '9', '1', '1', '3', '10', '3', '3', '8', '7', '3', '8', '9', '9', '12', '4', '8', '12', '2', '2', '4', '1', '9', '9', '4', '1', '4', '2', '8', '12', '2', '3', '10', '10', '9', '8', '9', '9', '1', '12', '8', '8', '8', '12', '4', '1', '8', '8', '1', '9', '8', '8', '2', '1', '8', '9', '8', '3', '3', '3', '1', '8', '8', '9', '1', '10', '9', '9', '9', '9', '5', '9', '9', '8', '8', '8', '8', '8', '8', '8', '8', '11', '12', '8', '8', '1', '8', '9', '11', '2', '2', '2', '2', '3', '1', '2', '2', '8', '2', '4', '9', '1', '2', '9', '8', '2', '8', '9', '9', '3', '10', '9', '9', '2', '8', '9', '8', '12', '12', '1', '3', '8', '8', '8', '2', '7', '7', '7', '7', '3', '9', '1', '9', '8', '9', '9', '1', '1', '1', '2', '9', '9', '9', '11', '1', '8', '8', '9', '1', '9', '8', '8', '8', '1', '1', '8', '7', '1', '1', '8', '8', '9', '4', '4', '8', '2', '2', '8', '8', '8', '8', '8', '8', '11', '8', '2', '9', '4', '9', '3', '9', '9', '1', '3', '9', '3', '1', '12', '8', '9', '12', '1', '8', '4', '2', '1', '4', '8', '3', '3', '8', '2', '8', '9', '7', '8', '8', '8', '5', '8', '3', '9', '8', '8', '13', '12', '1', '1', '2', '8', '4', '1', '9', '9', '12', '8', '9', '12', '9', '1', '9', '9', '9', '9', '3', '2', '9', '9', '4', '8', '12', '2', '4', '9', '3', '1', '9', '7', '8', '9', '9', '8', '4', '8', '8', '7', '9', '10', '3', '8', '8', '8', '1', '1', '1', '1', '8', '8', '4', '1', '10', '1', '5', '7', '7', '1', '8', '9', '3', '7', '2', '7', '7', '2', '4', '8', '12', '7', '4', '2', '9', '9', '12', '6', '10', '8', '2', '4', '12', '9', '9', '3', '8', '8', '1', '2', '10', '9', '9', '8', '4', '12', '2', '1', '8', '8', '8', '12', '10', '10', '9', '3', '8', '8', '9', '2', '8', '10', '1', '1', '1', '1', '2', '1', '1', '1', '1', '9', '8', '12', '9', '4', '8', '8', '9', '1', '9', '3', '9', '8', '8', '1', '7', '7', '10', '1', '8', '8', '1', '9', '8', '10', '3', '1', '7', '1', '8', '8', '12', '8', '8', '1', '8', '7', '1', '7', '7', '8', '2', '1', '8', '8', '2', '10', '8', '8', '8', '8', '8', '10', '1', '8', '8', '12', '8', '3', '3', '2', '2', '2', '10', '8', '8', '8', '2', '9', '1', '8', '9', '3', '2', '8', '10', '8', '6', '1', '1', '8', '4', '1', '9', '10', '8', '1', '7', '1', '2', '8', '1', '1', '1', '12', '1', '9', '12', '8', '12', '12', '12', '8', '8', '12', '4', '8', '8', '8', '8', '9', '9', '1', '3', '3', '3', '3', '1', '12', '12', '9', '10', '8', '8', '1', '9', '2', '2', '13', '9', '8', '9', '2', '1', '9', '1', '8', '8', '8', '4', '8', '1', '1', '1', '12', '12', '7', '2', '2', '2', '8', '3', '8', '9', '2', '10', '7', '8', '9', '2', '1', '2', '12', '12', '8', '8', '9', '2', '2', '9', '11', '1', '8', '1', '10', '9', '2', '1', '4', '7', '7', '7', '7', '7', '12', '8', '8', '8', '1', '1', '10', '1', '12', '1', '8', '2', '1', '1', '12', '8', '7', '9', '12', '8', '9', '3', '9', '8', '8', '8', '8', '3', '11', '2', '2', '9', '8', '8', '10', '8', '2', '7', '3', '1', '4', '7', '8', '8', '1', '8', '3', '7', '12', '8', '10', '9', '9', '8', '8', '2', '8', '9', '9', '1', '2', '8', '8', '9', '8', '3', '8', '1', '8', '10', '9', '8', '9', '9', '12', '4', '4', '8', '9', '9', '8', '2', '10', '1', '2', '8', '9', '1', '9', '9', '9', '7', '12', '12', '8', '1', '1', '1', '1', '8', '3', '1', '1', '8', '1', '8', '8', '7', '8', '8', '8', '8', '3', '2', '2', '10', '10', '10', '7', '8', '1', '2', '12', '7', '9', '8', '7', '8', '12', '2', '8', '9', '2', '6', '6', '7', '9', '8', '1', '8', '9', '8', '1', '12', '1', '2', '8', '7', '7', '7', '8', '2', '2', '8', '1', '2', '2', '9', '9', '1', '8', '8', '4', '3', '3', '1', '6', '3', '3', '12', '3', '8', '9', '1', '4', '3', '1', '8', '3', '9', '2', '8', '2', '8', '8', '8', '1', '1', '1', '9', '9', '8', '1', '9', '8', '1', '1', '3', '10', '8', '1', '1', '3', '9', '1', '4', '4', '1', '8', '9', '9', '2', '0', '0', '1', '8', '3', '1', '8', '8', '9', '8', '8', '1', '1', '8', '9', '8', '8', '8', '7', '9', '8', '8', '8', '10', '9', '8', '1', '2', '6', '1', '9', '9', '8', '12', '12', '12', '8', '8', '2', '8', '1', '2', '2', '2', '1', '9', '8', '2', '12', '2', '8', '12', '8', '9', '8', '8', '9', '7', '1', '1', '1', '1', '1', '8', '8', '1', '8', '8', '1', '1', '3', '2', '8', '8', '9', '10', '10', '2', '2', '1', '9', '2', '9', '9', '4', '12', '12', '12', '10', '7', '3', '3', '4', '2', '2', '9', '2', '8', '4', '2', '4', '1', '10', '9', '7', '8', '7', '1', '1', '3', '3', '1', '1', '3', '3', '3', '1', '1', '1', '1', '8', '2', '3', '1', '1', '2', '8', '8', '12', '8', '8', '8', '8', '11', '9', '1', '8', '9', '2', '8', '8', '8', '3', '9', '1', '9', '2', '7', '2', '8', '2', '8', '10', '8', '1', '10', '1', '1', '9', '9', '8', '8', '1', '8', '8', '8', '12', '8', '8', '8', '1', '8', '8', '8', '1', '9', '1', '1', '8', '1', '8', '9', '8', '2', '12', '9', '9', '0', '1', '8', '8', '1', '8', '12', '8', '8', '10', '8', '8', '8', '7', '8', '1', '8', '7', '3', '10', '1', '8', '9', '1', '8', '8', '8', '10', '1', '10', '3', '9', '1', '8', '9', '2', '8', '3', '3', '9', '9', '7', '9', '1', '1', '9', '2', '1', '1', '1', '7', '1', '1', '8', '8', '1', '1', '8', '1', '8', '3', '12', '9', '3', '3', '8', '8', '8', '8', '3', '1', '3', '3', '1', '11', '0', '8', '8', '7', '8', '12', '1', '8', '9', '8', '9', '8', '8', '3', '8', '8', '1', '1', '1', '9', '2', '2', '2', '8', '7', '12', '8', '8', '9', '10', '10', '7', '8', '1', '9', '8', '7', '3', '1', '3', '8', '2', '2', '3', '9', '8', '4', '4', '8', '9', '2', '1', '1', '7', '8', '9', '9', '7', '8', '7', '7', '8', '2', '2', '8', '4', '9', '7', '10', '0', '9', '8', '3', '7', '8', '1', '1', '8', '9', '9', '2', '2', '10', '1', '9', '10', '10', '10', '8', '3', '2', '12', '9', '9', '10', '12', '9', '12', '12', '9', '1', '2', '4', '12', '12', '7', '8', '9', '7', '7', '7', '3', '9', '8', '9', '1', '12', '8', '9', '4', '1', '3', '12', '12', '12', '12', '8', '8', '2', '1', '1', '2', '1', '1', '1', '12', '12', '8', '12', '2', '2', '12', '3', '3', '12', '8', '2', '8', '8', '12', '2', '1', '10', '3', '2', '8', '7', '1', '8', '1', '3', '7', '8', '9', '8', '3', '1', '1', '7', '8', '8', '9', '8', '2', '9', '2', '2', '9', '8', '1', '8', '8', '1', '3', '3', '1', '1', '10', '1', '2', '8', '1', '1', '1', '1', '9', '1', '4', '1', '7', '7', '7', '7', '2', '2', '8', '8', '12', '1', '9', '1', '7', '3', '3', '1', '8', '8', '10', '8', '9', '2', '9', '1', '3', '8', '8', '3', '12', '2', '8', '12', '2', '9', '1', '3', '3', '3', '3', '2', '8', '7', '9', '8', '3', '3', '1', '7', '8', '3', '1', '1', '12', '8', '9', '1', '2', '3', '8', '1', '1', '3', '3', '9', '1', '1', '1', '12', '1', '7', '3', '3', '1', '8', '8', '8', '1', '2', '4', '8', '1', '10', '2', '5', '3', '3', '12', '10', '9', '9', '12', '9', '0', '2', '8', '8', '9', '9', '9', '8', '1', '3', '1', '1', '4', '8', '1', '10', '8', '7', '2', '8', '2', '8', '4', '7', '8', '1', '9', '1', '9', '8', '2', '8', '2', '7', '9', '2', '2', '9', '1', '8', '12', '1', '8', '1', '4', '1', '9', '9', '1', '10', '12', '4', '8', '1', '7', '3', '9', '2', '12', '7', '8', '8', '2', '1', '12', '9', '8', '1', '2', '2', '8', '10', '2', '1', '7', '7', '7', '12', '3', '3', '8', '3', '8', '8', '3', '9', '8', '9', '1', '1', '8', '7', '9', '3', '3', '8', '1', '0', '9', '9', '9', '1', '8', '9', '9', '10', '1', '8', '7', '8', '8', '8', '9', '9', '8', '9', '10', '4', '9', '3', '7', '12', '1', '9', '9', '8', '9', '1', '9', '3', '1', '8', '4', '12', '10', '9', '8', '7', '10', '8', '12', '12', '3', '10', '8', '12', '2', '1', '2', '3', '9', '8', '8', '7', '1', '1', '2', '2', '1', '2', '2', '7', '1', '3', '9', '9', '3', '8', '8', '8', '8', '8', '7', '8', '8', '10', '8', '1', '8', '2', '8', '2', '2', '2', '2', '2', '1', '7', '12', '10', '1', '2', '8', '1', '4', '7', '8', '1', '12', '8', '7', '9', '2', '2', '2', '8', '1', '8', '1', '1', '0', '2', '2', '6', '1', '8', '2', '1', '8', '1', '1', '2', '2', '3', '2', '2', '10', '10', '9', '1', '7', '7', '8', '8', '1', '12', '10', '12', '3', '8', '8', '8', '3', '8', '3', '10', '2', '2', '2', '1', '2', '2', '1', '0', '1', '8', '9', '1', '1', '1', '2', '2', '2', '2', '2', '1', '1', '1', '1', '12', '9', '9', '1', '10', '11', '12', '9', '1', '1', '8', '8', '1', '2', '12', '8', '3', '7', '2', '10', '9', '7', '8', '1', '2', '2', '7', '9', '12', '2', '2', '1', '8', '9', '2', '3', '2', '2', '2', '9', '9', '8', '9', '2', '3', '8', '8', '9', '7', '3', '10', '8', '8', '9', '1', '1', '2', '8', '1', '10', '8', '8', '9', '7', '1', '7', '12', '8', '1', '7', '2', '1', '3', '9', '2', '8', '8', '1', '2', '3', '9', '3', '8', '9', '7', '7', '1', '10', '2', '8', '8', '8', '1', '8', '2', '8', '8', '1', '2', '8', '10', '2', '1', '0', '8', '3', '8', '10', '10', '12', '3', '8', '9', '3', '10', '8', '8', '8', '1', '8', '8', '2', '2', '2', '2', '2', '2', '1', '1', '10', '1', '10', '8', '2', '1', '2', '2', '8', '3', '3', '2', '2', '1', '8', '1', '3', '1', '9', '2', '2', '1', '3', '2', '2', '3', '2', '2', '3', '2', '1', '1', '2', '1', '2', '7', '8', '2', '1', '12', '12', '3', '1', '9', '9', '7', '8', '7', '2', '7', '9', '2', '2', '2', '8', '9', '7', '9', '2', '8', '9', '9', '2', '9', '1', '1', '9', '8', '3', '3', '8', '2', '7', '8', '11', '2', '8', '9', '1', '8', '3', '1', '2', '1', '2', '2', '2', '2', '8', '3', '9', '2', '10', '9', '9', '2', '7', '7', '7', '1', '3', '8', '8', '1', '1', '8', '7', '1', '8', '8', '9', '3', '3', '3', '2', '4', '8', '12', '8', '1', '12', '9', '2', '8', '2', '12', '2', '1', '3', '8', '12', '12', '11', '8', '10', '9', '2', '9', '4', '10', '1', '12', '12', '9', '3', '8', '9', '12', '9', '9', '2', '2', '2', '3', '5', '1', '1', '1', '7', '7', '8', '2', '2', '8', '2', '1', '7', '3', '2', '9', '8', '9', '1', '1', '9', '8', '9', '3', '3', '2', '9', '4', '9', '8', '8', '1', '8', '10', '2', '0', '3', '8', '8', '8', '9', '12', '9', '8', '2', '2', '8', '10', '9', '8', '2', '2', '4', '1', '9', '9', '8', '8', '10', '3', '1', '1', '2', '8', '7', '8', '2', '1', '1', '8', '12', '2', '9', '4', '8', '3', '3', '3', '8', '2', '12', '12', '8', '9', '12', '8', '2', '12', '7', '9', '2', '2', '1', '3', '1', '3', '11', '9', '8', '1', '10', '2', '12', '3', '8', '4', '1', '2', '8', '8', '3', '9', '3', '8', '7', '1', '1', '3', '1', '8', '2', '9', '8', '12', '1', '1', '1', '9', '9', '1', '8', '8', '8', '2', '2', '12', '3', '1', '1', '1', '9', '9', '3', '2', '1', '1', '9', '9', '1', '9', '9', '1', '9', '3', '9', '1', '8', '1', '9', '8', '3', '8', '8', '9', '9', '8', '2', '8', '1', '2', '2', '10', '1', '2', '1', '1', '9', '1', '9', '3', '7', '7', '2', '10', '3', '3', '1', '1', '9', '1', '2', '1', '3', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '8', '8', '7', '1', '1', '8', '8', '2', '1', '12', '1', '8', '1', '9', '8', '8', '2', '1', '9', '9', '2', '2', '8', '1', '7', '7', '9', '8', '1', '6', '8', '8', '2', '2', '8', '3', '8', '3', '2', '3', '8', '1', '2', '2', '2', '8', '9', '9', '9', '12', '1', '9', '2', '1', '9', '2', '9', '9', '10', '8', '1', '1', '9', '2', '1', '7', '1', '3', '7', '1', '1', '1', '3', '8', '8', '8', '9', '9', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '1', '0', '1', '1', '1', '2', '2', '3', '1', '1', '2', '3', '3', '3', '7', '3', '1', '9', '3', '9', '1', '4', '1', '1', '9', '10', '9', '8', '2', '3', '10', '9', '3', '10', '12', '8', '9', '8', '2', '1', '9', '8', '1', '7', '8', '1', '9', '1', '2', '10', '7', '7', '8', '1', '3', '3', '9', '3', '3', '1', '1', '1', '9', '1', '3', '8', '8', '8', '1', '8', '1', '9', '7', '8', '8', '2', '1', '3', '8', '2', '1', '6', '1', '8', '8', '2', '8', '2', '2', '9', '8', '1', '1', '6', '8', '6', '10', '2', '1', '1', '8', '9', '3', '3', '3', '1', '3', '9', '6', '8', '1', '8', '3', '1', '2', '2', '12', '7', '1', '1', '1', '1', '12', '1', '8', '8', '3', '2', '1', '9', '2', '3', '3', '2', '2', '7', '2', '2', '2', '3', '1', '9', '8', '7', '1', '1', '3', '1', '9', '4', '3', '9', '2', '1', '1', '9', '8', '8', '7', '2', '1', '3', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '10', '1', '1', '8', '2', '8', '1', '8', '1', '3', '1', '2', '1', '1', '3', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '8', '1', '9', '8', '8', '1', '10', '8', '8', '1', '3', '9', '8', '9', '8', '2', '1', '3', '4', '1', '12', '1', '9', '8', '2', '7', '2', '1', '2', '9', '2', '1', '3', '8', '1', '2', '3', '8', '2', '10', '10', '10', '9', '9', '9', '3', '8', '3', '1', '1', '1', '1', '1', '1', '2', '1', '9', '2', '7', '9', '8', '7', '9', '1', '1', '1', '1', '8', '2', '2', '3', '3', '2', '12', '8', '3', '1', '1', '12', '9', '8', '2', '2', '9', '1', '2', '2', '9', '1', '1', '2', '4', '8', '1', '8', '10', '2', '9', '9', '9', '1', '2', '1', '1', '2', '2', '2', '12', '1', '2', '8', '3', '9', '9', '3', '2', '9', '9', '7', '2', '8', '8', '9', '2', '9', '1', '1', '1', '1', '1', '2', '8', '2', '1', '2', '2', '8', '3', '1', '1', '9', '1', '3', '10', '7', '9', '8', '8', '2', '2', '9', '2', '2', '2', '2', '2', '2', '9', '1', '3', '6', '4', '2', '2', '9', '1', '9', '8', '1', '1', '1', '7', '3', '2', '9', '9', '1', '9', '7', '2', '8', '9', '9', '12', '10', '8', '10', '2', '3', '1', '2', '2', '12', '12', '3', '12', '1', '2', '1', '2', '1', '2', '8', '2', '3', '12', '12', '8', '2', '2', '9', '2', '9', '2', '3', '3', '1', '1', '1', '12', '3', '7', '1', '3', '1', '2', '9', '2', '7', '2', '1', '8', '3', '7', '8', '1', '1', '3', '8', '3', '2', '9', '3', '1', '1', '1', '1', '11', '1', '2', '6', '1', '2', '3', '8', '9', '9', '2', '9', '2', '1', '1', '3', '1', '12', '9', '1', '1', '9', '1', '9', '9', '8', '9', '8', '1', '2', '7', '1', '0', '9', '8', '2', '3', '2', '4', '1', '1', '1', '8', '1', '12', '1', '2', '3', '3', '9', '9', '9', '9', '9', '7', '9', '3', '9', '1', '7', '3', '3', '3', '3', '7', '8', '2', '2', '2', '8', '2', '3', '9', '9', '3', '1', '8', '9', '12', '8', '8', '3', '2', '1', '6', '1', '9', '1', '1', '1', '1', '1', '1', '2', '2', '1', '2', '2', '2', '2', '9', '2', '5', '3', '2', '2', '8', '2', '1', '8', '3', '3', '8', '3', '1', '3', '9', '2', '8', '9', '4', '4', '9', '8', '8', '7', '7', '3', '1', '8', '8', '3', '2', '2', '10', '3', '3', '2', '2', '2', '2', '12', '3', '1', '2', '7', '7', '12', '2', '1', '2', '1', '1', '2', '1', '3', '3', '3', '1', '3', '9', '4', '8', '8', '4', '2', '4', '2', '8', '9', '1', '1', '2', '2', '2', '8', '7', '2', '8', '2', '9', '1', '8', '1', '1', '2', '1', '1', '1', '2', '9', '9', '8', '1', '8', '1', '4', '8', '1', '2', '7', '9', '2', '1', '8', '9', '8', '9', '1', '1', '2', '3', '2', '12', '7', '1', '2', '4', '4', '4', '2', '2', '2', '9', '8', '8', '1', '12', '3', '3', '2', '2', '3', '12', '1', '5', '1', '1', '3', '2', '8', '8', '2', '2', '2', '3', '9', '8', '8', '9', '8', '8', '11', '8', '2', '9', '2', '3', '1', '7', '1', '8', '2', '8', '1', '1', '1', '8', '1', '1', '1', '7', '8', '8', '2', '3', '2', '1', '8', '8', '1', '8', '4', '8', '9', '8', '9', '8', '1', '2', '3', '2', '1', '2', '2', '3', '1', '9', '4', '8', '1', '1', '9', '1', '1', '8', '2', '2', '2', '1', '7', '3', '3', '1', '3', '3', '12', '3', '1', '1', '3', '1', '1', '4', '8', '4', '4', '3', '3', '3', '4', '8', '1', '9', '9', '9', '4', '1', '7', '4', '8', '4', '9', '8', '1', '1', '3', '8', '9', '1', '9', '7', '1', '1', '9', '1', '8', '8', '8', '1', '1', '8', '2', '2', '2', '9', '4', '4', '1', '2', '1', '2', '9', '1', '1', '8', '5', '5', '5', '9', '12', '4', '1', '2', '1', '8', '8', '1', '9', '9', '2', '12', '1', '1', '7', '8', '8', '4', '1', '2', '8', '11', '2', '3', '2', '2', '1', '11', '2', '2', '2', '2', '9', '9', '2', '2', '9', '3', '1', '9', '1', '1', '1', '7', '8', '1', '8', '9', '1', '2', '9', '8', '1', '2', '9', '8', '12', '2', '2', '10', '8', '2', '2', '8', '8', '1', '2', '6', '1', '1', '7', '7', '2', '3', '2', '1', '1', '8', '1', '10', '8', '12', '6', '4', '1', '4', '1', '2', '9', '8', '9', '4', '8', '8', '10', '8', '8', '8', '8', '8', '2', '2', '8', '4', '9', '3', '3', '3', '3', '3', '9', '2', '1', '1', '2', '3', '2', '1', '2', '3', '3', '3', '2', '2', '3', '3', '2', '1', '2', '3', '3', '3', '3', '12', '9', '3', '2', '2', '3', '1', '5', '1', '1', '3', '2', '2', '1', '2', '9', '3', '9', '8', '1', '8', '7', '7', '9', '1', '1', '7', '9', '10', '1', '7', '1', '4', '3', '8', '9', '4', '9', '9', '2', '9', '2', '8', '4', '2', '2', '9', '5', '2', '1', '10', '9', '3', '1', '1', '1', '2', '1', '2', '9', '1', '7', '9', '9', '8', '2', '2', '8', '9', '1', '9', '8', '2', '3', '2', '2', '1', '2', '2', '2', '1', '1', '8', '1', '9', '4', '12', '8', '2', '7', '2', '2', '1', '9', '3', '1', '8', '12', '1', '1', '2', '1', '10', '2', '6', '12', '12', '4', '9', '1', '9', '10', '1', '2', '8', '2', '1', '8', '6', '12', '9', '9', '2', '1', '7', '8', '9', '5', '8', '1', '8', '8', '3', '1', '8', '2', '8', '2', '2', '1', '2', '9', '2', '8', '1', '12', '8', '2', '7', '3', '3', '12', '2', '3', '3', '9', '9', '3', '3', '3', '3', '3', '2', '1', '4', '1', '4', '8', '8', '2', '1', '2', '9', '12', '1', '10', '12', '1', '2', '9', '4', '8', '10', '3', '2', '8', '7', '4', '8', '9', '2', '7', '1', '10', '2', '2', '2', '8', '4', '2', '2', '1', '1', '8', '7', '9', '2', '1', '9', '8', '9', '12', '4', '8', '2', '8', '7', '7', '1', '9', '2', '1', '1', '9', '1', '8', '2', '3', '9', '9', '1', '3', '2', '9', '2', '2', '8', '1', '1', '2', '1', '2', '1', '9', '8', '2', '2', '4', '8', '8', '9', '5', '5', '9', '8', '9', '6', '2', '1', '12', '2', '3', '8', '8', '9', '2', '2', '1', '3', '2', '10', '9', '10', '7', '2', '8', '4', '2', '8', '9', '8', '1', '3', '8', '8', '1', '8', '3', '8', '8', '1', '10', '3', '1', '5', '8', '8', '9', '2', '2', '9', '2', '1', '9', '1', '4', '1', '12', '8', '8', '2', '1', '1', '1', '1', '1', '9', '2', '9', '8', '9', '5', '9', '1', '8', '2', '4', '1', '1', '1', '9', '12', '4', '1', '1', '9', '8', '4', '1', '8', '9', '8', '8', '9', '9', '9', '9', '9', '9', '1', '3', '4', '2', '2', '8', '2', '9', '2', '3', '8', '3', '1', '7', '2', '1', '1', '4', '2', '9', '2', '1', '3', '2', '9', '2', '9', '3', '8', '1', '9', '1', '1', '2', '8', '8', '8', '2', '3', '9', '9', '8', '2', '4', '1', '5', '1', '1', '9', '9', '2', '1', '1', '1', '9', '9', '1', '3', '9', '2', '2', '9', '9', '8', '3', '9', '9', '8', '2', '2', '8', '9', '2', '2', '8', '9', '10', '10', '2', '8', '7', '9', '9', '4', '2', '4', '11', '2', '1', '7', '8', '8', '8', '9', '4', '9', '8', '8', '2', '1', '1', '9', '8', '3', '3', '8', '8', '7', '9', '1', '3', '4', '8', '10', '2', '4', '4', '8', '2', '8', '2', '8', '9', '2', '1', '2', '2', '3', '1', '9', '4', '5', '9', '9', '1', '1', '1', '1', '1', '1', '7', '1', '1', '1', '8', '1', '1', '1', '1', '1', '9', '1', '2', '1', '12', '9', '3', '9', '9', '4', '1', '9', '1', '1', '2', '11', '9', '3', '2', '2', '2', '4', '2', '3', '2', '7', '7', '8', '1', '10', '9', '5', '7', '1', '10', '8', '1', '2', '7', '1', '12', '5', '8', '4', '2', '9', '9', '8', '2', '9', '8', '8', '10', '2', '3', '2', '7', '2', '8', '10', '3', '2', '9', '9', '9', '1', '1', '1', '1', '8', '2', '10', '9', '8', '1', '2', '2', '2', '1', '2', '1', '3', '9', '12', '2', '2', '4', '8', '1', '3', '9', '4', '9', '1', '9', '9', '2', '1', '1', '9', '7', '10', '3', '10', '2', '9', '2', '9', '2', '8', '2', '1', '2', '3', '1', '1', '1', '8', '5', '8', '3', '1', '1', '4', '2', '2', '1', '3', '8', '2', '1', '1', '1', '2', '9', '4', '1', '8', '1', '2', '8', '2', '9', '2', '2', '5', '5', '2', '5', '2', '1', '8', '8', '1', '3', '12', '2', '4', '3', '2', '2', '2', '6', '2', '3', '3', '1', '8', '2', '2', '1', '1', '8', '8', '10', '1', '9', '2', '9', '12', '0', '2', '1', '3', '2', '2', '1', '2', '1', '9', '9', '2', '9', '8', '8', '1', '7', '8', '1', '2', '6', '9', '8', '10', '1', '12', '2', '2', '1', '8', '2', '1', '12', '7', '4', '2', '10', '2', '2', '1', '2', '1', '2', '1', '1', '2', '1', '9', '8', '10', '2', '10', '9', '9', '12', '5', '3', '2', '8', '2', '8', '3', '3', '1', '4', '9', '10', '2', '4', '8', '1', '2', '10', '12', '12', '3', '1', '1', '2', '9', '6', '6', '1', '9', '1', '8', '1', '8', '8', '8', '8', '2', '2', '2', '8', '8', '2', '1', '1', '1', '1', '1', '8', '8', '5', '8', '8', '1', '8', '9', '9', '1', '7', '12', '9', '9', '7', '2', '2', '7', '8', '9', '8', '2', '9', '6', '3', '4', '8', '4', '1', '2', '9', '8', '8', '8', '2', '1', '1', '8', '8', '3', '1', '9', '9', '7', '1', '2', '2', '2', '9', '4', '1', '2', '12', '1', '8', '2', '1', '9', '1', '8', '9', '9', '2', '5', '4', '2', '1', '2', '8', '12', '8', '10', '3', '8', '8', '8', '2', '2', '8', '2', '8', '2', '4', '8', '10', '2', '7', '2', '1', '8', '8', '9', '5', '8', '1', '12', '7', '10', '2', '2', '2', '1', '4', '8', '12', '1', '8', '2', '2', '9', '1', '8', '3', '1', '1', '5', '10', '2', '1', '2', '4', '8', '9', '3', '2', '8', '7', '4', '4', '9', '9', '2', '8', '1', '1', '2', '4', '7', '1', '9', '1', '1', '1', '8', '4', '1', '3', '1', '2', '2', '9', '1', '8', '8', '2', '2', '9', '9', '1', '8', '8', '1', '9', '8', '8', '2', '2', '2', '2', '1', '1', '1', '7', '4', '1', '1', '4', '2', '3', '3', '2', '3', '9', '2', '8', '2', '1', '5', '1', '2', '2', '1', '3', '5', '2', '9', '1', '1', '9', '8', '1', '4', '8', '1', '8', '2', '4', '8', '4', '7', '9', '8', '1', '2', '2', '4', '4', '11', '3', '11', '1', '3', '8', '1', '9', '6', '8', '9', '3', '9', '8', '9', '2', '3', '3', '7', '1', '7', '2', '9', '9', '1', '8', '8', '1', '5', '5', '8', '8', '1', '2', '1', '3', '9', '9', '5', '9', '8', '1', '4', '3', '8', '1', '1', '2', '1', '8', '9', '8', '2', '2', '2', '1', '2', '4', '10', '8', '1', '9', '1', '8', '1', '1', '9', '9', '8', '11', '1', '8', '2', '1', '2', '8', '2', '8', '8', '2', '9', '6', '10', '1', '8', '6', '4', '5', '11', '2', '2', '8', '1', '8', '1', '8', '1', '4', '8', '1', '1', '1', '8', '3', '7', '3', '3', '7', '1', '1', '4', '8', '1', '6', '4', '2', '2', '1', '1', '1', '1', '6', '2', '2', '8', '1', '8', '5', '5', '2', '1', '1', '2', '3', '7', '1', '1', '6', '2', '9', '3', '9', '8', '9', '2', '1', '4', '2', '9', '13', '9', '2', '8', '12', '4', '1', '1', '9', '5', '1', '1', '1', '1', '8', '2', '1', '1', '2', '9', '0', '12', '1', '1', '8', '9', '8', '3', '2', '2', '12', '8', '2', '2', '2', '1', '10', '1', '9', '8', '9', '5', '2', '2', '9', '2', '8', '4', '8', '3', '7', '9', '2', '2', '7', '2', '2', '8', '1', '1', '9', '10', '9', '8', '2', '9', '0', '7', '1', '1', '1', '9', '8', '2', '8', '12', '8', '3', '2', '8', '8', '7', '7', '8', '12', '2', '1', '3', '9', '2', '2', '8', '2', '8', '8', '12', '8', '8', '1', '8', '9', '2', '4', '4', '7', '2', '1', '1', '9', '3', '7', '1', '3', '9', '8', '2', '2', '3', '1', '3', '10', '2', '3', '7', '1', '8', '1', '1', '10', '3', '10', '8', '4', '1', '2', '4', '3', '10', '9', '3', '9', '5', '8', '7', '2', '9', '3', '3', '2', '11', '8', '1', '1', '7', '2', '7', '2', '9', '4', '8', '1', '12', '8', '7', '9', '1', '0', '2', '6', '4', '9', '3', '2', '4', '12', '9', '8', '5', '9', '2', '8', '4', '6', '8', '9', '3', '1', '8', '7', '3', '1', '1', '1', '8', '9', '1', '8', '7', '9', '8', '2', '1', '2', '2', '3', '2', '2', '1', '1', '4', '9', '7', '3', '2', '8', '8', '9', '1', '9', '7', '4', '2', '2', '8', '5', '9', '1', '5', '7', '1', '4', '6', '9', '10', '1', '8', '2', '9', '1', '9', '2', '9', '8', '2', '9', '9', '11', '2', '12', '2', '2', '9', '4', '8', '1', '9', '9', '2', '8', '9', '1', '2', '9', '3', '8', '8', '1', '7', '8', '8', '2', '3', '2', '2', '2', '2', '9', '8', '10', '2', '2', '1', '9', '11', '1', '8', '8', '2', '4', '2', '1', '2', '8', '8', '9', '2', '8', '9', '2', '3', '1', '2', '1', '3', '10', '8', '1', '2', '4', '1', '9', '8', '9', '3', '3', '9', '8', '2', '11', '3', '7', '1', '8', '7', '1', '8', '8', '8', '1', '4', '8', '8', '1', '9', '3', '1', '1', '2', '8', '8', '8', '2', '1', '8', '10', '2', '12', '8', '8', '9', '1', '8', '1', '3', '2', '2', '10', '7', '2', '2', '1', '1', '8', '2', '9', '1', '2', '9', '3', '3', '10', '1', '4', '7', '10', '12', '2', '4', '10', '8', '6', '2', '9', '1', '8', '3', '1', '2', '8', '8', '2', '12', '10', '2', '10', '9', '1', '2', '5', '8', '12', '8', '8', '7', '8', '8', '1', '8', '2', '2', '9', '1', '8', '10', '5', '5', '5', '8', '1', '9', '1', '13', '1', '2', '2', '1', '2', '4', '9', '2', '1', '9', '13', '11', '1', '9', '9', '3', '10', '8', '7', '8', '8', '4', '2', '1', '9', '4', '3', '1', '1', '10', '9', '2', '8', '6', '2', '1', '1', '3', '2', '8', '1', '1', '1', '1', '2', '4', '1', '1', '10', '1', '8', '1', '1', '9', '1', '7', '1', '1', '9', '9', '2', '12', '9', '1', '8', '1', '12', '1', '8', '3', '8', '1', '8', '1', '2', '10', '1', '1', '2', '2', '9', '3', '9', '12', '1', '9', '1', '2', '8', '7', '2', '1', '1', '3', '2', '8', '4', '4', '5', '12', '7', '8', '9', '6', '1', '8', '9', '2', '1', '9', '1', '4', '1', '8', '2', '1', '1', '8', '7', '4', '9', '1', '8', '4', '2', '7', '5', '1', '3', '9', '2', '8', '2', '1', '2', '9', '1', '1', '2', '3', '4', '3', '1', '2', '2', '10', '2', '2', '8', '1', '1', '2', '4', '9', '2', '11', '9', '8', '9', '2', '1', '10', '4', '1', '1', '10', '7', '2', '10', '8', '1', '10', '8', '8', '8', '8', '8', '8', '2', '2', '2', '8', '3', '4', '1', '1', '1', '2', '1', '8', '8', '2', '8', '3', '8', '3', '1', '2', '3', '1', '1', '10', '1', '4', '4', '3', '3', '1', '9', '1', '1', '2', '1', '1', '6', '1', '1', '1', '9', '1', '4', '1', '1', '1', '1', '1', '1', '2', '12', '8', '8', '1', '9', '12', '10', '8', '2', '12', '1', '1', '2', '1', '7', '10', '7', '1', '2', '1', '10', '8', '2', '2', '8', '2', '2', '1', '9', '8', '8', '8', '8', '3', '1', '4', '2', '8', '3', '10', '10', '1', '9', '1', '9', '1', '9', '1', '8', '3', '1', '1', '8', '8', '8', '6', '3', '4', '1', '1', '1', '9', '9', '5', '2', '10', '2', '6', '2', '2', '7', '1', '8', '2', '11', '1', '1', '1', '2', '1', '9', '4', '4', '2', '8', '4', '6', '8', '8', '10', '10', '2', '1', '2', '9', '1', '8', '8', '3', '4', '8', '8', '2', '8', '8', '1', '2', '1', '2', '9', '4', '1', '3', '3', '3', '8', '8', '8', '2', '6', '4', '3', '3', '12', '3', '4', '9', '6', '8', '7', '7', '8', '6', '4', '1', '10', '6', '3', '3', '8', '1', '1', '8', '1', '11', '8', '1', '1', '2', '3', '11', '7', '2', '1', '1', '1', '9', '1', '2', '1', '1', '9', '8', '1', '1', '8', '0', '4', '1', '1', '2', '1', '1', '2', '2', '9', '1', '10', '1', '3', '8', '9', '3', '3', '1', '10', '1', '9', '1', '1', '7', '4', '1', '8', '10', '1', '2', '10', '1', '1', '2', '3', '3', '9', '1', '8', '10', '1', '7', '9', '1', '9', '6', '3', '9', '2', '8', '4', '12', '12', '3', '1', '1', '9', '1', '9', '2', '1', '1', '1', '1', '1', '9', '2', '1', '2', '10', '9', '8', '8', '10', '8', '2', '3', '2', '1', '12', '8', '12', '2', '9', '1', '3', '2', '5', '2', '2', '8', '2', '2', '4', '10', '9', '10', '9', '4', '2', '4', '12', '8', '2', '1', '8', '3', '9', '2', '9', '4', '1', '1', '1', '1', '1', '9', '6', '2', '9', '2', '1', '3', '2', '2', '5', '8', '9', '1', '6', '3', '1', '2', '2', '2', '6', '1', '8', '10', '8', '3', '3', '13', '2', '9', '9', '10', '6', '12', '8', '2', '9', '2', '3', '8', '8', '1', '2', '2', '3', '2', '10', '1', '8', '9', '1', '8', '9', '8', '8', '2', '10', '2', '1', '1', '1', '9', '9', '12', '1', '1', '4', '8', '3', '2', '2', '4', '4', '2', '2', '1', '1', '1', '9', '2', '2', '4', '1', '1', '8', '8', '8', '9', '2', '13', '9', '9', '4', '1', '9', '7', '10', '10', '8', '1', '9', '1', '1', '1', '8', '12', '4', '1', '2', '1', '1', '1', '7', '8', '3', '3', '1', '2', '2', '7', '2', '2', '10', '1', '8', '4', '0', '1', '9', '4', '1', '1', '2', '10', '10', '7', '9', '3', '12', '11', '2', '8', '10', '8', '9', '4', '3', '4', '10', '1', '1', '9', '3', '10', '1', '5', '3', '3', '2', '2', '1', '1', '6', '1', '7', '1', '1', '12', '1', '1', '1', '10', '1', '8', '8', '1', '3', '8', '3', '1', '2', '8', '3', '4', '2', '8', '8', '6', '1', '1', '4', '1', '2', '9', '5', '1', '7', '8', '9', '2', '4', '9', '8', '5', '9', '9', '9', '1', '2', '1', '3', '8', '9', '2', '9', '8', '9', '1', '8', '13', '9', '3', '8', '1', '4', '1', '3', '1', '6', '4', '10', '2', '2', '7', '8', '8', '12', '8', '9', '9', '9', '10', '3', '12', '12', '2', '9', '10', '9', '7', '2', '3', '4', '10', '10', '2', '7', '7', '1', '7', '3', '9', '1', '9', '8', '2', '9', '1', '8', '1', '10', '8', '8', '2', '7', '8', '1', '8', '9', '8', '1', '4', '1', '8', '8', '8', '1', '1', '10', '3', '2', '2', '6', '8', '9', '8', '2', '1', '1', '3', '8', '8', '1', '4', '4', '3', '9', '10', '4', '2', '4', '2', '9', '2', '2', '9', '1', '1', '10', '1', '1', '2', '1', '1', '1', '9', '1', '8', '8', '8', '2', '3', '8', '1', '6', '7', '3', '1', '9', '1', '2', '1', '6', '1', '2', '10', '1', '4', '2', '3', '2', '9', '9', '4', '9', '9', '1', '2', '8', '4', '7', '8', '7', '13', '9', '1', '2', '1', '9', '3', '3', '6', '8', '9', '10', '9', '2', '2', '3', '12', '1', '1', '1', '13', '2', '1', '7', '10', '8', '9', '1', '2', '9', '1', '1', '1', '2', '1', '12', '5', '6', '9', '10', '3', '1', '10', '1', '3', '2', '8', '9', '2', '10', '8', '8', '9', '2', '8', '9', '2', '2', '2', '8', '8', '2', '3', '1', '4', '8', '1', '9', '9', '2', '8', '10', '9', '1', '2', '12', '8', '8', '0', '2', '1', '1', '9', '10', '1', '6', '2', '2', '10', '2', '2', '4', '2', '2', '12', '1', '6', '7', '8', '9', '1', '3', '5', '7', '3', '1', '3', '1', '1', '3', '2', '6', '3', '2', '1', '8', '3', '5', '2', '1', '1', '8', '1', '1', '0', '2', '3', '5', '3', '1', '1', '9', '8', '8', '8', '8', '4', '7', '2', '9', '12', '5', '9', '3', '12', '3', '9', '1', '9', '1', '7', '3', '9', '3', '10', '1', '2', '1', '4', '9', '8', '2', '9', '11', '2', '8', '9', '4', '1', '1', '1', '1', '1', '1', '1', '9', '1', '9', '1', '1', '1', '12', '3', '10', '3', '6', '1', '7', '10', '8', '3', '7', '1', '1', '2', '6', '1', '3', '9', '2', '8', '1', '8', '8', '1', '8', '10', '12', '1', '10', '12', '10', '1', '8', '8', '1', '4', '7', '9', '2', '1', '9', '3', '8', '12', '10', '6', '1', '6', '8', '3', '1', '3', '1', '10', '10', '9', '8', '1', '2', '9', '8', '8', '1', '9', '8', '8', '3', '1', '3', '9', '12', '1', '8', '1', '5', '8', '11', '5', '5', '1', '2', '1', '3', '1', '1', '1', '9', '8', '8', '1', '9', '10', '8', '4', '1', '1', '8', '10', '8', '9', '1', '10', '1', '7', '2', '1', '1', '9', '6', '2', '9', '8', '1', '1', '1', '9', '8', '8', '1', '9', '9', '1', '1', '2', '7', '9', '2', '9', '9', '8', '7', '6', '8', '7', '8', '2', '9', '2', '1', '8', '8', '8', '2', '6', '3', '1', '8', '12', '12', '8', '7', '1', '2', '2', '7', '1', '9', '8', '1', '4', '1', '1', '8', '5', '8', '1', '8', '8', '8', '8', '1', '2', '11', '1', '1', '1', '2', '7', '1', '9', '2', '2', '2', '9', '8', '9', '2', '9', '1', '8', '1', '7', '11', '13', '1', '9', '8', '2', '2', '1', '2', '3', '10', '3', '10', '4', '3', '9', '1', '8', '1', '1', '13', '1', '1', '3', '8', '1', '2', '2', '2', '9', '4', '1', '8', '1', '9', '3', '6', '8', '5', '2', '8', '2', '8', '1', '9', '2', '2', '8', '1', '1', '4', '8', '9', '2', '2', '7', '1', '8', '12', '2', '12', '8', '2', '9', '9', '3', '8', '1', '1', '9', '9', '9', '2', '8', '1', '9', '1', '8', '9', '8', '2', '2', '4', '1', '9', '10', '10', '8', '8', '1', '1', '2', '1', '4', '1', '2', '1', '1', '3', '12', '8', '8', '8', '8', '10', '2', '8', '12', '1', '9', '9', '8', '9', '1', '2', '1', '8', '8', '8', '2', '8', '8', '3', '10', '8', '9', '1', '1', '1', '3', '4', '8', '10', '6', '3', '1', '3', '2', '8', '9', '3', '5', '4', '1', '5', '2', '9', '9', '9', '1', '1', '1', '9', '9', '6', '10', '9', '8', '12', '2', '9', '1', '2', '1', '1', '1', '8', '1', '12', '1', '12', '1', '9', '1', '8', '1', '2', '1', '2', '8', '8', '10', '1', '9', '1', '2', '2', '8', '8', '3', '12', '1', '11', '2', '10', '12', '11', '2', '1', '10', '1', '1', '9', '3', '10', '2', '7', '1', '8', '1', '9', '9', '2', '1', '3', '12', '5', '9', '9', '8', '1', '8', '8', '8', '1', '1', '3', '9', '8', '9', '8', '3', '10', '3', '7', '8', '9', '2', '3', '1', '9', '10', '9', '2', '8', '2', '6', '4', '1', '1', '3', '8', '2', '3', '9', '1', '2', '1', '8', '1', '2', '2', '2', '2', '9', '9', '4', '8', '9', '1', '1', '2', '9', '1', '5', '2', '9', '8', '10', '1', '2', '10', '8', '5', '6', '4', '8', '1', '1', '1', '8', '9', '2', '8', '8', '8', '12', '2', '2', '1', '8', '1', '2', '1', '9', '8', '8', '9', '1', '1', '8', '7', '1', '8', '0', '2', '3', '8', '1', '1', '8', '1', '1', '12', '3', '2', '10', '8', '10', '6', '1', '8', '8', '10', '8', '8', '1', '4', '8', '1', '2', '9', '8', '1', '1', '3', '3', '5', '1', '1', '2', '1', '2', '1', '9', '8', '3', '9', '8', '2', '10', '9', '1', '8', '1', '10', '9', '10', '1', '2', '3', '8', '1', '3', '1', '9', '9', '8', '1', '9', '8', '8', '9', '1', '9', '2', '8', '8', '2', '13', '8', '10', '8', '9', '3', '2', '1', '3', '1', '12', '10', '10', '1', '11', '1', '2', '4', '2', '10', '1', '8', '11', '1', '1', '1', '2', '2', '8', '2', '9', '8', '9', '9', '12', '8', '1', '9', '2', '4', '1', '8', '3', '9', '1', '6', '5', '8', '9', '3', '3', '2', '1', '1', '1', '8', '11', '1', '8', '7', '1', '11', '9', '1', '7', '9', '9', '8', '8', '8', '12', '8', '1', '2', '9', '8', '8', '2', '10', '9', '8', '8', '4', '10', '9', '8', '2', '10', '10', '2', '1', '2', '1', '2', '1', '4', '1', '7', '1', '1', '3', '12', '9', '8', '5', '9', '10', '1', '9', '9', '2', '7', '4', '1', '1', '8', '12', '8', '2', '2', '9', '4', '1', '1', '5', '9', '1', '8', '12', '8', '1', '1', '4', '9', '10', '2', '3', '1', '3', '3', '3', '8', '1', '2', '1', '2', '1', '2', '9', '1', '2', '8', '9', '4', '8', '8', '10', '2', '12', '5', '5', '1', '8', '1', '7', '8', '1', '1', '8', '9', '12', '4', '9', '3', '1', '2', '5', '9', '2', '1', '2', '2', '1', '2', '8', '1', '8', '8', '2', '2', '1', '8', '4', '1', '2', '10', '9', '10', '8', '1', '10', '4', '8', '8', '10', '2', '8', '1', '1', '3', '10', '1', '4', '2', '8', '3', '3', '2', '9', '8', '5', '5', '9', '3', '10', '8', '1', '2', '1', '2', '9', '1', '1', '2', '9', '9', '8', '8', '11', '9', '4', '1', '8', '2', '7', '1', '2', '8', '2', '9', '9', '8', '2', '9', '9', '8', '8', '1', '2', '8', '1', '1', '2', '9', '8', '1', '4', '9', '1', '8', '12', '1', '12', '2', '8', '2', '9', '1', '12', '1', '2', '9', '1', '1', '9', '3', '2', '9', '9', '2', '11', '8', '7', '9', '9', '9', '8', '8', '1', '2', '8', '1', '1', '4', '1', '2', '10', '1', '9', '2', '1', '1', '1', '9', '1', '13', '4', '3', '2', '1', '1', '2', '2', '7', '8', '7', '1', '1', '2', '8', '8', '3', '4', '8', '2', '10', '13', '8', '8', '9', '2', '2', '1', '1', '10', '4', '2', '7', '9', '8', '2', '1', '9', '8', '1', '1', '9', '8', '9', '8', '2', '8', '2', '2', '9', '2', '1', '9', '1', '2', '4', '8', '2', '1', '1', '8', '1', '4', '1', '9', '3', '9', '2', '7', '1', '9', '6', '1', '10', '2', '2', '2', '2', '2', '10', '10', '10', '9', '9', '9', '3', '12', '10', '1', '1', '10', '1', '1', '2', '2', '1', '2', '3', '12', '8', '8', '1', '2', '9', '9', '1', '1', '10', '8', '9', '8', '3', '1', '1', '3', '1', '10', '1', '1', '1', '4', '1', '1', '1', '7', '10', '2', '1', '8', '1', '9', '3', '1', '10', '8', '8', '1', '5', '9', '1', '2', '1', '8', '8', '1', '3', '1', '10', '2', '1', '1', '2', '8', '2', '5', '3', '5', '2', '1', '1', '9', '1', '7', '9', '9', '2', '8', '1', '12', '4', '1', '4', '9', '9', '4', '8', '1', '10', '10', '8', '8', '8', '9', '2', '3', '5', '1', '8', '1', '1', '1', '7', '10', '1', '4', '12', '3', '2', '2', '9', '1', '1', '1', '2', '8', '4', '1', '7', '3', '12', '8', '6', '2', '2', '7', '9', '11', '1', '10', '9', '1', '8', '12', '2', '11', '1', '2', '3', '1', '1', '1', '8', '9', '2', '2', '2', '2', '3', '3', '8', '10', '4', '1', '2', '9', '8', '2', '2', '9', '1', '8', '11', '4', '2', '8', '7', '1', '1', '7', '3', '9', '9', '4', '5', '8', '10', '2', '9', '9', '9', '8', '1', '9', '2', '2', '2', '1', '2', '9', '4', '3', '12', '4', '3', '2', '3', '8', '3', '10', '1', '10', '1', '1', '8', '10', '6', '8', '9', '9', '1', '2', '9', '2', '9', '3', '8', '1', '1', '12', '1', '5', '1', '10', '8', '10', '2', '7', '1', '1', '1', '1', '3', '2', '3', '5', '9', '1', '2', '1', '9', '8', '10', '9', '8', '1', '8', '1', '8', '2', '8', '1', '2', '8', '1', '2', '5', '8', '12', '2', '1', '1', '1', '1', '1', '8', '8', '2', '1', '4', '2', '8', '8', '8', '2', '9', '9', '11', '1', '2', '9', '3', '1', '1', '8', '9', '2', '4', '10', '1', '9', '8', '4', '9', '8', '10', '8', '8', '9', '2', '8', '9', '3', '3', '3', '4', '3', '2', '2', '10', '8', '2', '1', '5', '1', '9', '1', '1', '2', '1', '2', '3', '1', '1', '8', '8', '1', '10', '8', '8', '1', '6', '4', '8', '2', '5', '8', '1', '3', '8', '2', '8', '9', '1', '1', '8', '12', '10', '1', '5', '8', '2', '8', '10', '9', '9', '1', '6', '9', '1', '10', '8', '2', '9', '10', '1', '2', '1', '1', '8', '8', '3', '9', '8', '1', '10', '2', '8', '1', '10', '1', '5', '1', '1', '1', '5', '1', '1', '1', '4', '1', '1', '1', '8', '2', '8', '1', '8', '3', '8', '9', '1', '8', '1', '8', '1', '1', '2', '2', '1', '12', '9', '9', '1', '8', '2', '1', '2', '8', '1', '9', '1', '1', '2', '1', '2', '2', '2', '1', '9', '9', '8', '8', '1', '1', '9', '10', '8', '4', '3', '3', '4', '9', '1', '3', '3', '10', '2', '2', '1', '8', '4', '1', '9', '4', '1', '1', '9', '8', '10', '4', '9', '9', '8', '2', '1', '3', '4', '9', '3', '8', '9', '1', '1', '2', '1', '7', '8', '2', '9', '1', '9', '2', '6', '9', '10', '8', '1', '1', '5', '9', '5', '1', '9', '10', '9', '3', '3', '8', '8', '2', '9', '2', '8', '2', '1', '8', '5', '8', '3', '10', '1', '1', '2', '1', '8', '1', '4', '3', '2', '9', '4', '9', '8', '8', '8', '1', '3', '9', '1', '9', '9', '1', '2', '1', '9', '8', '9', '8', '1', '1', '1', '4', '2', '2', '9', '9', '1', '1', '1', '3', '6', '1', '2', '3', '1', '4', '2', '9', '1', '9', '9', '1', '8', '2', '1', '9', '1', '8', '1', '8', '8', '2', '1', '9', '9', '6', '8', '8', '9', '8', '10', '8', '9', '5', '1', '1', '1', '1', '8', '1', '8', '12', '8', '1', '12', '9', '2', '8', '1', '1', '2', '1', '8', '6', '9', '9', '8', '1', '8', '9', '7', '7', '8', '9', '9', '1', '8', '3', '8', '1', '3', '3', '8', '9', '8', '2', '8', '1', '2', '9', '8', '1', '1', '1', '1', '9', '1', '9', '8', '12', '3', '8', '8', '1', '10', '10', '10', '2', '2', '1', '10', '2', '2', '10', '8', '12', '8', '1', '1', '1', '2', '1', '1', '3', '8', '1', '2', '2', '2', '1', '1', '6', '2', '8', '8', '8', '1', '1', '1', '9', '9', '2', '8', '10', '2', '8', '2', '1', '2', '9', '9', '2', '1', '1', '8', '8', '1', '3', '1', '8', '9', '1', '10', '9', '1', '1', '1', '1', '7', '2', '2', '1', '2', '8', '8', '1', '2', '1', '3', '2', '1', '8', '3', '9', '2', '10', '2', '10', '1', '2', '1', '1', '13', '9', '10', '8', '2', '2', '1', '1', '8', '2', '2', '1', '9', '1', '1', '8', '9', '9', '2', '9', '2', '2', '1', '1', '1', '8', '9', '4', '9', '9', '1', '8', '2', '1', '1', '8', '2', '2', '2', '8', '1', '1', '8', '2', '10', '2', '9', '9', '7', '1', '1', '2', '2', '8', '3', '1', '2', '1', '1', '8', '1', '1', '1', '9', '1', '1', '8', '8', '1', '9', '6', '1', '9', '1', '8', '1', '8', '8', '8', '1', '3', '8', '8', '2', '6', '3', '2', '1', '10', '1', '8', '2', '1', '6', '1', '1', '1', '8', '1', '10', '1', '1', '8', '9', '2', '6', '9', '2', '9', '4', '1', '8', '1', '3', '7', '8', '8', '5', '8', '7', '1', '1', '1', '13', '8', '3', '1', '1', '1', '1', '2', '8', '2', '12', '8', '1', '2', '5', '1', '8', '2', '10', '8', '2', '10', '1', '5', '2', '1', '1', '5', '2', '2', '7', '8', '2', '9', '9', '1', '10', '1', '8', '2', '5', '8', '1', '5', '1', '10', '1', '1', '9', '8', '6', '1', '8', '9', '8', '1', '8', '2', '2', '8', '3', '9', '1', '9', '3', '8', '4', '4', '3', '3', '1', '1', '1', '8', '9', '1', '1', '8', '3', '1', '2', '8', '2', '1', '1', '10', '1', '2', '2', '1', '1', '8', '2', '8', '2', '10', '2', '2', '10', '8', '8', '8', '13', '2', '2', '9', '2', '5', '9', '2', '1', '8', '8', '8', '1', '12', '12', '2', '9', '2', '1', '8', '2', '1', '8', '1', '9', '9', '2', '7', '1', '1', '7', '1', '4', '3', '1', '10', '3', '10', '9', '4', '6', '7', '5', '2', '1', '8', '8', '1', '4', '9', '2', '1', '8', '1', '1', '1', '1', '1', '8', '9', '8', '8', '8', '8', '9', '8', '10', '1', '8', '2', '7', '8', '9', '1', '2', '5', '9', '10', '8', '9', '12', '1', '6', '1', '2', '10', '9', '4', '1', '8', '10', '10', '1', '1', '1', '1', '1', '2', '3', '8', '1', '2', '10', '2', '1', '2', '4', '2', '2', '9', '1', '4', '2', '1', '1', '12', '12', '9', '9', '7', '1', '8', '4', '9', '9', '8', '1', '7', '3', '2', '1', '1', '4', '8', '1', '5', '8', '2', '8', '1', '14', '9', '12', '1', '10', '2', '1', '1', '8', '8', '6', '6', '3', '1', '2', '8', '1', '3', '2', '1', '8', '8', '1', '10', '8', '2', '8', '2', '5', '9', '1', '8', '8', '1', '1', '8', '8', '13', '1', '3', '8', '4', '1', '9', '7', '8', '8', '8', '3', '8', '1', '4', '2', '8', '8', '8', '7', '1', '1', '2', '8', '8', '9', '8', '8', '2', '3', '9', '9', '2', '1', '2', '2', '1', '8', '2', '6', '2', '1', '1', '9', '10', '3', '8', '2', '3', '2', '8', '8', '1', '8', '8', '8', '9', '1', '4', '1', '9', '2', '1', '8', '0', '1', '8', '1', '1', '8', '9', '9', '1', '3', '1', '2', '8', '8', '7', '1', '1', '2', '9', '2', '10', '2', '8', '2', '2', '2', '7', '1', '9', '8', '1', '3', '9', '2', '1', '10', '8', '1', '4', '1', '8', '5', '9', '8', '8', '1', '2', '2', '1', '8', '8', '6', '8', '1', '1', '8', '3', '2', '2', '1', '8', '1', '7', '6', '8', '1', '1', '1', '9', '1', '1', '1', '2', '1', '11', '10', '10', '11', '9', '']\n",
            "['8', '1', '8', '2', '8', '8', '8', '9', '7', '8', '1', '2', '1', '1', '8', '4', '8', '8', '12', '3', '3', '7', '3', '12', '1', '8', '8', '8', '8', '8', '8', '8', '1', '9', '5', '9', '9', '9', '11', '8', '8', '8', '4', '8', '8', '8', '8', '1', '3', '9', '3', '7', '1', '2', '9', '9', '7', '8', '8', '1', '10', '7', '8', '8', '9', '8', '7', '9', '9', '12', '7', '2', '8', '1', '11', '11', '1', '7', '7', '12', '1', '9', '8', '10', '12', '7', '8', '2', '8', '9', '9', '1', '8', '9', '1', '7', '12', '10', '10', '10', '8', '3', '7', '9', '8', '9', '1', '8', '8', '2', '7', '2', '9', '9', '11', '8', '8', '12', '12', '7', '8', '12', '4', '9', '3', '1', '12', '1', '1', '8', '8', '3', '8', '8', '8', '8', '9', '1', '8', '8', '10', '1', '8', '2', '8', '8', '7', '3', '8', '2', '4', '4', '9', '8', '10', '12', '12', '1', '1', '9', '1', '1', '1', '8', '2', '2', '8', '1', '1', '2', '2', '1', '2', '8', '1', '9', '9', '8', '8', '4', '2', '9', '9', '8', '3', '4', '3', '1', '8', '8', '2', '1', '9', '7', '8', '8', '1', '12', '3', '8', '2', '4', '2', '9', '12', '1', '4', '1', '8', '8', '8', '2', '2', '8', '9', '8', '8', '8', '10', '9', '8', '7', '9', '1', '1', '9', '4', '2', '4', '2', '2', '1', '7', '8', '11', '11', '3', '9', '2', '4', '8', '9', '1', '8', '1', '1', '4', '9', '1', '1', '8', '8', '2', '1', '8', '4', '2', '8', '9', '8', '8', '2', '8', '8', '8', '7', '1', '1', '1', '2', '1', '1', '8', '7', '8', '8', '12', '2', '12', '12', '8', '10', '12', '8', '3', '3', '12', '10', '1', '8', '12', '1', '8', '8', '2', '8', '4', '7', '8', '7', '10', '8', '10', '9', '8', '12', '12', '1', '8', '8', '3', '8', '8', '8', '8', '8', '1', '9', '8', '11', '1', '1', '1', '9', '8', '1', '9', '2', '3', '11', '8', '9', '9', '9', '2', '1', '8', '8', '9', '7', '1', '4', '9', '4', '8', '8', '4', '8', '12', '9', '4', '8', '2', '10', '10', '10', '8', '9', '9', '8', '8', '12', '7', '1', '8', '8', '8', '4', '1', '1', '1', '1', '1', '1', '8', '1', '9', '8', '9', '9', '4', '8', '12', '9', '8', '8', '2', '8', '8', '8', '6', '9', '8', '3', '7', '8', '8', '4', '12', '8', '8', '9', '12', '12', '9', '8', '2', '9', '2', '3', '1', '12', '8', '10', '9', '9', '9', '10', '10', '3', '8', '12', '1', '4', '2', '1', '10', '8', '2', '8', '4', '8', '9', '1', '9', '9', '10', '10', '1', '4', '9', '2', '4', '9', '1', '1', '3', '10', '3', '3', '8', '7', '3', '8', '9', '9', '12', '4', '8', '12', '2', '2', '4', '1', '9', '9', '4', '1', '4', '2', '8', '12', '2', '3', '10', '10', '9', '8', '9', '9', '1', '12', '8', '8', '8', '12', '4', '1', '8', '8', '1', '9', '8', '8', '2', '1', '8', '9', '8', '3', '3', '3', '1', '8', '8', '9', '1', '10', '9', '9', '9', '9', '5', '9', '9', '8', '8', '8', '8', '8', '8', '8', '8', '11', '12', '8', '8', '1', '8', '9', '11', '2', '2', '2', '2', '3', '1', '2', '2', '8', '2', '4', '9', '1', '2', '9', '8', '2', '8', '9', '9', '3', '10', '9', '9', '2', '8', '9', '8', '12', '12', '1', '3', '8', '8', '8', '2', '7', '7', '7', '7', '3', '9', '1', '9', '8', '9', '9', '1', '1', '1', '2', '9', '9', '9', '11', '1', '8', '8', '9', '1', '9', '8', '8', '8', '1', '1', '8', '7', '1', '1', '8', '8', '9', '4', '4', '8', '2', '2', '8', '8', '8', '8', '8', '8', '11', '8', '2', '9', '4', '9', '3', '9', '9', '1', '3', '9', '3', '1', '12', '8', '9', '12', '1', '8', '4', '2', '1', '4', '8', '3', '3', '8', '2', '8', '9', '7', '8', '8', '8', '5', '8', '3', '9', '8', '8', '13', '12', '1', '1', '2', '8', '4', '1', '9', '9', '12', '8', '9', '12', '9', '1', '9', '9', '9', '9', '3', '2', '9', '9', '4', '8', '12', '2', '4', '9', '3', '1', '9', '7', '8', '9', '9', '8', '4', '8', '8', '7', '9', '10', '3', '8', '8', '8', '1', '1', '1', '1', '8', '8', '4', '1', '10', '1', '5', '7', '7', '1', '8', '9', '3', '7', '2', '7', '7', '2', '4', '8', '12', '7', '4', '2', '9', '9', '12', '6', '10', '8', '2', '4', '12', '9', '9', '3', '8', '8', '1', '2', '10', '9', '9', '8', '4', '12', '2', '1', '8', '8', '8', '12', '10', '10', '9', '3', '8', '8', '9', '2', '8', '10', '1', '1', '1', '1', '2', '1', '1', '1', '1', '9', '8', '12', '9', '4', '8', '8', '9', '1', '9', '3', '9', '8', '8', '1', '7', '7', '10', '1', '8', '8', '1', '9', '8', '10', '3', '1', '7', '1', '8', '8', '12', '8', '8', '1', '8', '7', '1', '7', '7', '8', '2', '1', '8', '8', '2', '10', '8', '8', '8', '8', '8', '10', '1', '8', '8', '12', '8', '3', '3', '2', '2', '2', '10', '8', '8', '8', '2', '9', '1', '8', '9', '3', '2', '8', '10', '8', '6', '1', '1', '8', '4', '1', '9', '10', '8', '1', '7', '1', '2', '8', '1', '1', '1', '12', '1', '9', '12', '8', '12', '12', '12', '8', '8', '12', '4', '8', '8', '8', '8', '9', '9', '1', '3', '3', '3', '3', '1', '12', '12', '9', '10', '8', '8', '1', '9', '2', '2', '13', '9', '8', '9', '2', '1', '9', '1', '8', '8', '8', '4', '8', '1', '1', '1', '12', '12', '7', '2', '2', '2', '8', '3', '8', '9', '2', '10', '7', '8', '9', '2', '1', '2', '12', '12', '8', '8', '9', '2', '2', '9', '11', '1', '8', '1', '10', '9', '2', '1', '4', '7', '7', '7', '7', '7', '12', '8', '8', '8', '1', '1', '10', '1', '12', '1', '8', '2', '1', '1', '12', '8', '7', '9', '12', '8', '9', '3', '9', '8', '8', '8', '8', '3', '11', '2', '2', '9', '8', '8', '10', '8', '2', '7', '3', '1', '4', '7', '8', '8', '1', '8', '3', '7', '12', '8', '10', '9', '9', '8', '8', '2', '8', '9', '9', '1', '2', '8', '8', '9', '8', '3', '8', '1', '8', '10', '9', '8', '9', '9', '12', '4', '4', '8', '9', '9', '8', '2', '10', '1', '2', '8', '9', '1', '9', '9', '9', '7', '12', '12', '8', '1', '1', '1', '1', '8', '3', '1', '1', '8', '1', '8', '8', '7', '8', '8', '8', '8', '3', '2', '2', '10', '10', '10', '7', '8', '1', '2', '12', '7', '9', '8', '7', '8', '12', '2', '8', '9', '2', '6', '6', '7', '9', '8', '1', '8', '9', '8', '1', '12', '1', '2', '8', '7', '7', '7', '8', '2', '2', '8', '1', '2', '2', '9', '9', '1', '8', '8', '4', '3', '3', '1', '6', '3', '3', '12', '3', '8', '9', '1', '4', '3', '1', '8', '3', '9', '2', '8', '2', '8', '8', '8', '1', '1', '1', '9', '9', '8', '1', '9', '8', '1', '1', '3', '10', '8', '1', '1', '3', '9', '1', '4', '4', '1', '8', '9', '9', '2', '0', '0', '1', '8', '3', '1', '8', '8', '9', '8', '8', '1', '1', '8', '9', '8', '8', '8', '7', '9', '8', '8', '8', '10', '9', '8', '1', '2', '6', '1', '9', '9', '8', '12', '12', '12', '8', '8', '2', '8', '1', '2', '2', '2', '1', '9', '8', '2', '12', '2', '8', '12', '8', '9', '8', '8', '9', '7', '1', '1', '1', '1', '1', '8', '8', '1', '8', '8', '1', '1', '3', '2', '8', '8', '9', '10', '10', '2', '2', '1', '9', '2', '9', '9', '4', '12', '12', '12', '10', '7', '3', '3', '4', '2', '2', '9', '2', '8', '4', '2', '4', '1', '10', '9', '7', '8', '7', '1', '1', '3', '3', '1', '1', '3', '3', '3', '1', '1', '1', '1', '8', '2', '3', '1', '1', '2', '8', '8', '12', '8', '8', '8', '8', '11', '9', '1', '8', '9', '2', '8', '8', '8', '3', '9', '1', '9', '2', '7', '2', '8', '2', '8', '10', '8', '1', '10', '1', '1', '9', '9', '8', '8', '1', '8', '8', '8', '12', '8', '8', '8', '1', '8', '8', '8', '1', '9', '1', '1', '8', '1', '8', '9', '8', '2', '12', '9', '9', '0', '1', '8', '8', '1', '8', '12', '8', '8', '10', '8', '8', '8', '7', '8', '1', '8', '7', '3', '10', '1', '8', '9', '1', '8', '8', '8', '10', '1', '10', '3', '9', '1', '8', '9', '2', '8', '3', '3', '9', '9', '7', '9', '1', '1', '9', '2', '1', '1', '1', '7', '1', '1', '8', '8', '1', '1', '8', '1', '8', '3', '12', '9', '3', '3', '8', '8', '8', '8', '3', '1', '3', '3', '1', '11', '0', '8', '8', '7', '8', '12', '1', '8', '9', '8', '9', '8', '8', '3', '8', '8', '1', '1', '1', '9', '2', '2', '2', '8', '7', '12', '8', '8', '9', '10', '10', '7', '8', '1', '9', '8', '7', '3', '1', '3', '8', '2', '2', '3', '9', '8', '4', '4', '8', '9', '2', '1', '1', '7', '8', '9', '9', '7', '8', '7', '7', '8', '2', '2', '8', '4', '9', '7', '10', '0', '9', '8', '3', '7', '8', '1', '1', '8', '9', '9', '2', '2', '10', '1', '9', '10', '10', '10', '8', '3', '2', '12', '9', '9', '10', '12', '9', '12', '12', '9', '1', '2', '4', '12', '12', '7', '8', '9', '7', '7', '7', '3', '9', '8', '9', '1', '12', '8', '9', '4', '1', '3', '12', '12', '12', '12', '8', '8', '2', '1', '1', '2', '1', '1', '1', '12', '12', '8', '12', '2', '2', '12', '3', '3', '12', '8', '2', '8', '8', '12', '2', '1', '10', '3', '2', '8', '7', '1', '8', '1', '3', '7', '8', '9', '8', '3', '1', '1', '7', '8', '8', '9', '8', '2', '9', '2', '2', '9', '8', '1', '8', '8', '1', '3', '3', '1', '1', '10', '1', '2', '8', '1', '1', '1', '1', '9', '1', '4', '1', '7', '7', '7', '7', '2', '2', '8', '8', '12', '1', '9', '1', '7', '3', '3', '1', '8', '8', '10', '8', '9', '2', '9', '1', '3', '8', '8', '3', '12', '2', '8', '12', '2', '9', '1', '3', '3', '3', '3', '2', '8', '7', '9', '8', '3', '3', '1', '7', '8', '3', '1', '1', '12', '8', '9', '1', '2', '3', '8', '1', '1', '3', '3', '9', '1', '1', '1', '12', '1', '7', '3', '3', '1', '8', '8', '8', '1', '2', '4', '8', '1', '10', '2', '5', '3', '3', '12', '10', '9', '9', '12', '9', '0', '2', '8', '8', '9', '9', '9', '8', '1', '3', '1', '1', '4', '8', '1', '10', '8', '7', '2', '8', '2', '8', '4', '7', '8', '1', '9', '1', '9', '8', '2', '8', '2', '7', '9', '2', '2', '9', '1', '8', '12', '1', '8', '1', '4', '1', '9', '9', '1', '10', '12', '4', '8', '1', '7', '3', '9', '2', '12', '7', '8', '8', '2', '1', '12', '9', '8', '1', '2', '2', '8', '10', '2', '1', '7', '7', '7', '12', '3', '3', '8', '3', '8', '8', '3', '9', '8', '9', '1', '1', '8', '7', '9', '3', '3', '8', '1', '0', '9', '9', '9', '1', '8', '9', '9', '10', '1', '8', '7', '8', '8', '8', '9', '9', '8', '9', '10', '4', '9', '3', '7', '12', '1', '9', '9', '8', '9', '1', '9', '3', '1', '8', '4', '12', '10', '9', '8', '7', '10', '8', '12', '12', '3', '10', '8', '12', '2', '1', '2', '3', '9', '8', '8', '7', '1', '1', '2', '2', '1', '2', '2', '7', '1', '3', '9', '9', '3', '8', '8', '8', '8', '8', '7', '8', '8', '10', '8', '1', '8', '2', '8', '2', '2', '2', '2', '2', '1', '7', '12', '10', '1', '2', '8', '1', '4', '7', '8', '1', '12', '8', '7', '9', '2', '2', '2', '8', '1', '8', '1', '1', '0', '2', '2', '6', '1', '8', '2', '1', '8', '1', '1', '2', '2', '3', '2', '2', '10', '10', '9', '1', '7', '7', '8', '8', '1', '12', '10', '12', '3', '8', '8', '8', '3', '8', '3', '10', '2', '2', '2', '1', '2', '2', '1', '0', '1', '8', '9', '1', '1', '1', '2', '2', '2', '2', '2', '1', '1', '1', '1', '12', '9', '9', '1', '10', '11', '12', '9', '1', '1', '8', '8', '1', '2', '12', '8', '3', '7', '2', '10', '9', '7', '8', '1', '2', '2', '7', '9', '12', '2', '2', '1', '8', '9', '2', '3', '2', '2', '2', '9', '9', '8', '9', '2', '3', '8', '8', '9', '7', '3', '10', '8', '8', '9', '1', '1', '2', '8', '1', '10', '8', '8', '9', '7', '1', '7', '12', '8', '1', '7', '2', '1', '3', '9', '2', '8', '8', '1', '2', '3', '9', '3', '8', '9', '7', '7', '1', '10', '2', '8', '8', '8', '1', '8', '2', '8', '8', '1', '2', '8', '10', '2', '1', '0', '8', '3', '8', '10', '10', '12', '3', '8', '9', '3', '10', '8', '8', '8', '1', '8', '8', '2', '2', '2', '2', '2', '2', '1', '1', '10', '1', '10', '8', '2', '1', '2', '2', '8', '3', '3', '2', '2', '1', '8', '1', '3', '1', '9', '2', '2', '1', '3', '2', '2', '3', '2', '2', '3', '2', '1', '1', '2', '1', '2', '7', '8', '2', '1', '12', '12', '3', '1', '9', '9', '7', '8', '7', '2', '7', '9', '2', '2', '2', '8', '9', '7', '9', '2', '8', '9', '9', '2', '9', '1', '1', '9', '8', '3', '3', '8', '2', '7', '8', '11', '2', '8', '9', '1', '8', '3', '1', '2', '1', '2', '2', '2', '2', '8', '3', '9', '2', '10', '9', '9', '2', '7', '7', '7', '1', '3', '8', '8', '1', '1', '8', '7', '1', '8', '8', '9', '3', '3', '3', '2', '4', '8', '12', '8', '1', '12', '9', '2', '8', '2', '12', '2', '1', '3', '8', '12', '12', '11', '8', '10', '9', '2', '9', '4', '10', '1', '12', '12', '9', '3', '8', '9', '12', '9', '9', '2', '2', '2', '3', '5', '1', '1', '1', '7', '7', '8', '2', '2', '8', '2', '1', '7', '3', '2', '9', '8', '9', '1', '1', '9', '8', '9', '3', '3', '2', '9', '4', '9', '8', '8', '1', '8', '10', '2', '0', '3', '8', '8', '8', '9', '12', '9', '8', '2', '2', '8', '10', '9', '8', '2', '2', '4', '1', '9', '9', '8', '8', '10', '3', '1', '1', '2', '8', '7', '8', '2', '1', '1', '8', '12', '2', '9', '4', '8', '3', '3', '3', '8', '2', '12', '12', '8', '9', '12', '8', '2', '12', '7', '9', '2', '2', '1', '3', '1', '3', '11', '9', '8', '1', '10', '2', '12', '3', '8', '4', '1', '2', '8', '8', '3', '9', '3', '8', '7', '1', '1', '3', '1', '8', '2', '9', '8', '12', '1', '1', '1', '9', '9', '1', '8', '8', '8', '2', '2', '12', '3', '1', '1', '1', '9', '9', '3', '2', '1', '1', '9', '9', '1', '9', '9', '1', '9', '3', '9', '1', '8', '1', '9', '8', '3', '8', '8', '9', '9', '8', '2', '8', '1', '2', '2', '10', '1', '2', '1', '1', '9', '1', '9', '3', '7', '7', '2', '10', '3', '3', '1', '1', '9', '1', '2', '1', '3', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '8', '8', '7', '1', '1', '8', '8', '2', '1', '12', '1', '8', '1', '9', '8', '8', '2', '1', '9', '9', '2', '2', '8', '1', '7', '7', '9', '8', '1', '6', '8', '8', '2', '2', '8', '3', '8', '3', '2', '3', '8', '1', '2', '2', '2', '8', '9', '9', '9', '12', '1', '9', '2', '1', '9', '2', '9', '9', '10', '8', '1', '1', '9', '2', '1', '7', '1', '3', '7', '1', '1', '1', '3', '8', '8', '8', '9', '9', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '1', '0', '1', '1', '1', '2', '2', '3', '1', '1', '2', '3', '3', '3', '7', '3', '1', '9', '3', '9', '1', '4', '1', '1', '9', '10', '9', '8', '2', '3', '10', '9', '3', '10', '12', '8', '9', '8', '2', '1', '9', '8', '1', '7', '8', '1', '9', '1', '2', '10', '7', '7', '8', '1', '3', '3', '9', '3', '3', '1', '1', '1', '9', '1', '3', '8', '8', '8', '1', '8', '1', '9', '7', '8', '8', '2', '1', '3', '8', '2', '1', '6', '1', '8', '8', '2', '8', '2', '2', '9', '8', '1', '1', '6', '8', '6', '10', '2', '1', '1', '8', '9', '3', '3', '3', '1', '3', '9', '6', '8', '1', '8', '3', '1', '2', '2', '12', '7', '1', '1', '1', '1', '12', '1', '8', '8', '3', '2', '1', '9', '2', '3', '3', '2', '2', '7', '2', '2', '2', '3', '1', '9', '8', '7', '1', '1', '3', '1', '9', '4', '3', '9', '2', '1', '1', '9', '8', '8', '7', '2', '1', '3', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '10', '1', '1', '8', '2', '8', '1', '8', '1', '3', '1', '2', '1', '1', '3', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '8', '1', '9', '8', '8', '1', '10', '8', '8', '1', '3', '9', '8', '9', '8', '2', '1', '3', '4', '1', '12', '1', '9', '8', '2', '7', '2', '1', '2', '9', '2', '1', '3', '8', '1', '2', '3', '8', '2', '10', '10', '10', '9', '9', '9', '3', '8', '3', '1', '1', '1', '1', '1', '1', '2', '1', '9', '2', '7', '9', '8', '7', '9', '1', '1', '1', '1', '8', '2', '2', '3', '3', '2', '12', '8', '3', '1', '1', '12', '9', '8', '2', '2', '9', '1', '2', '2', '9', '1', '1', '2', '4', '8', '1', '8', '10', '2', '9', '9', '9', '1', '2', '1', '1', '2', '2', '2', '12', '1', '2', '8', '3', '9', '9', '3', '2', '9', '9', '7', '2', '8', '8', '9', '2', '9', '1', '1', '1', '1', '1', '2', '8', '2', '1', '2', '2', '8', '3', '1', '1', '9', '1', '3', '10', '7', '9', '8', '8', '2', '2', '9', '2', '2', '2', '2', '2', '2', '9', '1', '3', '6', '4', '2', '2', '9', '1', '9', '8', '1', '1', '1', '7', '3', '2', '9', '9', '1', '9', '7', '2', '8', '9', '9', '12', '10', '8', '10', '2', '3', '1', '2', '2', '12', '12', '3', '12', '1', '2', '1', '2', '1', '2', '8', '2', '3', '12', '12', '8', '2', '2', '9', '2', '9', '2', '3', '3', '1', '1', '1', '12', '3', '7', '1', '3', '1', '2', '9', '2', '7', '2', '1', '8', '3', '7', '8', '1', '1', '3', '8', '3', '2', '9', '3', '1', '1', '1', '1', '11', '1', '2', '6', '1', '2', '3', '8', '9', '9', '2', '9', '2', '1', '1', '3', '1', '12', '9', '1', '1', '9', '1', '9', '9', '8', '9', '8', '1', '2', '7', '1', '0', '9', '8', '2', '3', '2', '4', '1', '1', '1', '8', '1', '12', '1', '2', '3', '3', '9', '9', '9', '9', '9', '7', '9', '3', '9', '1', '7', '3', '3', '3', '3', '7', '8', '2', '2', '2', '8', '2', '3', '9', '9', '3', '1', '8', '9', '12', '8', '8', '3', '2', '1', '6', '1', '9', '1', '1', '1', '1', '1', '1', '2', '2', '1', '2', '2', '2', '2', '9', '2', '5', '3', '2', '2', '8', '2', '1', '8', '3', '3', '8', '3', '1', '3', '9', '2', '8', '9', '4', '4', '9', '8', '8', '7', '7', '3', '1', '8', '8', '3', '2', '2', '10', '3', '3', '2', '2', '2', '2', '12', '3', '1', '2', '7', '7', '12', '2', '1', '2', '1', '1', '2', '1', '3', '3', '3', '1', '3', '9', '4', '8', '8', '4', '2', '4', '2', '8', '9', '1', '1', '2', '2', '2', '8', '7', '2', '8', '2', '9', '1', '8', '1', '1', '2', '1', '1', '1', '2', '9', '9', '8', '1', '8', '1', '4', '8', '1', '2', '7', '9', '2', '1', '8', '9', '8', '9', '1', '1', '2', '3', '2', '12', '7', '1', '2', '4', '4', '4', '2', '2', '2', '9', '8', '8', '1', '12', '3', '3', '2', '2', '3', '12', '1', '5', '1', '1', '3', '2', '8', '8', '2', '2', '2', '3', '9', '8', '8', '9', '8', '8', '11', '8', '2', '9', '2', '3', '1', '7', '1', '8', '2', '8', '1', '1', '1', '8', '1', '1', '1', '7', '8', '8', '2', '3', '2', '1', '8', '8', '1', '8', '4', '8', '9', '8', '9', '8', '1', '2', '3', '2', '1', '2', '2', '3', '1', '9', '4', '8', '1', '1', '9', '1', '1', '8', '2', '2', '2', '1', '7', '3', '3', '1', '3', '3', '12', '3', '1', '1', '3', '1', '1', '4', '8', '4', '4', '3', '3', '3', '4', '8', '1', '9', '9', '9', '4', '1', '7', '4', '8', '4', '9', '8', '1', '1', '3', '8', '9', '1', '9', '7', '1', '1', '9', '1', '8', '8', '8', '1', '1', '8', '2', '2', '2', '9', '4', '4', '1', '2', '1', '2', '9', '1', '1', '8', '5', '5', '5', '9', '12', '4', '1', '2', '1', '8', '8', '1', '9', '9', '2', '12', '1', '1', '7', '8', '8', '4', '1', '2', '8', '11', '2', '3', '2', '2', '1', '11', '2', '2', '2', '2', '9', '9', '2', '2', '9', '3', '1', '9', '1', '1', '1', '7', '8', '1', '8', '9', '1', '2', '9', '8', '1', '2', '9', '8', '12', '2', '2', '10', '8', '2', '2', '8', '8', '1', '2', '6', '1', '1', '7', '7', '2', '3', '2', '1', '1', '8', '1', '10', '8', '12', '6', '4', '1', '4', '1', '2', '9', '8', '9', '4', '8', '8', '10', '8', '8', '8', '8', '8', '2', '2', '8', '4', '9', '3', '3', '3', '3', '3', '9', '2', '1', '1', '2', '3', '2', '1', '2', '3', '3', '3', '2', '2', '3', '3', '2', '1', '2', '3', '3', '3', '3', '12', '9', '3', '2', '2', '3', '1', '5', '1', '1', '3', '2', '2', '1', '2', '9', '3', '9', '8', '1', '8', '7', '7', '9', '1', '1', '7', '9', '10', '1', '7', '1', '4', '3', '8', '9', '4', '9', '9', '2', '9', '2', '8', '4', '2', '2', '9', '5', '2', '1', '10', '9', '3', '1', '1', '1', '2', '1', '2', '9', '1', '7', '9', '9', '8', '2', '2', '8', '9', '1', '9', '8', '2', '3', '2', '2', '1', '2', '2', '2', '1', '1', '8', '1', '9', '4', '12', '8', '2', '7', '2', '2', '1', '9', '3', '1', '8', '12', '1', '1', '2', '1', '10', '2', '6', '12', '12', '4', '9', '1', '9', '10', '1', '2', '8', '2', '1', '8', '6', '12', '9', '9', '2', '1', '7', '8', '9', '5', '8', '1', '8', '8', '3', '1', '8', '2', '8', '2', '2', '1', '2', '9', '2', '8', '1', '12', '8', '2', '7', '3', '3', '12', '2', '3', '3', '9', '9', '3', '3', '3', '3', '3', '2', '1', '4', '1', '4', '8', '8', '2', '1', '2', '9', '12', '1', '10', '12', '1', '2', '9', '4', '8', '10', '3', '2', '8', '7', '4', '8', '9', '2', '7', '1', '10', '2', '2', '2', '8', '4', '2', '2', '1', '1', '8', '7', '9', '2', '1', '9', '8', '9', '12', '4', '8', '2', '8', '7', '7', '1', '9', '2', '1', '1', '9', '1', '8', '2', '3', '9', '9', '1', '3', '2', '9', '2', '2', '8', '1', '1', '2', '1', '2', '1', '9', '8', '2', '2', '4', '8', '8', '9', '5', '5', '9', '8', '9', '6', '2', '1', '12', '2', '3', '8', '8', '9', '2', '2', '1', '3', '2', '10', '9', '10', '7', '2', '8', '4', '2', '8', '9', '8', '1', '3', '8', '8', '1', '8', '3', '8', '8', '1', '10', '3', '1', '5', '8', '8', '9', '2', '2', '9', '2', '1', '9', '1', '4', '1', '12', '8', '8', '2', '1', '1', '1', '1', '1', '9', '2', '9', '8', '9', '5', '9', '1', '8', '2', '4', '1', '1', '1', '9', '12', '4', '1', '1', '9', '8', '4', '1', '8', '9', '8', '8', '9', '9', '9', '9', '9', '9', '1', '3', '4', '2', '2', '8', '2', '9', '2', '3', '8', '3', '1', '7', '2', '1', '1', '4', '2', '9', '2', '1', '3', '2', '9', '2', '9', '3', '8', '1', '9', '1', '1', '2', '8', '8', '8', '2', '3', '9', '9', '8', '2', '4', '1', '5', '1', '1', '9', '9', '2', '1', '1', '1', '9', '9', '1', '3', '9', '2', '2', '9', '9', '8', '3', '9', '9', '8', '2', '2', '8', '9', '2', '2', '8', '9', '10', '10', '2', '8', '7', '9', '9', '4', '2', '4', '11', '2', '1', '7', '8', '8', '8', '9', '4', '9', '8', '8', '2', '1', '1', '9', '8', '3', '3', '8', '8', '7', '9', '1', '3', '4', '8', '10', '2', '4', '4', '8', '2', '8', '2', '8', '9', '2', '1', '2', '2', '3', '1', '9', '4', '5', '9', '9', '1', '1', '1', '1', '1', '1', '7', '1', '1', '1', '8', '1', '1', '1', '1', '1', '9', '1', '2', '1', '12', '9', '3', '9', '9', '4', '1', '9', '1', '1', '2', '11', '9', '3', '2', '2', '2', '4', '2', '3', '2', '7', '7', '8', '1', '10', '9', '5', '7', '1', '10', '8', '1', '2', '7', '1', '12', '5', '8', '4', '2', '9', '9', '8', '2', '9', '8', '8', '10', '2', '3', '2', '7', '2', '8', '10', '3', '2', '9', '9', '9', '1', '1', '1', '1', '8', '2', '10', '9', '8', '1', '2', '2', '2', '1', '2', '1', '3', '9', '12', '2', '2', '4', '8', '1', '3', '9', '4', '9', '1', '9', '9', '2', '1', '1', '9', '7', '10', '3', '10', '2', '9', '2', '9', '2', '8', '2', '1', '2', '3', '1', '1', '1', '8', '5', '8', '3', '1', '1', '4', '2', '2', '1', '3', '8', '2', '1', '1', '1', '2', '9', '4', '1', '8', '1', '2', '8', '2', '9', '2', '2', '5', '5', '2', '5', '2', '1', '8', '8', '1', '3', '12', '2', '4', '3', '2', '2', '2', '6', '2', '3', '3', '1', '8', '2', '2', '1', '1', '8', '8', '10', '1', '9', '2', '9', '12', '0', '2', '1', '3', '2', '2', '1', '2', '1', '9', '9', '2', '9', '8', '8', '1', '7', '8', '1', '2', '6', '9', '8', '10', '1', '12', '2', '2', '1', '8', '2', '1', '12', '7', '4', '2', '10', '2', '2', '1', '2', '1', '2', '1', '1', '2', '1', '9', '8', '10', '2', '10', '9', '9', '12', '5', '3', '2', '8', '2', '8', '3', '3', '1', '4', '9', '10', '2', '4', '8', '1', '2', '10', '12', '12', '3', '1', '1', '2', '9', '6', '6', '1', '9', '1', '8', '1', '8', '8', '8', '8', '2', '2', '2', '8', '8', '2', '1', '1', '1', '1', '1', '8', '8', '5', '8', '8', '1', '8', '9', '9', '1', '7', '12', '9', '9', '7', '2', '2', '7', '8', '9', '8', '2', '9', '6', '3', '4', '8', '4', '1', '2', '9', '8', '8', '8', '2', '1', '1', '8', '8', '3', '1', '9', '9', '7', '1', '2', '2', '2', '9', '4', '1', '2', '12', '1', '8', '2', '1', '9', '1', '8', '9', '9', '2', '5', '4', '2', '1', '2', '8', '12', '8', '10', '3', '8', '8', '8', '2', '2', '8', '2', '8', '2', '4', '8', '10', '2', '7', '2', '1', '8', '8', '9', '5', '8', '1', '12', '7', '10', '2', '2', '2', '1', '4', '8', '12', '1', '8', '2', '2', '9', '1', '8', '3', '1', '1', '5', '10', '2', '1', '2', '4', '8', '9', '3', '2', '8', '7', '4', '4', '9', '9', '2', '8', '1', '1', '2', '4', '7', '1', '9', '1', '1', '1', '8', '4', '1', '3', '1', '2', '2', '9', '1', '8', '8', '2', '2', '9', '9', '1', '8', '8', '1', '9', '8', '8', '2', '2', '2', '2', '1', '1', '1', '7', '4', '1', '1', '4', '2', '3', '3', '2', '3', '9', '2', '8', '2', '1', '5', '1', '2', '2', '1', '3', '5', '2', '9', '1', '1', '9', '8', '1', '4', '8', '1', '8', '2', '4', '8', '4', '7', '9', '8', '1', '2', '2', '4', '4', '11', '3', '11', '1', '3', '8', '1', '9', '6', '8', '9', '3', '9', '8', '9', '2', '3', '3', '7', '1', '7', '2', '9', '9', '1', '8', '8', '1', '5', '5', '8', '8', '1', '2', '1', '3', '9', '9', '5', '9', '8', '1', '4', '3', '8', '1', '1', '2', '1', '8', '9', '8', '2', '2', '2', '1', '2', '4', '10', '8', '1', '9', '1', '8', '1', '1', '9', '9', '8', '11', '1', '8', '2', '1', '2', '8', '2', '8', '8', '2', '9', '6', '10', '1', '8', '6', '4', '5', '11', '2', '2', '8', '1', '8', '1', '8', '1', '4', '8', '1', '1', '1', '8', '3', '7', '3', '3', '7', '1', '1', '4', '8', '1', '6', '4', '2', '2', '1', '1', '1', '1', '6', '2', '2', '8', '1', '8', '5', '5', '2', '1', '1', '2', '3', '7', '1', '1', '6', '2', '9', '3', '9', '8', '9', '2', '1', '4', '2', '9', '13', '9', '2', '8', '12', '4', '1', '1', '9', '5', '1', '1', '1', '1', '8', '2', '1', '1', '2', '9', '0', '12', '1', '1', '8', '9', '8', '3', '2', '2', '12', '8', '2', '2', '2', '1', '10', '1', '9', '8', '9', '5', '2', '2', '9', '2', '8', '4', '8', '3', '7', '9', '2', '2', '7', '2', '2', '8', '1', '1', '9', '10', '9', '8', '2', '9', '0', '7', '1', '1', '1', '9', '8', '2', '8', '12', '8', '3', '2', '8', '8', '7', '7', '8', '12', '2', '1', '3', '9', '2', '2', '8', '2', '8', '8', '12', '8', '8', '1', '8', '9', '2', '4', '4', '7', '2', '1', '1', '9', '3', '7', '1', '3', '9', '8', '2', '2', '3', '1', '3', '10', '2', '3', '7', '1', '8', '1', '1', '10', '3', '10', '8', '4', '1', '2', '4', '3', '10', '9', '3', '9', '5', '8', '7', '2', '9', '3', '3', '2', '11', '8', '1', '1', '7', '2', '7', '2', '9', '4', '8', '1', '12', '8', '7', '9', '1', '0', '2', '6', '4', '9', '3', '2', '4', '12', '9', '8', '5', '9', '2', '8', '4', '6', '8', '9', '3', '1', '8', '7', '3', '1', '1', '1', '8', '9', '1', '8', '7', '9', '8', '2', '1', '2', '2', '3', '2', '2', '1', '1', '4', '9', '7', '3', '2', '8', '8', '9', '1', '9', '7', '4', '2', '2', '8', '5', '9', '1', '5', '7', '1', '4', '6', '9', '10', '1', '8', '2', '9', '1', '9', '2', '9', '8', '2', '9', '9', '11', '2', '12', '2', '2', '9', '4', '8', '1', '9', '9', '2', '8', '9', '1', '2', '9', '3', '8', '8', '1', '7', '8', '8', '2', '3', '2', '2', '2', '2', '9', '8', '10', '2', '2', '1', '9', '11', '1', '8', '8', '2', '4', '2', '1', '2', '8', '8', '9', '2', '8', '9', '2', '3', '1', '2', '1', '3', '10', '8', '1', '2', '4', '1', '9', '8', '9', '3', '3', '9', '8', '2', '11', '3', '7', '1', '8', '7', '1', '8', '8', '8', '1', '4', '8', '8', '1', '9', '3', '1', '1', '2', '8', '8', '8', '2', '1', '8', '10', '2', '12', '8', '8', '9', '1', '8', '1', '3', '2', '2', '10', '7', '2', '2', '1', '1', '8', '2', '9', '1', '2', '9', '3', '3', '10', '1', '4', '7', '10', '12', '2', '4', '10', '8', '6', '2', '9', '1', '8', '3', '1', '2', '8', '8', '2', '12', '10', '2', '10', '9', '1', '2', '5', '8', '12', '8', '8', '7', '8', '8', '1', '8', '2', '2', '9', '1', '8', '10', '5', '5', '5', '8', '1', '9', '1', '13', '1', '2', '2', '1', '2', '4', '9', '2', '1', '9', '13', '11', '1', '9', '9', '3', '10', '8', '7', '8', '8', '4', '2', '1', '9', '4', '3', '1', '1', '10', '9', '2', '8', '6', '2', '1', '1', '3', '2', '8', '1', '1', '1', '1', '2', '4', '1', '1', '10', '1', '8', '1', '1', '9', '1', '7', '1', '1', '9', '9', '2', '12', '9', '1', '8', '1', '12', '1', '8', '3', '8', '1', '8', '1', '2', '10', '1', '1', '2', '2', '9', '3', '9', '12', '1', '9', '1', '2', '8', '7', '2', '1', '1', '3', '2', '8', '4', '4', '5', '12', '7', '8', '9', '6', '1', '8', '9', '2', '1', '9', '1', '4', '1', '8', '2', '1', '1', '8', '7', '4', '9', '1', '8', '4', '2', '7', '5', '1', '3', '9', '2', '8', '2', '1', '2', '9', '1', '1', '2', '3', '4', '3', '1', '2', '2', '10', '2', '2', '8', '1', '1', '2', '4', '9', '2', '11', '9', '8', '9', '2', '1', '10', '4', '1', '1', '10', '7', '2', '10', '8', '1', '10', '8', '8', '8', '8', '8', '8', '2', '2', '2', '8', '3', '4', '1', '1', '1', '2', '1', '8', '8', '2', '8', '3', '8', '3', '1', '2', '3', '1', '1', '10', '1', '4', '4', '3', '3', '1', '9', '1', '1', '2', '1', '1', '6', '1', '1', '1', '9', '1', '4', '1', '1', '1', '1', '1', '1', '2', '12', '8', '8', '1', '9', '12', '10', '8', '2', '12', '1', '1', '2', '1', '7', '10', '7', '1', '2', '1', '10', '8', '2', '2', '8', '2', '2', '1', '9', '8', '8', '8', '8', '3', '1', '4', '2', '8', '3', '10', '10', '1', '9', '1', '9', '1', '9', '1', '8', '3', '1', '1', '8', '8', '8', '6', '3', '4', '1', '1', '1', '9', '9', '5', '2', '10', '2', '6', '2', '2', '7', '1', '8', '2', '11', '1', '1', '1', '2', '1', '9', '4', '4', '2', '8', '4', '6', '8', '8', '10', '10', '2', '1', '2', '9', '1', '8', '8', '3', '4', '8', '8', '2', '8', '8', '1', '2', '1', '2', '9', '4', '1', '3', '3', '3', '8', '8', '8', '2', '6', '4', '3', '3', '12', '3', '4', '9', '6', '8', '7', '7', '8', '6', '4', '1', '10', '6', '3', '3', '8', '1', '1', '8', '1', '11', '8', '1', '1', '2', '3', '11', '7', '2', '1', '1', '1', '9', '1', '2', '1', '1', '9', '8', '1', '1', '8', '0', '4', '1', '1', '2', '1', '1', '2', '2', '9', '1', '10', '1', '3', '8', '9', '3', '3', '1', '10', '1', '9', '1', '1', '7', '4', '1', '8', '10', '1', '2', '10', '1', '1', '2', '3', '3', '9', '1', '8', '10', '1', '7', '9', '1', '9', '6', '3', '9', '2', '8', '4', '12', '12', '3', '1', '1', '9', '1', '9', '2', '1', '1', '1', '1', '1', '9', '2', '1', '2', '10', '9', '8', '8', '10', '8', '2', '3', '2', '1', '12', '8', '12', '2', '9', '1', '3', '2', '5', '2', '2', '8', '2', '2', '4', '10', '9', '10', '9', '4', '2', '4', '12', '8', '2', '1', '8', '3', '9', '2', '9', '4', '1', '1', '1', '1', '1', '9', '6', '2', '9', '2', '1', '3', '2', '2', '5', '8', '9', '1', '6', '3', '1', '2', '2', '2', '6', '1', '8', '10', '8', '3', '3', '13', '2', '9', '9', '10', '6', '12', '8', '2', '9', '2', '3', '8', '8', '1', '2', '2', '3', '2', '10', '1', '8', '9', '1', '8', '9', '8', '8', '2', '10', '2', '1', '1', '1', '9', '9', '12', '1', '1', '4', '8', '3', '2', '2', '4', '4', '2', '2', '1', '1', '1', '9', '2', '2', '4', '1', '1', '8', '8', '8', '9', '2', '13', '9', '9', '4', '1', '9', '7', '10', '10', '8', '1', '9', '1', '1', '1', '8', '12', '4', '1', '2', '1', '1', '1', '7', '8', '3', '3', '1', '2', '2', '7', '2', '2', '10', '1', '8', '4', '0', '1', '9', '4', '1', '1', '2', '10', '10', '7', '9', '3', '12', '11', '2', '8', '10', '8', '9', '4', '3', '4', '10', '1', '1', '9', '3', '10', '1', '5', '3', '3', '2', '2', '1', '1', '6', '1', '7', '1', '1', '12', '1', '1', '1', '10', '1', '8', '8', '1', '3', '8', '3', '1', '2', '8', '3', '4', '2', '8', '8', '6', '1', '1', '4', '1', '2', '9', '5', '1', '7', '8', '9', '2', '4', '9', '8', '5', '9', '9', '9', '1', '2', '1', '3', '8', '9', '2', '9', '8', '9', '1', '8', '13', '9', '3', '8', '1', '4', '1', '3', '1', '6', '4', '10', '2', '2', '7', '8', '8', '12', '8', '9', '9', '9', '10', '3', '12', '12', '2', '9', '10', '9', '7', '2', '3', '4', '10', '10', '2', '7', '7', '1', '7', '3', '9', '1', '9', '8', '2', '9', '1', '8', '1', '10', '8', '8', '2', '7', '8', '1', '8', '9', '8', '1', '4', '1', '8', '8', '8', '1', '1', '10', '3', '2', '2', '6', '8', '9', '8', '2', '1', '1', '3', '8', '8', '1', '4', '4', '3', '9', '10', '4', '2', '4', '2', '9', '2', '2', '9', '1', '1', '10', '1', '1', '2', '1', '1', '1', '9', '1', '8', '8', '8', '2', '3', '8', '1', '6', '7', '3', '1', '9', '1', '2', '1', '6', '1', '2', '10', '1', '4', '2', '3', '2', '9', '9', '4', '9', '9', '1', '2', '8', '4', '7', '8', '7', '13', '9', '1', '2', '1', '9', '3', '3', '6', '8', '9', '10', '9', '2', '2', '3', '12', '1', '1', '1', '13', '2', '1', '7', '10', '8', '9', '1', '2', '9', '1', '1', '1', '2', '1', '12', '5', '6', '9', '10', '3', '1', '10', '1', '3', '2', '8', '9', '2', '10', '8', '8', '9', '2', '8', '9', '2', '2', '2', '8', '8', '2', '3', '1', '4', '8', '1', '9', '9', '2', '8', '10', '9', '1', '2', '12', '8', '8', '0', '2', '1', '1', '9', '10', '1', '6', '2', '2', '10', '2', '2', '4', '2', '2', '12', '1', '6', '7', '8', '9', '1', '3', '5', '7', '3', '1', '3', '1', '1', '3', '2', '6', '3', '2', '1', '8', '3', '5', '2', '1', '1', '8', '1', '1', '0', '2', '3', '5', '3', '1', '1', '9', '8', '8', '8', '8', '4', '7', '2', '9', '12', '5', '9', '3', '12', '3', '9', '1', '9', '1', '7', '3', '9', '3', '10', '1', '2', '1', '4', '9', '8', '2', '9', '11', '2', '8', '9', '4', '1', '1', '1', '1', '1', '1', '1', '9', '1', '9', '1', '1', '1', '12', '3', '10', '3', '6', '1', '7', '10', '8', '3', '7', '1', '1', '2', '6', '1', '3', '9', '2', '8', '1', '8', '8', '1', '8', '10', '12', '1', '10', '12', '10', '1', '8', '8', '1', '4', '7', '9', '2', '1', '9', '3', '8', '12', '10', '6', '1', '6', '8', '3', '1', '3', '1', '10', '10', '9', '8', '1', '2', '9', '8', '8', '1', '9', '8', '8', '3', '1', '3', '9', '12', '1', '8', '1', '5', '8', '11', '5', '5', '1', '2', '1', '3', '1', '1', '1', '9', '8', '8', '1', '9', '10', '8', '4', '1', '1', '8', '10', '8', '9', '1', '10', '1', '7', '2', '1', '1', '9', '6', '2', '9', '8', '1', '1', '1', '9', '8', '8', '1', '9', '9', '1', '1', '2', '7', '9', '2', '9', '9', '8', '7', '6', '8', '7', '8', '2', '9', '2', '1', '8', '8', '8', '2', '6', '3', '1', '8', '12', '12', '8', '7', '1', '2', '2', '7', '1', '9', '8', '1', '4', '1', '1', '8', '5', '8', '1', '8', '8', '8', '8', '1', '2', '11', '1', '1', '1', '2', '7', '1', '9', '2', '2', '2', '9', '8', '9', '2', '9', '1', '8', '1', '7', '11', '13', '1', '9', '8', '2', '2', '1', '2', '3', '10', '3', '10', '4', '3', '9', '1', '8', '1', '1', '13', '1', '1', '3', '8', '1', '2', '2', '2', '9', '4', '1', '8', '1', '9', '3', '6', '8', '5', '2', '8', '2', '8', '1', '9', '2', '2', '8', '1', '1', '4', '8', '9', '2', '2', '7', '1', '8', '12', '2', '12', '8', '2', '9', '9', '3', '8', '1', '1', '9', '9', '9', '2', '8', '1', '9', '1', '8', '9', '8', '2', '2', '4', '1', '9', '10', '10', '8', '8', '1', '1', '2', '1', '4', '1', '2', '1', '1', '3', '12', '8', '8', '8', '8', '10', '2', '8', '12', '1', '9', '9', '8', '9', '1', '2', '1', '8', '8', '8', '2', '8', '8', '3', '10', '8', '9', '1', '1', '1', '3', '4', '8', '10', '6', '3', '1', '3', '2', '8', '9', '3', '5', '4', '1', '5', '2', '9', '9', '9', '1', '1', '1', '9', '9', '6', '10', '9', '8', '12', '2', '9', '1', '2', '1', '1', '1', '8', '1', '12', '1', '12', '1', '9', '1', '8', '1', '2', '1', '2', '8', '8', '10', '1', '9', '1', '2', '2', '8', '8', '3', '12', '1', '11', '2', '10', '12', '11', '2', '1', '10', '1', '1', '9', '3', '10', '2', '7', '1', '8', '1', '9', '9', '2', '1', '3', '12', '5', '9', '9', '8', '1', '8', '8', '8', '1', '1', '3', '9', '8', '9', '8', '3', '10', '3', '7', '8', '9', '2', '3', '1', '9', '10', '9', '2', '8', '2', '6', '4', '1', '1', '3', '8', '2', '3', '9', '1', '2', '1', '8', '1', '2', '2', '2', '2', '9', '9', '4', '8', '9', '1', '1', '2', '9', '1', '5', '2', '9', '8', '10', '1', '2', '10', '8', '5', '6', '4', '8', '1', '1', '1', '8', '9', '2', '8', '8', '8', '12', '2', '2', '1', '8', '1', '2', '1', '9', '8', '8', '9', '1', '1', '8', '7', '1', '8', '0', '2', '3', '8', '1', '1', '8', '1', '1', '12', '3', '2', '10', '8', '10', '6', '1', '8', '8', '10', '8', '8', '1', '4', '8', '1', '2', '9', '8', '1', '1', '3', '3', '5', '1', '1', '2', '1', '2', '1', '9', '8', '3', '9', '8', '2', '10', '9', '1', '8', '1', '10', '9', '10', '1', '2', '3', '8', '1', '3', '1', '9', '9', '8', '1', '9', '8', '8', '9', '1', '9', '2', '8', '8', '2', '13', '8', '10', '8', '9', '3', '2', '1', '3', '1', '12', '10', '10', '1', '11', '1', '2', '4', '2', '10', '1', '8', '11', '1', '1', '1', '2', '2', '8', '2', '9', '8', '9', '9', '12', '8', '1', '9', '2', '4', '1', '8', '3', '9', '1', '6', '5', '8', '9', '3', '3', '2', '1', '1', '1', '8', '11', '1', '8', '7', '1', '11', '9', '1', '7', '9', '9', '8', '8', '8', '12', '8', '1', '2', '9', '8', '8', '2', '10', '9', '8', '8', '4', '10', '9', '8', '2', '10', '10', '2', '1', '2', '1', '2', '1', '4', '1', '7', '1', '1', '3', '12', '9', '8', '5', '9', '10', '1', '9', '9', '2', '7', '4', '1', '1', '8', '12', '8', '2', '2', '9', '4', '1', '1', '5', '9', '1', '8', '12', '8', '1', '1', '4', '9', '10', '2', '3', '1', '3', '3', '3', '8', '1', '2', '1', '2', '1', '2', '9', '1', '2', '8', '9', '4', '8', '8', '10', '2', '12', '5', '5', '1', '8', '1', '7', '8', '1', '1', '8', '9', '12', '4', '9', '3', '1', '2', '5', '9', '2', '1', '2', '2', '1', '2', '8', '1', '8', '8', '2', '2', '1', '8', '4', '1', '2', '10', '9', '10', '8', '1', '10', '4', '8', '8', '10', '2', '8', '1', '1', '3', '10', '1', '4', '2', '8', '3', '3', '2', '9', '8', '5', '5', '9', '3', '10', '8', '1', '2', '1', '2', '9', '1', '1', '2', '9', '9', '8', '8', '11', '9', '4', '1', '8', '2', '7', '1', '2', '8', '2', '9', '9', '8', '2', '9', '9', '8', '8', '1', '2', '8', '1', '1', '2', '9', '8', '1', '4', '9', '1', '8', '12', '1', '12', '2', '8', '2', '9', '1', '12', '1', '2', '9', '1', '1', '9', '3', '2', '9', '9', '2', '11', '8', '7', '9', '9', '9', '8', '8', '1', '2', '8', '1', '1', '4', '1', '2', '10', '1', '9', '2', '1', '1', '1', '9', '1', '13', '4', '3', '2', '1', '1', '2', '2', '7', '8', '7', '1', '1', '2', '8', '8', '3', '4', '8', '2', '10', '13', '8', '8', '9', '2', '2', '1', '1', '10', '4', '2', '7', '9', '8', '2', '1', '9', '8', '1', '1', '9', '8', '9', '8', '2', '8', '2', '2', '9', '2', '1', '9', '1', '2', '4', '8', '2', '1', '1', '8', '1', '4', '1', '9', '3', '9', '2', '7', '1', '9', '6', '1', '10', '2', '2', '2', '2', '2', '10', '10', '10', '9', '9', '9', '3', '12', '10', '1', '1', '10', '1', '1', '2', '2', '1', '2', '3', '12', '8', '8', '1', '2', '9', '9', '1', '1', '10', '8', '9', '8', '3', '1', '1', '3', '1', '10', '1', '1', '1', '4', '1', '1', '1', '7', '10', '2', '1', '8', '1', '9', '3', '1', '10', '8', '8', '1', '5', '9', '1', '2', '1', '8', '8', '1', '3', '1', '10', '2', '1', '1', '2', '8', '2', '5', '3', '5', '2', '1', '1', '9', '1', '7', '9', '9', '2', '8', '1', '12', '4', '1', '4', '9', '9', '4', '8', '1', '10', '10', '8', '8', '8', '9', '2', '3', '5', '1', '8', '1', '1', '1', '7', '10', '1', '4', '12', '3', '2', '2', '9', '1', '1', '1', '2', '8', '4', '1', '7', '3', '12', '8', '6', '2', '2', '7', '9', '11', '1', '10', '9', '1', '8', '12', '2', '11', '1', '2', '3', '1', '1', '1', '8', '9', '2', '2', '2', '2', '3', '3', '8', '10', '4', '1', '2', '9', '8', '2', '2', '9', '1', '8', '11', '4', '2', '8', '7', '1', '1', '7', '3', '9', '9', '4', '5', '8', '10', '2', '9', '9', '9', '8', '1', '9', '2', '2', '2', '1', '2', '9', '4', '3', '12', '4', '3', '2', '3', '8', '3', '10', '1', '10', '1', '1', '8', '10', '6', '8', '9', '9', '1', '2', '9', '2', '9', '3', '8', '1', '1', '12', '1', '5', '1', '10', '8', '10', '2', '7', '1', '1', '1', '1', '3', '2', '3', '5', '9', '1', '2', '1', '9', '8', '10', '9', '8', '1', '8', '1', '8', '2', '8', '1', '2', '8', '1', '2', '5', '8', '12', '2', '1', '1', '1', '1', '1', '8', '8', '2', '1', '4', '2', '8', '8', '8', '2', '9', '9', '11', '1', '2', '9', '3', '1', '1', '8', '9', '2', '4', '10', '1', '9', '8', '4', '9', '8', '10', '8', '8', '9', '2', '8', '9', '3', '3', '3', '4', '3', '2', '2', '10', '8', '2', '1', '5', '1', '9', '1', '1', '2', '1', '2', '3', '1', '1', '8', '8', '1', '10', '8', '8', '1', '6', '4', '8', '2', '5', '8', '1', '3', '8', '2', '8', '9', '1', '1', '8', '12', '10', '1', '5', '8', '2', '8', '10', '9', '9', '1', '6', '9', '1', '10', '8', '2', '9', '10', '1', '2', '1', '1', '8', '8', '3', '9', '8', '1', '10', '2', '8', '1', '10', '1', '5', '1', '1', '1', '5', '1', '1', '1', '4', '1', '1', '1', '8', '2', '8', '1', '8', '3', '8', '9', '1', '8', '1', '8', '1', '1', '2', '2', '1', '12', '9', '9', '1', '8', '2', '1', '2', '8', '1', '9', '1', '1', '2', '1', '2', '2', '2', '1', '9', '9', '8', '8', '1', '1', '9', '10', '8', '4', '3', '3', '4', '9', '1', '3', '3', '10', '2', '2', '1', '8', '4', '1', '9', '4', '1', '1', '9', '8', '10', '4', '9', '9', '8', '2', '1', '3', '4', '9', '3', '8', '9', '1', '1', '2', '1', '7', '8', '2', '9', '1', '9', '2', '6', '9', '10', '8', '1', '1', '5', '9', '5', '1', '9', '10', '9', '3', '3', '8', '8', '2', '9', '2', '8', '2', '1', '8', '5', '8', '3', '10', '1', '1', '2', '1', '8', '1', '4', '3', '2', '9', '4', '9', '8', '8', '8', '1', '3', '9', '1', '9', '9', '1', '2', '1', '9', '8', '9', '8', '1', '1', '1', '4', '2', '2', '9', '9', '1', '1', '1', '3', '6', '1', '2', '3', '1', '4', '2', '9', '1', '9', '9', '1', '8', '2', '1', '9', '1', '8', '1', '8', '8', '2', '1', '9', '9', '6', '8', '8', '9', '8', '10', '8', '9', '5', '1', '1', '1', '1', '8', '1', '8', '12', '8', '1', '12', '9', '2', '8', '1', '1', '2', '1', '8', '6', '9', '9', '8', '1', '8', '9', '7', '7', '8', '9', '9', '1', '8', '3', '8', '1', '3', '3', '8', '9', '8', '2', '8', '1', '2', '9', '8', '1', '1', '1', '1', '9', '1', '9', '8', '12', '3', '8', '8', '1', '10', '10', '10', '2', '2', '1', '10', '2', '2', '10', '8', '12', '8', '1', '1', '1', '2', '1', '1', '3', '8', '1', '2', '2', '2', '1', '1', '6', '2', '8', '8', '8', '1', '1', '1', '9', '9', '2', '8', '10', '2', '8', '2', '1', '2', '9', '9', '2', '1', '1', '8', '8', '1', '3', '1', '8', '9', '1', '10', '9', '1', '1', '1', '1', '7', '2', '2', '1', '2', '8', '8', '1', '2', '1', '3', '2', '1', '8', '3', '9', '2', '10', '2', '10', '1', '2', '1', '1', '13', '9', '10', '8', '2', '2', '1', '1', '8', '2', '2', '1', '9', '1', '1', '8', '9', '9', '2', '9', '2', '2', '1', '1', '1', '8', '9', '4', '9', '9', '1', '8', '2', '1', '1', '8', '2', '2', '2', '8', '1', '1', '8', '2', '10', '2', '9', '9', '7', '1', '1', '2', '2', '8', '3', '1', '2', '1', '1', '8', '1', '1', '1', '9', '1', '1', '8', '8', '1', '9', '6', '1', '9', '1', '8', '1', '8', '8', '8', '1', '3', '8', '8', '2', '6', '3', '2', '1', '10', '1', '8', '2', '1', '6', '1', '1', '1', '8', '1', '10', '1', '1', '8', '9', '2', '6', '9', '2', '9', '4', '1', '8', '1', '3', '7', '8', '8', '5', '8', '7', '1', '1', '1', '13', '8', '3', '1', '1', '1', '1', '2', '8', '2', '12', '8', '1', '2', '5', '1', '8', '2', '10', '8', '2', '10', '1', '5', '2', '1', '1', '5', '2', '2', '7', '8', '2', '9', '9', '1', '10', '1', '8', '2', '5', '8', '1', '5', '1', '10', '1', '1', '9', '8', '6', '1', '8', '9', '8', '1', '8', '2', '2', '8', '3', '9', '1', '9', '3', '8', '4', '4', '3', '3', '1', '1', '1', '8', '9', '1', '1', '8', '3', '1', '2', '8', '2', '1', '1', '10', '1', '2', '2', '1', '1', '8', '2', '8', '2', '10', '2', '2', '10', '8', '8', '8', '13', '2', '2', '9', '2', '5', '9', '2', '1', '8', '8', '8', '1', '12', '12', '2', '9', '2', '1', '8', '2', '1', '8', '1', '9', '9', '2', '7', '1', '1', '7', '1', '4', '3', '1', '10', '3', '10', '9', '4', '6', '7', '5', '2', '1', '8', '8', '1', '4', '9', '2', '1', '8', '1', '1', '1', '1', '1', '8', '9', '8', '8', '8', '8', '9', '8', '10', '1', '8', '2', '7', '8', '9', '1', '2', '5', '9', '10', '8', '9', '12', '1', '6', '1', '2', '10', '9', '4', '1', '8', '10', '10', '1', '1', '1', '1', '1', '2', '3', '8', '1', '2', '10', '2', '1', '2', '4', '2', '2', '9', '1', '4', '2', '1', '1', '12', '12', '9', '9', '7', '1', '8', '4', '9', '9', '8', '1', '7', '3', '2', '1', '1', '4', '8', '1', '5', '8', '2', '8', '1', '14', '9', '12', '1', '10', '2', '1', '1', '8', '8', '6', '6', '3', '1', '2', '8', '1', '3', '2', '1', '8', '8', '1', '10', '8', '2', '8', '2', '5', '9', '1', '8', '8', '1', '1', '8', '8', '13', '1', '3', '8', '4', '1', '9', '7', '8', '8', '8', '3', '8', '1', '4', '2', '8', '8', '8', '7', '1', '1', '2', '8', '8', '9', '8', '8', '2', '3', '9', '9', '2', '1', '2', '2', '1', '8', '2', '6', '2', '1', '1', '9', '10', '3', '8', '2', '3', '2', '8', '8', '1', '8', '8', '8', '9', '1', '4', '1', '9', '2', '1', '8', '0', '1', '8', '1', '1', '8', '9', '9', '1', '3', '1', '2', '8', '8', '7', '1', '1', '2', '9', '2', '10', '2', '8', '2', '2', '2', '7', '1', '9', '8', '1', '3', '9', '2', '1', '10', '8', '1', '4', '1', '8', '5', '9', '8', '8', '1', '2', '2', '1', '8', '8', '6', '8', '1', '1', '8', '3', '2', '2', '1', '8', '1', '7', '6', '8', '1', '1', '1', '9', '1', '1', '1', '2', '1', '11', '10', '10', '11', '9']\n",
            "                                                   text  label\n",
            "0       Halliburton Oil Well Cementing Co. v. Walker...      8\n",
            "1       Petitioners are members of a Mormon sect, kn...      1\n",
            "2       Champlin owns and operates a line of six-inc...      8\n",
            "3       Eleven Indian tribes have sued the U.S. in t...      2\n",
            "4       The Court of Claims rendered a judgment for ...      8\n",
            "...                                                 ...    ...\n",
            "8414   Opinion reported: Ante, p. 88.\\nDECREE\\n1. It...     11\n",
            "8415    In this dispute between Utah and the United ...     10\n",
            "8416    The U.S. held to have sovereign rights over ...     10\n",
            "8417    Louisiana's exception to the portion of the ...     11\n",
            "8418    California seeks to invoke this Court's orig...      9\n",
            "\n",
            "[8419 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "with open('summarized_usdb.txt') as f:\n",
        "    contents = f.read()\n",
        "\n",
        "records=contents.split(\"---\")\n",
        "records=records[1:]\n",
        "\n",
        "summarized_data = pd.DataFrame(records,\n",
        "               columns =['text'])\n",
        "\n",
        "len_list = [len(ele.split()) for ele in records]\n",
        "# len_list = [len(ele.split()) for ele in texts]\n",
        "res = 0 if len(len_list) == 0 else (float(sum(len_list)) / len(len_list))\n",
        "print(\"Average Length %s\" % res) \n",
        "\n",
        "temp_file = open(\"labels_sc.txt\", \"r\")\n",
        "#temp_file = open(\"labels_sc_279.txt\", \"r\")\n",
        "\n",
        "data = temp_file.read()\n",
        "  \n",
        "# replacing end splitting the text \n",
        "# when newline ('\\n') is seen.\n",
        "label_list = data.split(\"\\n\")\n",
        "print(label_list)\n",
        "label_list = label_list[0:-1]\n",
        "print(label_list)\n",
        "label_list = [int(i) for i in label_list]\n",
        "temp_file.close()\n",
        "# label_list = temp_file.readlines()\n",
        "# print(label_list)\n",
        "\n",
        "summarized_data['label'] = label_list\n",
        "\n",
        "print(summarized_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_tlJZIjXjKkM"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    inps = Input(shape = (max_len,), dtype='int64')\n",
        "    masks= Input(shape = (max_len,), dtype='int64')\n",
        "    dbert_layer = dbert_model(inps, attention_mask=masks)[0][:,0,:]\n",
        "    dense_0 = Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))(dbert_layer)\n",
        "    dropout_0= Dropout(0.5)(dense_0)\n",
        "    pred = Dense(15, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout_0)\n",
        "    model = tf.keras.Model(inputs=[inps,masks], outputs=pred)\n",
        "    print(model.summary())\n",
        "    return model   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3222330b4e8d47e4b275db6e2ebe5292",
            "c0233c15b11c4e0b881d8c6f94bba612",
            "2d58123f020341a3b6af8bb077f71f6e",
            "5b1111869aaa44f68ab0883dbd5d5270",
            "39206b4da72f45879e273a19296f158c",
            "a6242b11fc8846e3a63cfa0572c3ef4e",
            "51b49b687bac4265a80fc5915dbfeb1f",
            "e66173d1a2e341a78aa6ba0781726099",
            "97c33d10b5f9438195500e2945a1b347",
            "6a80e22258db44229a000dbde3e062e1",
            "0e4dd7f07fcb42fab63b2c6362195dd7",
            "a41ed273a8e44e3da6ea1f91ccd541a4",
            "3305cd4bec5b4605bfcc512091dd19a5",
            "5a8399a729f84254a286eae594def066",
            "87bfd027d7884361aebc07db28480c14",
            "776f40517efd4e35a1ac9bb46fe20f54",
            "fd317d9034af4c8fad402eb90e32d508",
            "4c4019e443114f698c616053642f803d",
            "9e345f9b023a414bbaa6c796bcae6971",
            "a250f0ed50c74c30b3f33342f9e3e34e",
            "4d2e02d8de4548c3aebef6410f42f164",
            "e370513c58bb4a34ab48341d671f8de4",
            "b99af197e39b4fc4a94d3824ef3f2489",
            "65dbf0e595b244679e70e50e3bb0d64a",
            "bf46dc50b47b4f9bbf4b686f1aa41549",
            "7b08344b294a46798679a8a50515ecf6",
            "7dd9e36cb04f4174bf554591c6e06779",
            "6d9fd082c92942cb84face4ebe8ef070",
            "b179e89006f2444a96e027802cc3fa76",
            "b879cb886bce4953918370c964ffaa04",
            "611309bd33674508b26a81eb291d02c8",
            "3c0888e013a3496aa4865363edc0f3c4",
            "4536c3b3124549bfae5b997e5ffd4532",
            "d3573ea767394c6dbcc63bb9c2522d90",
            "8345a95f76034d92943c7049a2c1d48d",
            "b0544ccafa8f42d8955edd619f7102dc",
            "5c866888c17241d6a7a424ec445cd2d1",
            "54c95cd042a8486a9e06acd36ce9b249",
            "0c9ed7052e88412686d3e0af867abb0e",
            "8b9c6fc56e4d419ea5102bffc039ad02",
            "703afa06aaaf458fb46a9f283f6ad70b",
            "89fc9affeb5e44f9a3d20657c03efe28",
            "d67df63f1e594fd38027af801c6b889b",
            "518198985ea646828b85292d271e655a",
            "17c19b2e4e7b45fd83451fb9a9428cc8",
            "6a3079e9630948ab983659616d03ecc2",
            "594a34aff5874e7689aa47970d7610c0",
            "8c5df1f49c47473faa1108069ca330ff",
            "84793f47511c4b5db577233f479da783",
            "e2f866a54acf40ff977cb211e5026156",
            "f50a46c46bf94ffa86b9844896bdffda",
            "35dd76b0094f4a8a9345184fe35acecc",
            "5922d3fe6aa1408bb0b016905533492b",
            "f2377ba8f0284ea3b54c87278a6ebcc0",
            "faa7c5435d3e4a63ad73acc0f7e8f14e"
          ]
        },
        "id": "oXvikWU_jMvE",
        "outputId": "a4a2fe1e-0181-4058-f0e6-a94874f57afe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3222330b4e8d47e4b275db6e2ebe5292"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.99k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a41ed273a8e44e3da6ea1f91ccd541a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/217k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b99af197e39b4fc4a94d3824ef3f2489"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3573ea767394c6dbcc63bb9c2522d90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17c19b2e4e7b45fd83451fb9a9428cc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 21 04:57:45 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    42W / 300W |   1683MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 339s 341ms/step - loss: 6.9033 - accuracy: 0.6606 - val_loss: 5.9831 - val_accuracy: 0.7482\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 324s 341ms/step - loss: 5.3748 - accuracy: 0.8090 - val_loss: 4.9675 - val_accuracy: 0.7684\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 324s 342ms/step - loss: 4.2821 - accuracy: 0.8641 - val_loss: 4.2158 - val_accuracy: 0.7755\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 321s 338ms/step - loss: 3.3716 - accuracy: 0.9110 - val_loss: 3.6020 - val_accuracy: 0.7743\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 324s 342ms/step - loss: 2.6055 - accuracy: 0.9426 - val_loss: 3.0897 - val_accuracy: 0.7827\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.7826603325415677\n",
            "Weighted F1: 0.7854149264171284\n",
            "Micro F1: 0.7826603325415677\n",
            "Weighted Precision: 0.8021470079878871\n",
            "Micro Precision: 0.7826603325415677\n",
            "Weighted Recall: 0.7826603325415677\n",
            "Micro Recall: 0.7826603325415677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 21 05:26:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    43W / 300W |  15237MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 339s 343ms/step - loss: 7.0139 - accuracy: 0.6439 - val_loss: 6.0184 - val_accuracy: 0.7518\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 325s 343ms/step - loss: 5.4128 - accuracy: 0.7986 - val_loss: 4.9608 - val_accuracy: 0.7910\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 322s 340ms/step - loss: 4.3012 - accuracy: 0.8620 - val_loss: 4.2466 - val_accuracy: 0.7672\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 322s 340ms/step - loss: 3.3827 - accuracy: 0.9058 - val_loss: 3.5725 - val_accuracy: 0.7850\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 325s 343ms/step - loss: 2.6106 - accuracy: 0.9407 - val_loss: 2.9935 - val_accuracy: 0.7981\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.7980997624703088\n",
            "Weighted F1: 0.8008275345038027\n",
            "Micro F1: 0.7980997624703088\n",
            "Weighted Precision: 0.8085961593897452\n",
            "Micro Precision: 0.7980997624703088\n",
            "Weighted Recall: 0.7980997624703088\n",
            "Micro Recall: 0.7980997624703088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 21 05:55:12 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    43W / 300W |  15237MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 343s 344ms/step - loss: 6.9689 - accuracy: 0.6566 - val_loss: 6.0702 - val_accuracy: 0.7518\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 325s 343ms/step - loss: 5.4961 - accuracy: 0.7942 - val_loss: 5.1387 - val_accuracy: 0.7755\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 322s 340ms/step - loss: 4.4043 - accuracy: 0.8634 - val_loss: 4.2913 - val_accuracy: 0.7755\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 322s 340ms/step - loss: 3.4650 - accuracy: 0.9129 - val_loss: 3.6003 - val_accuracy: 0.7720\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 325s 343ms/step - loss: 2.6963 - accuracy: 0.9388 - val_loss: 3.0561 - val_accuracy: 0.7898\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.7897862232779097\n",
            "Weighted F1: 0.7929042864682719\n",
            "Micro F1: 0.7897862232779097\n",
            "Weighted Precision: 0.8054091857753799\n",
            "Micro Precision: 0.7897862232779097\n",
            "Weighted Recall: 0.7897862232779097\n",
            "Micro Recall: 0.7897862232779097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 21 06:24:03 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    43W / 300W |  15237MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 343s 344ms/step - loss: 6.9134 - accuracy: 0.6521 - val_loss: 6.0006 - val_accuracy: 0.7494\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 325s 343ms/step - loss: 5.4274 - accuracy: 0.7917 - val_loss: 5.0561 - val_accuracy: 0.7720\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 322s 339ms/step - loss: 4.3826 - accuracy: 0.8497 - val_loss: 4.2819 - val_accuracy: 0.7708\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 322s 340ms/step - loss: 3.4467 - accuracy: 0.9101 - val_loss: 3.6327 - val_accuracy: 0.7684\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 326s 344ms/step - loss: 2.7028 - accuracy: 0.9336 - val_loss: 3.0319 - val_accuracy: 0.7933\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.7933491686460807\n",
            "Weighted F1: 0.7964205846007012\n",
            "Micro F1: 0.7933491686460807\n",
            "Weighted Precision: 0.805453348022404\n",
            "Micro Precision: 0.7933491686460807\n",
            "Weighted Recall: 0.7933491686460807\n",
            "Micro Recall: 0.7933491686460807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 15)           7695        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 21 06:52:56 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    43W / 300W |  15237MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "948/948 [==============================] - 344s 344ms/step - loss: 6.9007 - accuracy: 0.6607 - val_loss: 6.0021 - val_accuracy: 0.7447\n",
            "Epoch 2/5\n",
            "948/948 [==============================] - 326s 343ms/step - loss: 5.3494 - accuracy: 0.8078 - val_loss: 4.9775 - val_accuracy: 0.7779\n",
            "Epoch 3/5\n",
            "948/948 [==============================] - 322s 340ms/step - loss: 4.2482 - accuracy: 0.8680 - val_loss: 4.1710 - val_accuracy: 0.7779\n",
            "Epoch 4/5\n",
            "948/948 [==============================] - 325s 343ms/step - loss: 3.3297 - accuracy: 0.9154 - val_loss: 3.5364 - val_accuracy: 0.7815\n",
            "Epoch 5/5\n",
            "948/948 [==============================] - 321s 339ms/step - loss: 2.5738 - accuracy: 0.9448 - val_loss: 2.9809 - val_accuracy: 0.7815\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 15)           7695        ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,883,663\n",
            "Trainable params: 109,883,663\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Accuracy: 0.7814726840855107\n",
            "Weighted F1: 0.7786808993171465\n",
            "Micro F1: 0.7814726840855107\n",
            "Weighted Precision: 0.7842595460987092\n",
            "Micro Precision: 0.7814726840855107\n",
            "Weighted Recall: 0.7814726840855107\n",
            "Micro Recall: 0.7814726840855107\n",
            "Average Accuracy: 0.7890736342042756\n",
            "Average Weighted F1: 0.7908496462614101\n",
            "Average Micro F1: 0.7890736342042756\n",
            "Average Weighted Precision: 0.8011730494548249\n",
            "Average Micro Precision: 0.7890736342042756\n",
            "Average Weighted Recall: 0.7890736342042756\n",
            "Average Micro Recall: 0.7890736342042756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "total_accuracy=0\n",
        "total_weighted_f1=0\n",
        "total_micro_f1=0\n",
        "total_weighted_precision=0\n",
        "total_micro_precision=0\n",
        "total_weighted_recall=0\n",
        "total_micro_recall=0\n",
        "\n",
        "for i in range(5):\n",
        "  gc.collect()\n",
        "  tf.keras.backend.clear_session()\n",
        "  dbert_tokenizer = AutoTokenizer.from_pretrained('nlpaueb/legal-bert-base-uncased')\n",
        "  dbert_model = TFAutoModel.from_pretrained('nlpaueb/legal-bert-base-uncased')\n",
        "  max_len=512\n",
        "  sentences=summarized_data['text']\n",
        "  labels=summarized_data['label']\n",
        "  len(sentences),len(labels)\n",
        "  model_0=create_model()\n",
        "  input_ids=[]\n",
        "  attention_masks=[]\n",
        "\n",
        "  for sent in sentences:\n",
        "    dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
        "    input_ids.append(dbert_inps['input_ids'])\n",
        "    attention_masks.append(dbert_inps['attention_mask'])\n",
        "  input_ids=np.asarray(input_ids)\n",
        "\n",
        "  attention_masks=np.array(attention_masks)\n",
        "  labels=np.array(labels)\n",
        "  train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.1,random_state=42)\n",
        "  log_dir='dbert_model'\n",
        "\n",
        "  model_save_path='./drive/MyDrive/Summarization/legalbert-summarization-512-'+str(i)+'-15labels.h5'\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "  callbacks= [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,monitor='val_accuracy',mode='max',save_best_only=True,save_weights_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
        "  model_0.compile(loss=loss,optimizer=optimizer, metrics=[accuracy])\n",
        "  gpu_info = !nvidia-smi\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "  else:\n",
        "    print(gpu_info)\n",
        "  history=model_0.fit([train_inp,train_mask],train_label,batch_size=8,epochs=5,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)\n",
        "  pred_labels=[]\n",
        "\n",
        "  model_saved= create_model()\n",
        "  model_saved.compile(loss=loss,optimizer=optimizer, metrics=[accuracy])\n",
        "  model_saved.load_weights('./drive/MyDrive/Summarization/legalbert-summarization-512-'+str(i)+'-15labels.h5')\n",
        "\n",
        "  for i in range(0,len(val_inp)):\n",
        "    pred=model_saved.predict([val_inp[i].reshape(1,512),val_mask[i].reshape(1,512)])\n",
        "    pred_label = pred.argmax(axis=1)\n",
        "    pred_labels.append(pred_label)\n",
        "  accuracy=accuracy_score(val_label, pred_labels)\n",
        "  print(\"Accuracy: \"+str(accuracy))\n",
        "  total_accuracy=total_accuracy+accuracy\n",
        "  \n",
        "  weighted_f1=f1_score(val_label,pred_labels, average='weighted')\n",
        "  print(\"Weighted F1: \"+ str(weighted_f1))\n",
        "  total_weighted_f1=total_weighted_f1+weighted_f1\n",
        "  micro_f1=f1_score(val_label,pred_labels, average='micro')\n",
        "  print(\"Micro F1: \"+ str(micro_f1))\n",
        "  total_micro_f1=total_micro_f1+micro_f1\n",
        "\n",
        "  weighted_precision=precision_score(val_label, pred_labels, average='weighted')\n",
        "  print(\"Weighted Precision: \" + str(weighted_precision))\n",
        "  total_weighted_precision=total_weighted_precision+weighted_precision\n",
        "  micro_precision=precision_score(val_label, pred_labels, average='micro')\n",
        "  print(\"Micro Precision: \" + str(micro_precision))\n",
        "  total_micro_precision=total_micro_precision+micro_precision\n",
        "\n",
        "  weighted_recall=recall_score(val_label, pred_labels, average='weighted')\n",
        "  print(\"Weighted Recall: \" + str(weighted_recall))\n",
        "  total_weighted_recall=total_weighted_recall+weighted_recall\n",
        "  micro_recall=recall_score(val_label, pred_labels, average='micro')\n",
        "  print(\"Micro Recall: \" + str(micro_recall))\n",
        "  total_micro_recall=total_micro_recall+micro_recall\n",
        "\n",
        "\n",
        "print(\"Average Accuracy: \"+str(total_accuracy/5))\n",
        "print(\"Average Weighted F1: \"+str(total_weighted_f1/5))\n",
        "print(\"Average Micro F1: \"+str(total_micro_f1/5))\n",
        "print(\"Average Weighted Precision: \"+str(total_weighted_precision/5))\n",
        "print(\"Average Micro Precision: \"+str(total_micro_precision/5))\n",
        "print(\"Average Weighted Recall: \"+str(total_weighted_recall/5))\n",
        "print(\"Average Micro Recall: \"+str(total_micro_recall/5))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "machine_shape": "hm",
      "name": "LegalBERT_Summarization-512_15labels.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3222330b4e8d47e4b275db6e2ebe5292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0233c15b11c4e0b881d8c6f94bba612",
              "IPY_MODEL_2d58123f020341a3b6af8bb077f71f6e",
              "IPY_MODEL_5b1111869aaa44f68ab0883dbd5d5270"
            ],
            "layout": "IPY_MODEL_39206b4da72f45879e273a19296f158c"
          }
        },
        "c0233c15b11c4e0b881d8c6f94bba612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6242b11fc8846e3a63cfa0572c3ef4e",
            "placeholder": "​",
            "style": "IPY_MODEL_51b49b687bac4265a80fc5915dbfeb1f",
            "value": "Downloading: 100%"
          }
        },
        "2d58123f020341a3b6af8bb077f71f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e66173d1a2e341a78aa6ba0781726099",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97c33d10b5f9438195500e2945a1b347",
            "value": 48
          }
        },
        "5b1111869aaa44f68ab0883dbd5d5270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a80e22258db44229a000dbde3e062e1",
            "placeholder": "​",
            "style": "IPY_MODEL_0e4dd7f07fcb42fab63b2c6362195dd7",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.23kB/s]"
          }
        },
        "39206b4da72f45879e273a19296f158c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6242b11fc8846e3a63cfa0572c3ef4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b49b687bac4265a80fc5915dbfeb1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e66173d1a2e341a78aa6ba0781726099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c33d10b5f9438195500e2945a1b347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a80e22258db44229a000dbde3e062e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e4dd7f07fcb42fab63b2c6362195dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a41ed273a8e44e3da6ea1f91ccd541a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3305cd4bec5b4605bfcc512091dd19a5",
              "IPY_MODEL_5a8399a729f84254a286eae594def066",
              "IPY_MODEL_87bfd027d7884361aebc07db28480c14"
            ],
            "layout": "IPY_MODEL_776f40517efd4e35a1ac9bb46fe20f54"
          }
        },
        "3305cd4bec5b4605bfcc512091dd19a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd317d9034af4c8fad402eb90e32d508",
            "placeholder": "​",
            "style": "IPY_MODEL_4c4019e443114f698c616053642f803d",
            "value": "Downloading: 100%"
          }
        },
        "5a8399a729f84254a286eae594def066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e345f9b023a414bbaa6c796bcae6971",
            "max": 1017,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a250f0ed50c74c30b3f33342f9e3e34e",
            "value": 1017
          }
        },
        "87bfd027d7884361aebc07db28480c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d2e02d8de4548c3aebef6410f42f164",
            "placeholder": "​",
            "style": "IPY_MODEL_e370513c58bb4a34ab48341d671f8de4",
            "value": " 0.99k/0.99k [00:00&lt;00:00, 39.4kB/s]"
          }
        },
        "776f40517efd4e35a1ac9bb46fe20f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd317d9034af4c8fad402eb90e32d508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c4019e443114f698c616053642f803d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e345f9b023a414bbaa6c796bcae6971": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a250f0ed50c74c30b3f33342f9e3e34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d2e02d8de4548c3aebef6410f42f164": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e370513c58bb4a34ab48341d671f8de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b99af197e39b4fc4a94d3824ef3f2489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65dbf0e595b244679e70e50e3bb0d64a",
              "IPY_MODEL_bf46dc50b47b4f9bbf4b686f1aa41549",
              "IPY_MODEL_7b08344b294a46798679a8a50515ecf6"
            ],
            "layout": "IPY_MODEL_7dd9e36cb04f4174bf554591c6e06779"
          }
        },
        "65dbf0e595b244679e70e50e3bb0d64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d9fd082c92942cb84face4ebe8ef070",
            "placeholder": "​",
            "style": "IPY_MODEL_b179e89006f2444a96e027802cc3fa76",
            "value": "Downloading: 100%"
          }
        },
        "bf46dc50b47b4f9bbf4b686f1aa41549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b879cb886bce4953918370c964ffaa04",
            "max": 221793,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_611309bd33674508b26a81eb291d02c8",
            "value": 221793
          }
        },
        "7b08344b294a46798679a8a50515ecf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c0888e013a3496aa4865363edc0f3c4",
            "placeholder": "​",
            "style": "IPY_MODEL_4536c3b3124549bfae5b997e5ffd4532",
            "value": " 217k/217k [00:00&lt;00:00, 627kB/s]"
          }
        },
        "7dd9e36cb04f4174bf554591c6e06779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d9fd082c92942cb84face4ebe8ef070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b179e89006f2444a96e027802cc3fa76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b879cb886bce4953918370c964ffaa04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "611309bd33674508b26a81eb291d02c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c0888e013a3496aa4865363edc0f3c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4536c3b3124549bfae5b997e5ffd4532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3573ea767394c6dbcc63bb9c2522d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8345a95f76034d92943c7049a2c1d48d",
              "IPY_MODEL_b0544ccafa8f42d8955edd619f7102dc",
              "IPY_MODEL_5c866888c17241d6a7a424ec445cd2d1"
            ],
            "layout": "IPY_MODEL_54c95cd042a8486a9e06acd36ce9b249"
          }
        },
        "8345a95f76034d92943c7049a2c1d48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c9ed7052e88412686d3e0af867abb0e",
            "placeholder": "​",
            "style": "IPY_MODEL_8b9c6fc56e4d419ea5102bffc039ad02",
            "value": "Downloading: 100%"
          }
        },
        "b0544ccafa8f42d8955edd619f7102dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_703afa06aaaf458fb46a9f283f6ad70b",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89fc9affeb5e44f9a3d20657c03efe28",
            "value": 112
          }
        },
        "5c866888c17241d6a7a424ec445cd2d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d67df63f1e594fd38027af801c6b889b",
            "placeholder": "​",
            "style": "IPY_MODEL_518198985ea646828b85292d271e655a",
            "value": " 112/112 [00:00&lt;00:00, 2.87kB/s]"
          }
        },
        "54c95cd042a8486a9e06acd36ce9b249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c9ed7052e88412686d3e0af867abb0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b9c6fc56e4d419ea5102bffc039ad02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "703afa06aaaf458fb46a9f283f6ad70b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89fc9affeb5e44f9a3d20657c03efe28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d67df63f1e594fd38027af801c6b889b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "518198985ea646828b85292d271e655a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17c19b2e4e7b45fd83451fb9a9428cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a3079e9630948ab983659616d03ecc2",
              "IPY_MODEL_594a34aff5874e7689aa47970d7610c0",
              "IPY_MODEL_8c5df1f49c47473faa1108069ca330ff"
            ],
            "layout": "IPY_MODEL_84793f47511c4b5db577233f479da783"
          }
        },
        "6a3079e9630948ab983659616d03ecc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2f866a54acf40ff977cb211e5026156",
            "placeholder": "​",
            "style": "IPY_MODEL_f50a46c46bf94ffa86b9844896bdffda",
            "value": "Downloading: 100%"
          }
        },
        "594a34aff5874e7689aa47970d7610c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35dd76b0094f4a8a9345184fe35acecc",
            "max": 536063208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5922d3fe6aa1408bb0b016905533492b",
            "value": 536063208
          }
        },
        "8c5df1f49c47473faa1108069ca330ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2377ba8f0284ea3b54c87278a6ebcc0",
            "placeholder": "​",
            "style": "IPY_MODEL_faa7c5435d3e4a63ad73acc0f7e8f14e",
            "value": " 511M/511M [00:08&lt;00:00, 65.0MB/s]"
          }
        },
        "84793f47511c4b5db577233f479da783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2f866a54acf40ff977cb211e5026156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f50a46c46bf94ffa86b9844896bdffda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35dd76b0094f4a8a9345184fe35acecc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5922d3fe6aa1408bb0b016905533492b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2377ba8f0284ea3b54c87278a6ebcc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa7c5435d3e4a63ad73acc0f7e8f14e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}